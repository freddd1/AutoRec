{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AutoRec cs3639 Recommendation Systems course IDC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### here will be general explanations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch\n",
    "from torch import nn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this project, we will use 2 datasets:\n",
    "* **movielens**, which can be downloaded using `utils.datasets_download.py` or straight from [here](http://files.grouplens.org/datasets/movielens/).\n",
    "* **netflixprize**, which can be downloaded from this [semi-parsed version from kaggle](https://www.kaggle.com/netflix-inc/netflix-prize-data) or from this [raw version](https://archive.org/download/nf_prize_dataset.tar)\n",
    "\n",
    "**NOTE**: for the notebook to run properly, you should save you dataset under `data` folder and `movielens` folder for the movielens dataset and `netflix` folder for the netflixprize dataset.\n",
    "i.e `data/movielens` folder and `data/netflix` folder respectively."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "       user_id  item_id  rating  timestamp\n0            1        1       5  874965758\n1            1        2       3  876893171\n2            1        3       4  878542960\n3            1        4       3  876893119\n4            1        5       3  889751712\n...        ...      ...     ...        ...\n79995      943     1067       2  875501756\n79996      943     1074       4  888640250\n79997      943     1188       3  888640250\n79998      943     1228       3  888640275\n79999      943     1330       3  888692465\n\n[80000 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>874965758</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>876893171</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>878542960</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n      <td>876893119</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>3</td>\n      <td>889751712</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>79995</th>\n      <td>943</td>\n      <td>1067</td>\n      <td>2</td>\n      <td>875501756</td>\n    </tr>\n    <tr>\n      <th>79996</th>\n      <td>943</td>\n      <td>1074</td>\n      <td>4</td>\n      <td>888640250</td>\n    </tr>\n    <tr>\n      <th>79997</th>\n      <td>943</td>\n      <td>1188</td>\n      <td>3</td>\n      <td>888640250</td>\n    </tr>\n    <tr>\n      <th>79998</th>\n      <td>943</td>\n      <td>1228</td>\n      <td>3</td>\n      <td>888640275</td>\n    </tr>\n    <tr>\n      <th>79999</th>\n      <td>943</td>\n      <td>1330</td>\n      <td>3</td>\n      <td>888692465</td>\n    </tr>\n  </tbody>\n</table>\n<p>80000 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data_prep import movielens_load\n",
    "train, test = movielens_load(1)\n",
    "print(train.shape)\n",
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - add function that will calculate the validation loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "def train_epocs(train, model, epochs=10, lr=0.001, reg=0):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=reg)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        # users and items indexes start 1, therefore we use the -1\n",
    "        users = torch.LongTensor(train.user_id.values-1).to(device)\n",
    "        items = torch.LongTensor(train.item_id.values-1).to(device)\n",
    "        ratings = torch.FloatTensor(train.rating.values).to(device) # rating is our label\n",
    "\n",
    "        preds = model(users, items)\n",
    "        loss = torch.sqrt(nn.functional.mse_loss(preds, ratings))\n",
    "\n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # update\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'train RMSE: {loss.item()}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 1682\n"
     ]
    }
   ],
   "source": [
    "from src.matrixfactorization import MatrixFactorization\n",
    "num_users = train.user_id.max()\n",
    "num_items = train.item_id.max()\n",
    "print(num_users, num_items)\n",
    "model = MatrixFactorization(num_users, num_items).to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train RMSE: 5.380264759063721\n",
      "train RMSE: 5.375567436218262\n",
      "train RMSE: 5.370880126953125\n",
      "train RMSE: 5.366203784942627\n",
      "train RMSE: 5.361536502838135\n",
      "train RMSE: 5.356879234313965\n",
      "train RMSE: 5.352232456207275\n",
      "train RMSE: 5.347595691680908\n",
      "train RMSE: 5.342968940734863\n",
      "train RMSE: 5.338353157043457\n",
      "train RMSE: 5.333747386932373\n",
      "train RMSE: 5.329152584075928\n",
      "train RMSE: 5.324568748474121\n",
      "train RMSE: 5.319995403289795\n",
      "train RMSE: 5.315433025360107\n",
      "train RMSE: 5.310881614685059\n",
      "train RMSE: 5.30634069442749\n",
      "train RMSE: 5.3018107414245605\n",
      "train RMSE: 5.2972917556762695\n",
      "train RMSE: 5.292783737182617\n",
      "train RMSE: 5.2882866859436035\n",
      "train RMSE: 5.283801078796387\n",
      "train RMSE: 5.279326915740967\n",
      "train RMSE: 5.2748637199401855\n",
      "train RMSE: 5.270411968231201\n",
      "train RMSE: 5.265970706939697\n",
      "train RMSE: 5.261541366577148\n",
      "train RMSE: 5.257123947143555\n",
      "train RMSE: 5.252717018127441\n",
      "train RMSE: 5.248322486877441\n",
      "train RMSE: 5.24393892288208\n",
      "train RMSE: 5.239566802978516\n",
      "train RMSE: 5.235206604003906\n",
      "train RMSE: 5.230858325958252\n",
      "train RMSE: 5.2265214920043945\n",
      "train RMSE: 5.222195625305176\n",
      "train RMSE: 5.217881202697754\n",
      "train RMSE: 5.213579177856445\n",
      "train RMSE: 5.209288120269775\n",
      "train RMSE: 5.205008506774902\n",
      "train RMSE: 5.200740814208984\n",
      "train RMSE: 5.196483612060547\n",
      "train RMSE: 5.192238807678223\n",
      "train RMSE: 5.188004970550537\n",
      "train RMSE: 5.18378210067749\n",
      "train RMSE: 5.179571151733398\n",
      "train RMSE: 5.1753716468811035\n",
      "train RMSE: 5.171183109283447\n",
      "train RMSE: 5.167006492614746\n",
      "train RMSE: 5.162840843200684\n",
      "train RMSE: 5.158686637878418\n",
      "train RMSE: 5.154543876647949\n",
      "train RMSE: 5.150412082672119\n",
      "train RMSE: 5.146292209625244\n",
      "train RMSE: 5.14218282699585\n",
      "train RMSE: 5.138084888458252\n",
      "train RMSE: 5.133997917175293\n",
      "train RMSE: 5.129922389984131\n",
      "train RMSE: 5.125857830047607\n",
      "train RMSE: 5.121804237365723\n",
      "train RMSE: 5.117762088775635\n",
      "train RMSE: 5.1137309074401855\n",
      "train RMSE: 5.109710693359375\n",
      "train RMSE: 5.105701446533203\n",
      "train RMSE: 5.10170316696167\n",
      "train RMSE: 5.097716331481934\n",
      "train RMSE: 5.0937395095825195\n",
      "train RMSE: 5.089774131774902\n",
      "train RMSE: 5.085819244384766\n",
      "train RMSE: 5.081875324249268\n",
      "train RMSE: 5.077942371368408\n",
      "train RMSE: 5.074019908905029\n",
      "train RMSE: 5.070108413696289\n",
      "train RMSE: 5.066207408905029\n",
      "train RMSE: 5.06231689453125\n",
      "train RMSE: 5.058437347412109\n",
      "train RMSE: 5.054568290710449\n",
      "train RMSE: 5.0507097244262695\n",
      "train RMSE: 5.04686164855957\n",
      "train RMSE: 5.043024063110352\n",
      "train RMSE: 5.039196968078613\n",
      "train RMSE: 5.0353803634643555\n",
      "train RMSE: 5.031574249267578\n",
      "train RMSE: 5.027778148651123\n",
      "train RMSE: 5.023993015289307\n",
      "train RMSE: 5.0202178955078125\n",
      "train RMSE: 5.016452789306641\n",
      "train RMSE: 5.012698173522949\n",
      "train RMSE: 5.008954048156738\n",
      "train RMSE: 5.00521993637085\n",
      "train RMSE: 5.001495838165283\n",
      "train RMSE: 4.997782230377197\n",
      "train RMSE: 4.994078159332275\n",
      "train RMSE: 4.990384578704834\n",
      "train RMSE: 4.986701488494873\n",
      "train RMSE: 4.983027458190918\n",
      "train RMSE: 4.979363918304443\n",
      "train RMSE: 4.975710391998291\n",
      "train RMSE: 4.972066879272461\n",
      "train RMSE: 4.968432903289795\n",
      "train RMSE: 4.964809417724609\n",
      "train RMSE: 4.961195468902588\n",
      "train RMSE: 4.9575910568237305\n",
      "train RMSE: 4.953996658325195\n",
      "train RMSE: 4.950412273406982\n",
      "train RMSE: 4.946837425231934\n",
      "train RMSE: 4.943272113800049\n",
      "train RMSE: 4.939716815948486\n",
      "train RMSE: 4.936171054840088\n",
      "train RMSE: 4.932634353637695\n",
      "train RMSE: 4.929108142852783\n",
      "train RMSE: 4.925590991973877\n",
      "train RMSE: 4.922083377838135\n",
      "train RMSE: 4.918585777282715\n",
      "train RMSE: 4.915096759796143\n",
      "train RMSE: 4.911618232727051\n",
      "train RMSE: 4.908148288726807\n",
      "train RMSE: 4.904688358306885\n",
      "train RMSE: 4.901237487792969\n",
      "train RMSE: 4.897796154022217\n",
      "train RMSE: 4.894363880157471\n",
      "train RMSE: 4.890941143035889\n",
      "train RMSE: 4.887527942657471\n",
      "train RMSE: 4.8841233253479\n",
      "train RMSE: 4.880728244781494\n",
      "train RMSE: 4.877342700958252\n",
      "train RMSE: 4.873966217041016\n",
      "train RMSE: 4.870598793029785\n",
      "train RMSE: 4.8672404289245605\n",
      "train RMSE: 4.863890647888184\n",
      "train RMSE: 4.860550403594971\n",
      "train RMSE: 4.857219696044922\n",
      "train RMSE: 4.853897571563721\n",
      "train RMSE: 4.850584030151367\n",
      "train RMSE: 4.847280025482178\n",
      "train RMSE: 4.843985080718994\n",
      "train RMSE: 4.840698719024658\n",
      "train RMSE: 4.837421417236328\n",
      "train RMSE: 4.834152698516846\n",
      "train RMSE: 4.830893039703369\n",
      "train RMSE: 4.827642440795898\n",
      "train RMSE: 4.824400424957275\n",
      "train RMSE: 4.8211669921875\n",
      "train RMSE: 4.8179426193237305\n",
      "train RMSE: 4.814726829528809\n",
      "train RMSE: 4.811519622802734\n",
      "train RMSE: 4.808321475982666\n",
      "train RMSE: 4.805131912231445\n",
      "train RMSE: 4.801950454711914\n",
      "train RMSE: 4.798778057098389\n",
      "train RMSE: 4.795614242553711\n",
      "train RMSE: 4.792459011077881\n",
      "train RMSE: 4.789312362670898\n",
      "train RMSE: 4.7861738204956055\n",
      "train RMSE: 4.783044338226318\n",
      "train RMSE: 4.779922962188721\n",
      "train RMSE: 4.7768096923828125\n",
      "train RMSE: 4.77370548248291\n",
      "train RMSE: 4.7706098556518555\n",
      "train RMSE: 4.76752233505249\n",
      "train RMSE: 4.7644429206848145\n",
      "train RMSE: 4.761372089385986\n",
      "train RMSE: 4.758309364318848\n",
      "train RMSE: 4.755254745483398\n",
      "train RMSE: 4.752209186553955\n",
      "train RMSE: 4.749171257019043\n",
      "train RMSE: 4.74614143371582\n",
      "train RMSE: 4.743120193481445\n",
      "train RMSE: 4.74010705947876\n",
      "train RMSE: 4.737102031707764\n",
      "train RMSE: 4.734105110168457\n",
      "train RMSE: 4.73111629486084\n",
      "train RMSE: 4.728135585784912\n",
      "train RMSE: 4.725162982940674\n",
      "train RMSE: 4.722198486328125\n",
      "train RMSE: 4.719242095947266\n",
      "train RMSE: 4.716293811798096\n",
      "train RMSE: 4.713353157043457\n",
      "train RMSE: 4.71042013168335\n",
      "train RMSE: 4.70749568939209\n",
      "train RMSE: 4.704578876495361\n",
      "train RMSE: 4.701670169830322\n",
      "train RMSE: 4.698769569396973\n",
      "train RMSE: 4.695876121520996\n",
      "train RMSE: 4.692990779876709\n",
      "train RMSE: 4.690113544464111\n",
      "train RMSE: 4.687243938446045\n",
      "train RMSE: 4.68438196182251\n",
      "train RMSE: 4.681528091430664\n",
      "train RMSE: 4.67868185043335\n",
      "train RMSE: 4.675842761993408\n",
      "train RMSE: 4.673011779785156\n",
      "train RMSE: 4.6701884269714355\n",
      "train RMSE: 4.667373180389404\n",
      "train RMSE: 4.664565086364746\n",
      "train RMSE: 4.661764621734619\n",
      "train RMSE: 4.658971786499023\n",
      "train RMSE: 4.656186103820801\n",
      "train RMSE: 4.653408527374268\n",
      "train RMSE: 4.650638580322266\n",
      "train RMSE: 4.647875785827637\n",
      "train RMSE: 4.645120620727539\n",
      "train RMSE: 4.642373085021973\n",
      "train RMSE: 4.639632701873779\n",
      "train RMSE: 4.636899948120117\n",
      "train RMSE: 4.634174346923828\n",
      "train RMSE: 4.63145637512207\n",
      "train RMSE: 4.6287455558776855\n",
      "train RMSE: 4.626041889190674\n",
      "train RMSE: 4.623346328735352\n",
      "train RMSE: 4.620657444000244\n",
      "train RMSE: 4.617976188659668\n",
      "train RMSE: 4.615302085876465\n",
      "train RMSE: 4.612635135650635\n",
      "train RMSE: 4.609975337982178\n",
      "train RMSE: 4.607323169708252\n",
      "train RMSE: 4.604677677154541\n",
      "train RMSE: 4.602039337158203\n",
      "train RMSE: 4.5994086265563965\n",
      "train RMSE: 4.596784591674805\n",
      "train RMSE: 4.594168186187744\n",
      "train RMSE: 4.591558456420898\n",
      "train RMSE: 4.588955879211426\n",
      "train RMSE: 4.586360454559326\n",
      "train RMSE: 4.5837721824646\n",
      "train RMSE: 4.581190586090088\n",
      "train RMSE: 4.578616619110107\n",
      "train RMSE: 4.576048851013184\n",
      "train RMSE: 4.573488712310791\n",
      "train RMSE: 4.570934772491455\n",
      "train RMSE: 4.56838846206665\n",
      "train RMSE: 4.5658488273620605\n",
      "train RMSE: 4.563316345214844\n",
      "train RMSE: 4.560790061950684\n",
      "train RMSE: 4.558271408081055\n",
      "train RMSE: 4.555758953094482\n",
      "train RMSE: 4.553253650665283\n",
      "train RMSE: 4.550755023956299\n",
      "train RMSE: 4.548263072967529\n",
      "train RMSE: 4.545778274536133\n",
      "train RMSE: 4.543300151824951\n",
      "train RMSE: 4.540828227996826\n",
      "train RMSE: 4.538363456726074\n",
      "train RMSE: 4.535905361175537\n",
      "train RMSE: 4.533453464508057\n",
      "train RMSE: 4.531009197235107\n",
      "train RMSE: 4.528570652008057\n",
      "train RMSE: 4.526139259338379\n",
      "train RMSE: 4.523714065551758\n",
      "train RMSE: 4.52129602432251\n",
      "train RMSE: 4.518884181976318\n",
      "train RMSE: 4.516478538513184\n",
      "train RMSE: 4.514080047607422\n",
      "train RMSE: 4.511687755584717\n",
      "train RMSE: 4.509301662445068\n",
      "train RMSE: 4.506922721862793\n",
      "train RMSE: 4.504549503326416\n",
      "train RMSE: 4.502183437347412\n",
      "train RMSE: 4.499823570251465\n",
      "train RMSE: 4.497470378875732\n",
      "train RMSE: 4.495122909545898\n",
      "train RMSE: 4.492782115936279\n",
      "train RMSE: 4.490447998046875\n",
      "train RMSE: 4.488119602203369\n",
      "train RMSE: 4.485797882080078\n",
      "train RMSE: 4.483482360839844\n",
      "train RMSE: 4.481173515319824\n",
      "train RMSE: 4.478870391845703\n",
      "train RMSE: 4.476573944091797\n",
      "train RMSE: 4.474283695220947\n",
      "train RMSE: 4.471999168395996\n",
      "train RMSE: 4.46972131729126\n",
      "train RMSE: 4.46744966506958\n",
      "train RMSE: 4.465184211730957\n",
      "train RMSE: 4.462924957275391\n",
      "train RMSE: 4.460671424865723\n",
      "train RMSE: 4.4584245681762695\n",
      "train RMSE: 4.456183433532715\n",
      "train RMSE: 4.453948497772217\n",
      "train RMSE: 4.451719284057617\n",
      "train RMSE: 4.449496746063232\n",
      "train RMSE: 4.447279930114746\n",
      "train RMSE: 4.445069313049316\n",
      "train RMSE: 4.442864418029785\n",
      "train RMSE: 4.4406657218933105\n",
      "train RMSE: 4.438472747802734\n",
      "train RMSE: 4.436285972595215\n",
      "train RMSE: 4.434105396270752\n",
      "train RMSE: 4.431930065155029\n",
      "train RMSE: 4.429760932922363\n",
      "train RMSE: 4.427597999572754\n",
      "train RMSE: 4.425440788269043\n",
      "train RMSE: 4.423289775848389\n",
      "train RMSE: 4.421144008636475\n",
      "train RMSE: 4.419003963470459\n",
      "train RMSE: 4.4168701171875\n",
      "train RMSE: 4.414742469787598\n",
      "train RMSE: 4.4126200675964355\n",
      "train RMSE: 4.410503387451172\n",
      "train RMSE: 4.408392906188965\n",
      "train RMSE: 4.406287670135498\n",
      "train RMSE: 4.40418815612793\n",
      "train RMSE: 4.402094841003418\n",
      "train RMSE: 4.4000067710876465\n",
      "train RMSE: 4.397924900054932\n",
      "train RMSE: 4.395848274230957\n",
      "train RMSE: 4.393776893615723\n",
      "train RMSE: 4.391712188720703\n",
      "train RMSE: 4.389652252197266\n",
      "train RMSE: 4.387598037719727\n",
      "train RMSE: 4.385549545288086\n",
      "train RMSE: 4.383506774902344\n",
      "train RMSE: 4.3814697265625\n",
      "train RMSE: 4.379437446594238\n",
      "train RMSE: 4.377411365509033\n",
      "train RMSE: 4.375391006469727\n",
      "train RMSE: 4.373375415802002\n",
      "train RMSE: 4.371366024017334\n",
      "train RMSE: 4.369361400604248\n",
      "train RMSE: 4.3673624992370605\n",
      "train RMSE: 4.365368843078613\n",
      "train RMSE: 4.3633809089660645\n",
      "train RMSE: 4.361398696899414\n",
      "train RMSE: 4.359421253204346\n",
      "train RMSE: 4.357449531555176\n",
      "train RMSE: 4.355483055114746\n",
      "train RMSE: 4.353521823883057\n",
      "train RMSE: 4.351566314697266\n",
      "train RMSE: 4.349616050720215\n",
      "train RMSE: 4.347670555114746\n",
      "train RMSE: 4.345730781555176\n",
      "train RMSE: 4.343796253204346\n",
      "train RMSE: 4.341866970062256\n",
      "train RMSE: 4.339942932128906\n",
      "train RMSE: 4.338024139404297\n",
      "train RMSE: 4.336110591888428\n",
      "train RMSE: 4.334201812744141\n",
      "train RMSE: 4.332298755645752\n",
      "train RMSE: 4.3304009437561035\n",
      "train RMSE: 4.328508377075195\n",
      "train RMSE: 4.326620101928711\n",
      "train RMSE: 4.324738025665283\n",
      "train RMSE: 4.322860240936279\n",
      "train RMSE: 4.320987701416016\n",
      "train RMSE: 4.31912088394165\n",
      "train RMSE: 4.317258834838867\n",
      "train RMSE: 4.315401554107666\n",
      "train RMSE: 4.313549518585205\n",
      "train RMSE: 4.311702251434326\n",
      "train RMSE: 4.309860706329346\n",
      "train RMSE: 4.308023929595947\n",
      "train RMSE: 4.306191921234131\n",
      "train RMSE: 4.3043646812438965\n",
      "train RMSE: 4.302542686462402\n",
      "train RMSE: 4.300725936889648\n",
      "train RMSE: 4.298913955688477\n",
      "train RMSE: 4.2971062660217285\n",
      "train RMSE: 4.295304298400879\n",
      "train RMSE: 4.293506622314453\n",
      "train RMSE: 4.291714191436768\n",
      "train RMSE: 4.289926528930664\n",
      "train RMSE: 4.288144111633301\n",
      "train RMSE: 4.286365985870361\n",
      "train RMSE: 4.284593105316162\n",
      "train RMSE: 4.282824993133545\n",
      "train RMSE: 4.28106164932251\n",
      "train RMSE: 4.279303073883057\n",
      "train RMSE: 4.2775492668151855\n",
      "train RMSE: 4.2758002281188965\n",
      "train RMSE: 4.2740559577941895\n",
      "train RMSE: 4.2723164558410645\n",
      "train RMSE: 4.2705817222595215\n",
      "train RMSE: 4.268851280212402\n",
      "train RMSE: 4.267126083374023\n",
      "train RMSE: 4.265405654907227\n",
      "train RMSE: 4.263689994812012\n",
      "train RMSE: 4.2619781494140625\n",
      "train RMSE: 4.2602715492248535\n",
      "train RMSE: 4.258569717407227\n",
      "train RMSE: 4.256872177124023\n",
      "train RMSE: 4.255179405212402\n",
      "train RMSE: 4.253491401672363\n",
      "train RMSE: 4.251807689666748\n",
      "train RMSE: 4.250128269195557\n",
      "train RMSE: 4.2484540939331055\n",
      "train RMSE: 4.246784210205078\n",
      "train RMSE: 4.245119094848633\n",
      "train RMSE: 4.243458271026611\n",
      "train RMSE: 4.241801738739014\n",
      "train RMSE: 4.240149974822998\n",
      "train RMSE: 4.238502502441406\n",
      "train RMSE: 4.2368597984313965\n",
      "train RMSE: 4.2352213859558105\n",
      "train RMSE: 4.233587741851807\n",
      "train RMSE: 4.231957912445068\n",
      "train RMSE: 4.230332851409912\n",
      "train RMSE: 4.228712558746338\n",
      "train RMSE: 4.2270965576171875\n",
      "train RMSE: 4.225484371185303\n",
      "train RMSE: 4.223876953125\n",
      "train RMSE: 4.222274303436279\n",
      "train RMSE: 4.220675468444824\n",
      "train RMSE: 4.219080924987793\n",
      "train RMSE: 4.217491149902344\n",
      "train RMSE: 4.21590518951416\n",
      "train RMSE: 4.214323997497559\n",
      "train RMSE: 4.212747097015381\n",
      "train RMSE: 4.211174011230469\n",
      "train RMSE: 4.2096052169799805\n",
      "train RMSE: 4.208041667938232\n",
      "train RMSE: 4.206481456756592\n",
      "train RMSE: 4.204925537109375\n",
      "train RMSE: 4.203373908996582\n",
      "train RMSE: 4.201826572418213\n",
      "train RMSE: 4.200283527374268\n",
      "train RMSE: 4.198744297027588\n",
      "train RMSE: 4.19720983505249\n",
      "train RMSE: 4.195679187774658\n",
      "train RMSE: 4.19415283203125\n",
      "train RMSE: 4.192630767822266\n",
      "train RMSE: 4.191112041473389\n",
      "train RMSE: 4.189598560333252\n",
      "train RMSE: 4.188088417053223\n",
      "train RMSE: 4.186582565307617\n",
      "train RMSE: 4.1850810050964355\n",
      "train RMSE: 4.1835832595825195\n",
      "train RMSE: 4.182089805603027\n",
      "train RMSE: 4.180600166320801\n",
      "train RMSE: 4.179114818572998\n",
      "train RMSE: 4.177633285522461\n",
      "train RMSE: 4.1761555671691895\n",
      "train RMSE: 4.1746826171875\n",
      "train RMSE: 4.173213005065918\n",
      "train RMSE: 4.17174768447876\n",
      "train RMSE: 4.170286178588867\n",
      "train RMSE: 4.168828964233398\n",
      "train RMSE: 4.167375564575195\n",
      "train RMSE: 4.1659255027771\n",
      "train RMSE: 4.164480209350586\n",
      "train RMSE: 4.16303825378418\n",
      "train RMSE: 4.161600589752197\n",
      "train RMSE: 4.1601667404174805\n",
      "train RMSE: 4.158736705780029\n",
      "train RMSE: 4.157310485839844\n",
      "train RMSE: 4.155888080596924\n",
      "train RMSE: 4.154469966888428\n",
      "train RMSE: 4.153055191040039\n",
      "train RMSE: 4.151644706726074\n",
      "train RMSE: 4.150237560272217\n",
      "train RMSE: 4.148834705352783\n",
      "train RMSE: 4.147435188293457\n",
      "train RMSE: 4.146039962768555\n",
      "train RMSE: 4.14464807510376\n",
      "train RMSE: 4.1432600021362305\n",
      "train RMSE: 4.141875743865967\n",
      "train RMSE: 4.140495777130127\n",
      "train RMSE: 4.139118671417236\n",
      "train RMSE: 4.1377458572387695\n",
      "train RMSE: 4.13637638092041\n",
      "train RMSE: 4.135010719299316\n",
      "train RMSE: 4.1336493492126465\n",
      "train RMSE: 4.132290840148926\n",
      "train RMSE: 4.130936622619629\n",
      "train RMSE: 4.1295857429504395\n",
      "train RMSE: 4.128238677978516\n",
      "train RMSE: 4.126894950866699\n",
      "train RMSE: 4.125555038452148\n",
      "train RMSE: 4.124218940734863\n",
      "train RMSE: 4.1228861808776855\n",
      "train RMSE: 4.121557235717773\n",
      "train RMSE: 4.120231628417969\n",
      "train RMSE: 4.11890983581543\n",
      "train RMSE: 4.117591857910156\n",
      "train RMSE: 4.116276741027832\n",
      "train RMSE: 4.114965915679932\n",
      "train RMSE: 4.113658428192139\n",
      "train RMSE: 4.112353801727295\n",
      "train RMSE: 4.111053466796875\n",
      "train RMSE: 4.1097564697265625\n",
      "train RMSE: 4.108463287353516\n",
      "train RMSE: 4.107172966003418\n",
      "train RMSE: 4.105886459350586\n",
      "train RMSE: 4.104603290557861\n",
      "train RMSE: 4.103323459625244\n",
      "train RMSE: 4.102047443389893\n",
      "train RMSE: 4.100774765014648\n",
      "train RMSE: 4.099505424499512\n",
      "train RMSE: 4.098239898681641\n",
      "train RMSE: 4.096977233886719\n",
      "train RMSE: 4.0957183837890625\n",
      "train RMSE: 4.0944623947143555\n",
      "train RMSE: 4.093210220336914\n",
      "train RMSE: 4.091961860656738\n",
      "train RMSE: 4.0907158851623535\n",
      "train RMSE: 4.089473724365234\n",
      "train RMSE: 4.088234901428223\n",
      "train RMSE: 4.086999893188477\n",
      "train RMSE: 4.08576774597168\n",
      "train RMSE: 4.08453893661499\n",
      "train RMSE: 4.08331298828125\n",
      "train RMSE: 4.082090854644775\n",
      "train RMSE: 4.080872058868408\n",
      "train RMSE: 4.079656600952148\n",
      "train RMSE: 4.078444004058838\n",
      "train RMSE: 4.077235221862793\n",
      "train RMSE: 4.076029300689697\n",
      "train RMSE: 4.074826717376709\n",
      "train RMSE: 4.073627471923828\n",
      "train RMSE: 4.072431564331055\n",
      "train RMSE: 4.0712385177612305\n",
      "train RMSE: 4.070048809051514\n",
      "train RMSE: 4.068861961364746\n",
      "train RMSE: 4.067678928375244\n",
      "train RMSE: 4.06649923324585\n",
      "train RMSE: 4.065321922302246\n",
      "train RMSE: 4.064148426055908\n",
      "train RMSE: 4.0629777908325195\n",
      "train RMSE: 4.06181001663208\n",
      "train RMSE: 4.060646057128906\n",
      "train RMSE: 4.059484481811523\n",
      "train RMSE: 4.058326721191406\n",
      "train RMSE: 4.057171821594238\n",
      "train RMSE: 4.0560197830200195\n",
      "train RMSE: 4.054871082305908\n",
      "train RMSE: 4.053725242614746\n",
      "train RMSE: 4.052582740783691\n",
      "train RMSE: 4.051443099975586\n",
      "train RMSE: 4.050306797027588\n",
      "train RMSE: 4.049173355102539\n",
      "train RMSE: 4.0480427742004395\n",
      "train RMSE: 4.046915531158447\n",
      "train RMSE: 4.045791149139404\n",
      "train RMSE: 4.0446696281433105\n",
      "train RMSE: 4.043550968170166\n",
      "train RMSE: 4.042435646057129\n",
      "train RMSE: 4.041323184967041\n",
      "train RMSE: 4.0402140617370605\n",
      "train RMSE: 4.039107799530029\n",
      "train RMSE: 4.038003921508789\n",
      "train RMSE: 4.036903381347656\n",
      "train RMSE: 4.035806179046631\n",
      "train RMSE: 4.0347113609313965\n",
      "train RMSE: 4.033619403839111\n",
      "train RMSE: 4.032530784606934\n",
      "train RMSE: 4.031445026397705\n",
      "train RMSE: 4.030362129211426\n",
      "train RMSE: 4.0292816162109375\n",
      "train RMSE: 4.028204441070557\n",
      "train RMSE: 4.027130126953125\n",
      "train RMSE: 4.026058673858643\n",
      "train RMSE: 4.024990081787109\n",
      "train RMSE: 4.023924350738525\n",
      "train RMSE: 4.022861480712891\n",
      "train RMSE: 4.021800994873047\n",
      "train RMSE: 4.0207438468933105\n",
      "train RMSE: 4.019689559936523\n",
      "train RMSE: 4.0186381340026855\n",
      "train RMSE: 4.017589092254639\n",
      "train RMSE: 4.016543388366699\n",
      "train RMSE: 4.015500068664551\n",
      "train RMSE: 4.014459609985352\n",
      "train RMSE: 4.013421535491943\n",
      "train RMSE: 4.012386798858643\n",
      "train RMSE: 4.011354446411133\n",
      "train RMSE: 4.010324954986572\n",
      "train RMSE: 4.009297847747803\n",
      "train RMSE: 4.008274078369141\n",
      "train RMSE: 4.0072526931762695\n",
      "train RMSE: 4.006234169006348\n",
      "train RMSE: 4.005218505859375\n",
      "train RMSE: 4.004205226898193\n",
      "train RMSE: 4.003194808959961\n",
      "train RMSE: 4.002187252044678\n",
      "train RMSE: 4.0011820793151855\n",
      "train RMSE: 4.000179290771484\n",
      "train RMSE: 3.9991796016693115\n",
      "train RMSE: 3.9981822967529297\n",
      "train RMSE: 3.997187614440918\n",
      "train RMSE: 3.9961957931518555\n",
      "train RMSE: 3.995206356048584\n",
      "train RMSE: 3.994220018386841\n",
      "train RMSE: 3.9932358264923096\n",
      "train RMSE: 3.9922544956207275\n",
      "train RMSE: 3.9912755489349365\n",
      "train RMSE: 3.9902992248535156\n",
      "train RMSE: 3.989325523376465\n",
      "train RMSE: 3.988354444503784\n",
      "train RMSE: 3.9873859882354736\n",
      "train RMSE: 3.986419916152954\n",
      "train RMSE: 3.9854564666748047\n",
      "train RMSE: 3.984495162963867\n",
      "train RMSE: 3.983536720275879\n",
      "train RMSE: 3.98258113861084\n",
      "train RMSE: 3.9816277027130127\n",
      "train RMSE: 3.9806766510009766\n",
      "train RMSE: 3.9797284603118896\n",
      "train RMSE: 3.9787826538085938\n",
      "train RMSE: 3.977839469909668\n",
      "train RMSE: 3.976898431777954\n",
      "train RMSE: 3.9759600162506104\n",
      "train RMSE: 3.9750239849090576\n",
      "train RMSE: 3.974090576171875\n",
      "train RMSE: 3.9731595516204834\n",
      "train RMSE: 3.972230911254883\n",
      "train RMSE: 3.9713046550750732\n",
      "train RMSE: 3.970381021499634\n",
      "train RMSE: 3.9694595336914062\n",
      "train RMSE: 3.968540668487549\n",
      "train RMSE: 3.9676241874694824\n",
      "train RMSE: 3.966710090637207\n",
      "train RMSE: 3.9657983779907227\n",
      "train RMSE: 3.96488881111145\n",
      "train RMSE: 3.963981866836548\n",
      "train RMSE: 3.9630773067474365\n",
      "train RMSE: 3.962175130844116\n",
      "train RMSE: 3.961275339126587\n",
      "train RMSE: 3.9603776931762695\n",
      "train RMSE: 3.9594826698303223\n",
      "train RMSE: 3.958589792251587\n",
      "train RMSE: 3.9576992988586426\n",
      "train RMSE: 3.9568111896514893\n",
      "train RMSE: 3.955925226211548\n",
      "train RMSE: 3.9550414085388184\n",
      "train RMSE: 3.954160213470459\n",
      "train RMSE: 3.9532811641693115\n",
      "train RMSE: 3.952404737472534\n",
      "train RMSE: 3.9515302181243896\n",
      "train RMSE: 3.950658082962036\n",
      "train RMSE: 3.9497880935668945\n",
      "train RMSE: 3.948920249938965\n",
      "train RMSE: 3.948054790496826\n",
      "train RMSE: 3.9471917152404785\n",
      "train RMSE: 3.9463307857513428\n",
      "train RMSE: 3.945472002029419\n",
      "train RMSE: 3.9446158409118652\n",
      "train RMSE: 3.9437613487243652\n",
      "train RMSE: 3.9429092407226562\n",
      "train RMSE: 3.942059278488159\n",
      "train RMSE: 3.941211700439453\n",
      "train RMSE: 3.940366506576538\n",
      "train RMSE: 3.9395229816436768\n",
      "train RMSE: 3.9386818408966064\n",
      "train RMSE: 3.937842845916748\n",
      "train RMSE: 3.9370062351226807\n",
      "train RMSE: 3.936171531677246\n",
      "train RMSE: 3.9353389739990234\n",
      "train RMSE: 3.934508800506592\n",
      "train RMSE: 3.933680295944214\n",
      "train RMSE: 3.932854413986206\n",
      "train RMSE: 3.932030200958252\n",
      "train RMSE: 3.931208372116089\n",
      "train RMSE: 3.9303886890411377\n",
      "train RMSE: 3.9295709133148193\n",
      "train RMSE: 3.928755521774292\n",
      "train RMSE: 3.9279420375823975\n",
      "train RMSE: 3.927130699157715\n",
      "train RMSE: 3.926321268081665\n",
      "train RMSE: 3.9255142211914062\n",
      "train RMSE: 3.924708604812622\n",
      "train RMSE: 3.923905611038208\n",
      "train RMSE: 3.9231045246124268\n",
      "train RMSE: 3.9223055839538574\n",
      "train RMSE: 3.921508550643921\n",
      "train RMSE: 3.9207136631011963\n",
      "train RMSE: 3.9199206829071045\n",
      "train RMSE: 3.9191296100616455\n",
      "train RMSE: 3.9183406829833984\n",
      "train RMSE: 3.917553663253784\n",
      "train RMSE: 3.916768789291382\n",
      "train RMSE: 3.915985584259033\n",
      "train RMSE: 3.9152047634124756\n",
      "train RMSE: 3.9144256114959717\n",
      "train RMSE: 3.913648843765259\n",
      "train RMSE: 3.9128737449645996\n",
      "train RMSE: 3.9121005535125732\n",
      "train RMSE: 3.911329507827759\n",
      "train RMSE: 3.910560131072998\n",
      "train RMSE: 3.909792900085449\n",
      "train RMSE: 3.909027576446533\n",
      "train RMSE: 3.908263921737671\n",
      "train RMSE: 3.9075026512145996\n",
      "train RMSE: 3.906743049621582\n",
      "train RMSE: 3.9059853553771973\n",
      "train RMSE: 3.9052295684814453\n",
      "train RMSE: 3.904475688934326\n",
      "train RMSE: 3.90372371673584\n",
      "train RMSE: 3.9029736518859863\n",
      "train RMSE: 3.9022252559661865\n",
      "train RMSE: 3.9014790058135986\n",
      "train RMSE: 3.9007344245910645\n",
      "train RMSE: 3.899991989135742\n",
      "train RMSE: 3.8992509841918945\n",
      "train RMSE: 3.898512125015259\n",
      "train RMSE: 3.8977749347686768\n",
      "train RMSE: 3.8970396518707275\n",
      "train RMSE: 3.896306276321411\n",
      "train RMSE: 3.8955748081207275\n",
      "train RMSE: 3.8948450088500977\n",
      "train RMSE: 3.8941168785095215\n",
      "train RMSE: 3.8933908939361572\n",
      "train RMSE: 3.8926665782928467\n",
      "train RMSE: 3.89194393157959\n",
      "train RMSE: 3.8912229537963867\n",
      "train RMSE: 3.8905041217803955\n",
      "train RMSE: 3.889786958694458\n",
      "train RMSE: 3.889071464538574\n",
      "train RMSE: 3.888357639312744\n",
      "train RMSE: 3.887645721435547\n",
      "train RMSE: 3.8869357109069824\n",
      "train RMSE: 3.8862268924713135\n",
      "train RMSE: 3.8855202198028564\n",
      "train RMSE: 3.884814977645874\n",
      "train RMSE: 3.8841121196746826\n",
      "train RMSE: 3.8834104537963867\n",
      "train RMSE: 3.8827104568481445\n",
      "train RMSE: 3.8820126056671143\n",
      "train RMSE: 3.8813159465789795\n",
      "train RMSE: 3.8806211948394775\n",
      "train RMSE: 3.8799283504486084\n",
      "train RMSE: 3.879236936569214\n",
      "train RMSE: 3.878547430038452\n",
      "train RMSE: 3.877859354019165\n",
      "train RMSE: 3.8771731853485107\n",
      "train RMSE: 3.876488447189331\n",
      "train RMSE: 3.875805377960205\n",
      "train RMSE: 3.875124216079712\n",
      "train RMSE: 3.8744442462921143\n",
      "train RMSE: 3.8737661838531494\n",
      "train RMSE: 3.8730897903442383\n",
      "train RMSE: 3.87241530418396\n",
      "train RMSE: 3.871742010116577\n",
      "train RMSE: 3.871070623397827\n",
      "train RMSE: 3.8704004287719727\n",
      "train RMSE: 3.869732141494751\n",
      "train RMSE: 3.869065284729004\n",
      "train RMSE: 3.8684003353118896\n",
      "train RMSE: 3.86773681640625\n",
      "train RMSE: 3.867074966430664\n",
      "train RMSE: 3.866414785385132\n",
      "train RMSE: 3.865755796432495\n",
      "train RMSE: 3.865098476409912\n",
      "train RMSE: 3.864442825317383\n",
      "train RMSE: 3.8637888431549072\n",
      "train RMSE: 3.8631362915039062\n",
      "train RMSE: 3.86248517036438\n",
      "train RMSE: 3.8618357181549072\n",
      "train RMSE: 3.8611879348754883\n",
      "train RMSE: 3.860541582107544\n",
      "train RMSE: 3.859896421432495\n",
      "train RMSE: 3.859253406524658\n",
      "train RMSE: 3.8586113452911377\n",
      "train RMSE: 3.857970952987671\n",
      "train RMSE: 3.857332229614258\n",
      "train RMSE: 3.8566951751708984\n",
      "train RMSE: 3.8560588359832764\n",
      "train RMSE: 3.855424642562866\n",
      "train RMSE: 3.8547918796539307\n",
      "train RMSE: 3.8541605472564697\n",
      "train RMSE: 3.8535306453704834\n",
      "train RMSE: 3.8529021739959717\n",
      "train RMSE: 3.8522751331329346\n",
      "train RMSE: 3.851649522781372\n",
      "train RMSE: 3.851025342941284\n",
      "train RMSE: 3.85040283203125\n",
      "train RMSE: 3.8497815132141113\n",
      "train RMSE: 3.8491618633270264\n",
      "train RMSE: 3.848543405532837\n",
      "train RMSE: 3.847926378250122\n",
      "train RMSE: 3.847310781478882\n",
      "train RMSE: 3.8466968536376953\n",
      "train RMSE: 3.8460841178894043\n",
      "train RMSE: 3.845473051071167\n",
      "train RMSE: 3.844862937927246\n",
      "train RMSE: 3.844254493713379\n",
      "train RMSE: 3.8436472415924072\n",
      "train RMSE: 3.8430416584014893\n",
      "train RMSE: 3.8424370288848877\n",
      "train RMSE: 3.841834306716919\n",
      "train RMSE: 3.8412325382232666\n",
      "train RMSE: 3.840632200241089\n",
      "train RMSE: 3.8400332927703857\n",
      "train RMSE: 3.8394358158111572\n",
      "train RMSE: 3.8388397693634033\n",
      "train RMSE: 3.838244915008545\n",
      "train RMSE: 3.837651014328003\n",
      "train RMSE: 3.8370590209960938\n",
      "train RMSE: 3.836467981338501\n",
      "train RMSE: 3.835878610610962\n",
      "train RMSE: 3.8352901935577393\n",
      "train RMSE: 3.834703207015991\n",
      "train RMSE: 3.834117889404297\n",
      "train RMSE: 3.83353328704834\n",
      "train RMSE: 3.8329503536224365\n",
      "train RMSE: 3.8323683738708496\n",
      "train RMSE: 3.8317880630493164\n",
      "train RMSE: 3.8312087059020996\n",
      "train RMSE: 3.8306307792663574\n",
      "train RMSE: 3.83005428314209\n",
      "train RMSE: 3.8294789791107178\n",
      "train RMSE: 3.828904628753662\n",
      "train RMSE: 3.82833194732666\n",
      "train RMSE: 3.8277599811553955\n",
      "train RMSE: 3.8271896839141846\n",
      "train RMSE: 3.826620578765869\n",
      "train RMSE: 3.8260529041290283\n",
      "train RMSE: 3.825485944747925\n",
      "train RMSE: 3.824920415878296\n",
      "train RMSE: 3.8243560791015625\n",
      "train RMSE: 3.8237929344177246\n",
      "train RMSE: 3.8232312202453613\n",
      "train RMSE: 3.8226706981658936\n",
      "train RMSE: 3.822111129760742\n",
      "train RMSE: 3.8215529918670654\n",
      "train RMSE: 3.8209962844848633\n",
      "train RMSE: 3.8204400539398193\n",
      "train RMSE: 3.819885492324829\n",
      "train RMSE: 3.8193318843841553\n",
      "train RMSE: 3.818779468536377\n",
      "train RMSE: 3.8182284832000732\n",
      "train RMSE: 3.817678451538086\n",
      "train RMSE: 3.817129373550415\n",
      "train RMSE: 3.8165817260742188\n",
      "train RMSE: 3.816035032272339\n",
      "train RMSE: 3.8154897689819336\n",
      "train RMSE: 3.8149454593658447\n",
      "train RMSE: 3.8144023418426514\n",
      "train RMSE: 3.8138604164123535\n",
      "train RMSE: 3.813319444656372\n",
      "train RMSE: 3.812779664993286\n",
      "train RMSE: 3.8122410774230957\n",
      "train RMSE: 3.8117034435272217\n",
      "train RMSE: 3.811166763305664\n",
      "train RMSE: 3.810631513595581\n",
      "train RMSE: 3.8100972175598145\n",
      "train RMSE: 3.8095638751983643\n",
      "train RMSE: 3.8090319633483887\n",
      "train RMSE: 3.8085007667541504\n",
      "train RMSE: 3.8079707622528076\n",
      "train RMSE: 3.8074421882629395\n",
      "train RMSE: 3.8069140911102295\n",
      "train RMSE: 3.806387186050415\n",
      "train RMSE: 3.805861473083496\n",
      "train RMSE: 3.8053369522094727\n",
      "train RMSE: 3.8048133850097656\n",
      "train RMSE: 3.804290771484375\n",
      "train RMSE: 3.803769111633301\n",
      "train RMSE: 3.803248643875122\n",
      "train RMSE: 3.8027288913726807\n",
      "train RMSE: 3.802210807800293\n",
      "train RMSE: 3.8016932010650635\n",
      "train RMSE: 3.8011767864227295\n",
      "train RMSE: 3.800661325454712\n",
      "train RMSE: 3.8001468181610107\n",
      "train RMSE: 3.799633026123047\n",
      "train RMSE: 3.7991206645965576\n",
      "train RMSE: 3.7986092567443848\n",
      "train RMSE: 3.7980990409851074\n",
      "train RMSE: 3.7975893020629883\n",
      "train RMSE: 3.7970807552337646\n",
      "train RMSE: 3.7965731620788574\n",
      "train RMSE: 3.7960665225982666\n",
      "train RMSE: 3.7955610752105713\n",
      "train RMSE: 3.7950563430786133\n",
      "train RMSE: 3.7945523262023926\n",
      "train RMSE: 3.7940497398376465\n",
      "train RMSE: 3.7935478687286377\n",
      "train RMSE: 3.7930469512939453\n",
      "train RMSE: 3.7925469875335693\n",
      "train RMSE: 3.7920479774475098\n",
      "train RMSE: 3.7915496826171875\n",
      "train RMSE: 3.7910525798797607\n",
      "train RMSE: 3.7905564308166504\n",
      "train RMSE: 3.7900609970092773\n",
      "train RMSE: 3.7895665168762207\n",
      "train RMSE: 3.7890727519989014\n",
      "train RMSE: 3.7885799407958984\n",
      "train RMSE: 3.788088321685791\n",
      "train RMSE: 3.787597417831421\n",
      "train RMSE: 3.787107467651367\n",
      "train RMSE: 3.786618232727051\n",
      "train RMSE: 3.786129951477051\n",
      "train RMSE: 3.785642385482788\n",
      "train RMSE: 3.785156011581421\n",
      "train RMSE: 3.784670114517212\n",
      "train RMSE: 3.7841854095458984\n",
      "train RMSE: 3.7837014198303223\n",
      "train RMSE: 3.7832181453704834\n",
      "train RMSE: 3.782735824584961\n",
      "train RMSE: 3.782254457473755\n",
      "train RMSE: 3.781773567199707\n",
      "train RMSE: 3.781294107437134\n",
      "train RMSE: 3.7808151245117188\n",
      "train RMSE: 3.780336856842041\n",
      "train RMSE: 3.7798595428466797\n",
      "train RMSE: 3.7793829441070557\n",
      "train RMSE: 3.778907299041748\n",
      "train RMSE: 3.7784323692321777\n",
      "train RMSE: 3.7779581546783447\n",
      "train RMSE: 3.777484893798828\n",
      "train RMSE: 3.777012348175049\n",
      "train RMSE: 3.776540517807007\n",
      "train RMSE: 3.776069402694702\n",
      "train RMSE: 3.7755990028381348\n",
      "train RMSE: 3.775129556655884\n",
      "train RMSE: 3.77466082572937\n",
      "train RMSE: 3.774193048477173\n",
      "train RMSE: 3.773725748062134\n",
      "train RMSE: 3.773259401321411\n",
      "train RMSE: 3.7727935314178467\n",
      "train RMSE: 3.7723288536071777\n",
      "train RMSE: 3.771864652633667\n",
      "train RMSE: 3.7714009284973145\n",
      "train RMSE: 3.7709381580352783\n",
      "train RMSE: 3.7704761028289795\n",
      "train RMSE: 3.770014762878418\n",
      "train RMSE: 3.769554376602173\n",
      "train RMSE: 3.769094467163086\n",
      "train RMSE: 3.7686352729797363\n",
      "train RMSE: 3.768176794052124\n",
      "train RMSE: 3.767719030380249\n",
      "train RMSE: 3.7672617435455322\n",
      "train RMSE: 3.7668051719665527\n",
      "train RMSE: 3.7663497924804688\n",
      "train RMSE: 3.765894651412964\n",
      "train RMSE: 3.7654402256011963\n",
      "train RMSE: 3.764986515045166\n",
      "train RMSE: 3.764533519744873\n",
      "train RMSE: 3.7640810012817383\n",
      "train RMSE: 3.763629198074341\n",
      "train RMSE: 3.7631783485412598\n",
      "train RMSE: 3.762727975845337\n",
      "train RMSE: 3.7622783184051514\n",
      "train RMSE: 3.761829137802124\n",
      "train RMSE: 3.761380434036255\n",
      "train RMSE: 3.760932445526123\n",
      "train RMSE: 3.7604854106903076\n",
      "train RMSE: 3.7600388526916504\n",
      "train RMSE: 3.7595925331115723\n",
      "train RMSE: 3.7591474056243896\n",
      "train RMSE: 3.758702516555786\n",
      "train RMSE: 3.75825834274292\n",
      "train RMSE: 3.757814884185791\n",
      "train RMSE: 3.757371664047241\n",
      "train RMSE: 3.756929397583008\n",
      "train RMSE: 3.7564876079559326\n",
      "train RMSE: 3.7560462951660156\n",
      "train RMSE: 3.755605459213257\n",
      "train RMSE: 3.7551655769348145\n",
      "train RMSE: 3.7547261714935303\n",
      "train RMSE: 3.754287004470825\n",
      "train RMSE: 3.7538485527038574\n",
      "train RMSE: 3.753410577774048\n",
      "train RMSE: 3.7529735565185547\n",
      "train RMSE: 3.7525365352630615\n",
      "train RMSE: 3.752100706100464\n",
      "train RMSE: 3.751664638519287\n",
      "train RMSE: 3.751229763031006\n",
      "train RMSE: 3.7507948875427246\n",
      "train RMSE: 3.7503609657287598\n",
      "train RMSE: 3.749927282333374\n",
      "train RMSE: 3.7494945526123047\n",
      "train RMSE: 3.7490620613098145\n",
      "train RMSE: 3.7486298084259033\n",
      "train RMSE: 3.7481982707977295\n",
      "train RMSE: 3.747767210006714\n",
      "train RMSE: 3.7473368644714355\n",
      "train RMSE: 3.7469065189361572\n",
      "train RMSE: 3.746476888656616\n",
      "train RMSE: 3.7460479736328125\n",
      "train RMSE: 3.745619297027588\n",
      "train RMSE: 3.7451910972595215\n",
      "train RMSE: 3.7447633743286133\n",
      "train RMSE: 3.7443361282348633\n",
      "train RMSE: 3.7439095973968506\n",
      "train RMSE: 3.743483304977417\n",
      "train RMSE: 3.7430572509765625\n",
      "train RMSE: 3.7426319122314453\n",
      "train RMSE: 3.7422068119049072\n",
      "train RMSE: 3.7417826652526855\n",
      "train RMSE: 3.7413582801818848\n",
      "train RMSE: 3.740934371948242\n",
      "train RMSE: 3.740511178970337\n",
      "train RMSE: 3.74008846282959\n",
      "train RMSE: 3.7396657466888428\n",
      "train RMSE: 3.739244222640991\n",
      "train RMSE: 3.7388222217559814\n",
      "train RMSE: 3.738401174545288\n",
      "train RMSE: 3.737980365753174\n",
      "train RMSE: 3.7375597953796387\n",
      "train RMSE: 3.737139940261841\n",
      "train RMSE: 3.736720085144043\n",
      "train RMSE: 3.7363007068634033\n",
      "train RMSE: 3.735882043838501\n",
      "train RMSE: 3.7354633808135986\n",
      "train RMSE: 3.7350451946258545\n",
      "train RMSE: 3.7346272468566895\n",
      "train RMSE: 3.7342097759246826\n",
      "train RMSE: 3.733792781829834\n",
      "train RMSE: 3.7333757877349854\n",
      "train RMSE: 3.732959270477295\n",
      "CPU times: total: 37.7 s\n",
      "Wall time: 4.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_epocs(train, model, epochs=1000, lr=0.001, reg=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# halpful links:\n",
    "# https://d2l.ai/chapter_recommender-systems/autorec.html\n",
    "# https://github.com/gtshs2/Autorec\n",
    "# https://github.com/ImKeTT/Recommend_algorithms_Librec2Python/blob/master/AutoRec_torch/src/model.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "item_id  1     2     3     4     5     6     7     8     9     10    ...  \\\nuser_id                                                              ...   \n1         5.0   3.0   4.0   3.0   3.0   0.0   4.0   1.0   5.0   0.0  ...   \n2         4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  ...   \n3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n939       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   5.0   0.0  ...   \n940       0.0   0.0   0.0   2.0   0.0   0.0   4.0   5.0   3.0   0.0  ...   \n941       5.0   0.0   0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0  ...   \n942       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n943       0.0   5.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0   0.0  ...   \n\nitem_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \nuser_id                                                              \n1         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n2         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n939       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n940       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n941       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n942       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n943       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n\n[943 rows x 1650 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>item_id</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>1673</th>\n      <th>1674</th>\n      <th>1675</th>\n      <th>1676</th>\n      <th>1677</th>\n      <th>1678</th>\n      <th>1679</th>\n      <th>1680</th>\n      <th>1681</th>\n      <th>1682</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>939</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>940</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>941</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>942</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>943</th>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>943 rows Ã— 1650 columns</p>\n</div>"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data_prep import movielens_prep\n",
    "train, test = movielens_prep(1)\n",
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "class AutoRec(nn.Module):\n",
    "    \"\"\"\n",
    "    AutoRec model. See explanation on :param: num_features for use as USER TO USER or ITEM TO ITEM\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features, num_hidden=500):\n",
    "        \"\"\"\n",
    "        :param num_hidden: Size of the hidden layer\n",
    "        :param num_features: If num_features == num_items that means that we are doing USER TO USER model.\n",
    "                             If num_features == num_users that means that we are doing ITEM TO ITEM model.\n",
    "                             The logic is the a user vector has number of items features for it.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_features, num_hidden),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(num_hidden, num_features),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "num_items = train.shape[1]\n",
    "model = AutoRec(num_hidden=500, num_features=num_items).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "data": {
      "text/plain": "item_id  1     2     3     4     5     6     7     8     9     10    ...  \\\nuser_id                                                              ...   \n1         5.0   3.0   4.0   3.0   3.0   0.0   4.0   1.0   5.0   0.0  ...   \n2         4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  ...   \n3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n939       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   5.0   0.0  ...   \n940       0.0   0.0   0.0   2.0   0.0   0.0   4.0   5.0   3.0   0.0  ...   \n941       5.0   0.0   0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0  ...   \n942       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n943       0.0   5.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0   0.0  ...   \n\nitem_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \nuser_id                                                              \n1         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n2         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n939       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n940       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n941       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n942       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n943       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n\n[943 rows x 1650 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>item_id</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>1673</th>\n      <th>1674</th>\n      <th>1675</th>\n      <th>1676</th>\n      <th>1677</th>\n      <th>1678</th>\n      <th>1679</th>\n      <th>1680</th>\n      <th>1681</th>\n      <th>1682</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>939</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>940</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>941</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>942</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>943</th>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>943 rows Ã— 1650 columns</p>\n</div>"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train RMSE: 0.6633583903312683\n",
      "epoch: 2 train RMSE: 0.6633725762367249\n",
      "epoch: 3 train RMSE: 0.6633778214454651\n",
      "epoch: 4 train RMSE: 0.6633684635162354\n",
      "epoch: 5 train RMSE: 0.6633650064468384\n",
      "epoch: 6 train RMSE: 0.6633610129356384\n",
      "epoch: 7 train RMSE: 0.663355827331543\n",
      "epoch: 8 train RMSE: 0.663353681564331\n",
      "epoch: 9 train RMSE: 0.6633505821228027\n",
      "epoch: 10 train RMSE: 0.6633493900299072\n",
      "epoch: 11 train RMSE: 0.663348913192749\n",
      "epoch: 12 train RMSE: 0.6633484363555908\n",
      "epoch: 13 train RMSE: 0.6633481979370117\n",
      "epoch: 14 train RMSE: 0.6633477807044983\n",
      "epoch: 15 train RMSE: 0.663347601890564\n",
      "epoch: 16 train RMSE: 0.6633474230766296\n",
      "epoch: 17 train RMSE: 0.6633473038673401\n",
      "epoch: 18 train RMSE: 0.6633472442626953\n",
      "epoch: 19 train RMSE: 0.6633471250534058\n",
      "epoch: 20 train RMSE: 0.6633470058441162\n",
      "epoch: 21 train RMSE: 0.6633468866348267\n",
      "epoch: 22 train RMSE: 0.6633468270301819\n",
      "epoch: 23 train RMSE: 0.6633468270301819\n",
      "epoch: 24 train RMSE: 0.6633469462394714\n",
      "epoch: 25 train RMSE: 0.6633468866348267\n",
      "epoch: 26 train RMSE: 0.6633467078208923\n",
      "epoch: 27 train RMSE: 0.6633465886116028\n",
      "epoch: 28 train RMSE: 0.6633464694023132\n",
      "epoch: 29 train RMSE: 0.6633464694023132\n",
      "epoch: 30 train RMSE: 0.6633464097976685\n",
      "epoch: 31 train RMSE: 0.6633464097976685\n",
      "epoch: 32 train RMSE: 0.6633462905883789\n",
      "epoch: 33 train RMSE: 0.6633462309837341\n",
      "epoch: 34 train RMSE: 0.6633462309837341\n",
      "epoch: 35 train RMSE: 0.6633461713790894\n",
      "epoch: 36 train RMSE: 0.6633461713790894\n",
      "epoch: 37 train RMSE: 0.6633460521697998\n",
      "epoch: 38 train RMSE: 0.6633461117744446\n",
      "epoch: 39 train RMSE: 0.6633460521697998\n",
      "epoch: 40 train RMSE: 0.663345992565155\n",
      "epoch: 41 train RMSE: 0.663345992565155\n",
      "epoch: 42 train RMSE: 0.6633459329605103\n",
      "epoch: 43 train RMSE: 0.6633459329605103\n",
      "epoch: 44 train RMSE: 0.6633459329605103\n",
      "epoch: 45 train RMSE: 0.6633458733558655\n",
      "epoch: 46 train RMSE: 0.6633458733558655\n",
      "epoch: 47 train RMSE: 0.6633458733558655\n",
      "epoch: 48 train RMSE: 0.6633458733558655\n",
      "epoch: 49 train RMSE: 0.6633458733558655\n",
      "epoch: 50 train RMSE: 0.6633459329605103\n",
      "epoch: 51 train RMSE: 0.6633457541465759\n",
      "epoch: 52 train RMSE: 0.6633457541465759\n",
      "epoch: 53 train RMSE: 0.6633456945419312\n",
      "epoch: 54 train RMSE: 0.6633456945419312\n",
      "epoch: 55 train RMSE: 0.6633456945419312\n",
      "epoch: 56 train RMSE: 0.6633456945419312\n",
      "epoch: 57 train RMSE: 0.6633478403091431\n",
      "epoch: 58 train RMSE: 0.6633495688438416\n",
      "epoch: 59 train RMSE: 0.6633707880973816\n",
      "epoch: 60 train RMSE: 0.6634261608123779\n",
      "epoch: 61 train RMSE: 0.6642957329750061\n",
      "epoch: 62 train RMSE: 0.6652633547782898\n",
      "epoch: 63 train RMSE: 0.6665780544281006\n",
      "epoch: 64 train RMSE: 0.6663634181022644\n",
      "epoch: 65 train RMSE: 0.666147768497467\n",
      "epoch: 66 train RMSE: 0.666046142578125\n",
      "epoch: 67 train RMSE: 0.6650715470314026\n",
      "epoch: 68 train RMSE: 0.6639593243598938\n",
      "epoch: 69 train RMSE: 0.6635816693305969\n",
      "epoch: 70 train RMSE: 0.6634069085121155\n",
      "epoch: 71 train RMSE: 0.6633663773536682\n",
      "epoch: 72 train RMSE: 0.6633477807044983\n",
      "epoch: 73 train RMSE: 0.6633402109146118\n",
      "epoch: 74 train RMSE: 0.6633329391479492\n",
      "epoch: 75 train RMSE: 0.6633315086364746\n",
      "epoch: 76 train RMSE: 0.6633304953575134\n",
      "epoch: 77 train RMSE: 0.6633296012878418\n",
      "epoch: 78 train RMSE: 0.6633287668228149\n",
      "epoch: 79 train RMSE: 0.6633281111717224\n",
      "epoch: 80 train RMSE: 0.6633275151252747\n",
      "epoch: 81 train RMSE: 0.6633270978927612\n",
      "epoch: 82 train RMSE: 0.663326621055603\n",
      "epoch: 83 train RMSE: 0.6633262038230896\n",
      "epoch: 84 train RMSE: 0.6633259057998657\n",
      "epoch: 85 train RMSE: 0.6633255481719971\n",
      "epoch: 86 train RMSE: 0.6633252501487732\n",
      "epoch: 87 train RMSE: 0.6633249521255493\n",
      "epoch: 88 train RMSE: 0.6633247137069702\n",
      "epoch: 89 train RMSE: 0.6633244752883911\n",
      "epoch: 90 train RMSE: 0.663324236869812\n",
      "epoch: 91 train RMSE: 0.6633240580558777\n",
      "epoch: 92 train RMSE: 0.6633238792419434\n",
      "epoch: 93 train RMSE: 0.6633238792419434\n",
      "epoch: 94 train RMSE: 0.6633235812187195\n",
      "epoch: 95 train RMSE: 0.6633234024047852\n",
      "epoch: 96 train RMSE: 0.6633232235908508\n",
      "epoch: 97 train RMSE: 0.6633230447769165\n",
      "epoch: 98 train RMSE: 0.663322925567627\n",
      "epoch: 99 train RMSE: 0.6633227467536926\n",
      "epoch: 100 train RMSE: 0.6633226275444031\n",
      "epoch: 101 train RMSE: 0.6633225083351135\n",
      "epoch: 102 train RMSE: 0.663322389125824\n",
      "epoch: 103 train RMSE: 0.6633223295211792\n",
      "epoch: 104 train RMSE: 0.6633222103118896\n",
      "epoch: 105 train RMSE: 0.6633220911026001\n",
      "epoch: 106 train RMSE: 0.6633220314979553\n",
      "epoch: 107 train RMSE: 0.663321852684021\n",
      "epoch: 108 train RMSE: 0.6633217930793762\n",
      "epoch: 109 train RMSE: 0.6633216142654419\n",
      "epoch: 110 train RMSE: 0.6633215546607971\n",
      "epoch: 111 train RMSE: 0.6633214950561523\n",
      "epoch: 112 train RMSE: 0.6633214354515076\n",
      "epoch: 113 train RMSE: 0.663321316242218\n",
      "epoch: 114 train RMSE: 0.6633212566375732\n",
      "epoch: 115 train RMSE: 0.6633211374282837\n",
      "epoch: 116 train RMSE: 0.6633210778236389\n",
      "epoch: 117 train RMSE: 0.6633210182189941\n",
      "epoch: 118 train RMSE: 0.6633209586143494\n",
      "epoch: 119 train RMSE: 0.6633208394050598\n",
      "epoch: 120 train RMSE: 0.6633208394050598\n",
      "epoch: 121 train RMSE: 0.663320779800415\n",
      "epoch: 122 train RMSE: 0.663320779800415\n",
      "epoch: 123 train RMSE: 0.663320779800415\n",
      "epoch: 124 train RMSE: 0.6633207201957703\n",
      "epoch: 125 train RMSE: 0.6633206605911255\n",
      "epoch: 126 train RMSE: 0.6633205413818359\n",
      "epoch: 127 train RMSE: 0.6633204817771912\n",
      "epoch: 128 train RMSE: 0.6633204221725464\n",
      "epoch: 129 train RMSE: 0.6633203625679016\n",
      "epoch: 130 train RMSE: 0.6633203029632568\n",
      "epoch: 131 train RMSE: 0.6633202433586121\n",
      "epoch: 132 train RMSE: 0.6633201837539673\n",
      "epoch: 133 train RMSE: 0.6633201241493225\n",
      "epoch: 134 train RMSE: 0.6633201241493225\n",
      "epoch: 135 train RMSE: 0.6633200645446777\n",
      "epoch: 136 train RMSE: 0.6633199453353882\n",
      "epoch: 137 train RMSE: 0.6633199453353882\n",
      "epoch: 138 train RMSE: 0.6633198857307434\n",
      "epoch: 139 train RMSE: 0.6633198857307434\n",
      "epoch: 140 train RMSE: 0.6633198261260986\n",
      "epoch: 141 train RMSE: 0.6633197069168091\n",
      "epoch: 142 train RMSE: 0.6633197069168091\n",
      "epoch: 143 train RMSE: 0.6633196473121643\n",
      "epoch: 144 train RMSE: 0.6633196473121643\n",
      "epoch: 145 train RMSE: 0.6633195877075195\n",
      "epoch: 146 train RMSE: 0.6633197069168091\n",
      "epoch: 147 train RMSE: 0.6633195877075195\n",
      "epoch: 148 train RMSE: 0.66331946849823\n",
      "epoch: 149 train RMSE: 0.66331946849823\n",
      "epoch: 150 train RMSE: 0.66331946849823\n",
      "epoch: 151 train RMSE: 0.6633194088935852\n",
      "epoch: 152 train RMSE: 0.6633193492889404\n",
      "epoch: 153 train RMSE: 0.6633192896842957\n",
      "epoch: 154 train RMSE: 0.6633192896842957\n",
      "epoch: 155 train RMSE: 0.6633192300796509\n",
      "epoch: 156 train RMSE: 0.6633192300796509\n",
      "epoch: 157 train RMSE: 0.6633191108703613\n",
      "epoch: 158 train RMSE: 0.6633191108703613\n",
      "epoch: 159 train RMSE: 0.6633190512657166\n",
      "epoch: 160 train RMSE: 0.6633190512657166\n",
      "epoch: 161 train RMSE: 0.6633189916610718\n",
      "epoch: 162 train RMSE: 0.663318932056427\n",
      "epoch: 163 train RMSE: 0.663318932056427\n",
      "epoch: 164 train RMSE: 0.663318932056427\n",
      "epoch: 165 train RMSE: 0.663318932056427\n",
      "epoch: 166 train RMSE: 0.663318932056427\n",
      "epoch: 167 train RMSE: 0.663318932056427\n",
      "epoch: 168 train RMSE: 0.6633188724517822\n",
      "epoch: 169 train RMSE: 0.6633188128471375\n",
      "epoch: 170 train RMSE: 0.6633187532424927\n",
      "epoch: 171 train RMSE: 0.6633187532424927\n",
      "epoch: 172 train RMSE: 0.6633186936378479\n",
      "epoch: 173 train RMSE: 0.6633186936378479\n",
      "epoch: 174 train RMSE: 0.6633186936378479\n",
      "epoch: 175 train RMSE: 0.6633185744285583\n",
      "epoch: 176 train RMSE: 0.6633185744285583\n",
      "epoch: 177 train RMSE: 0.6633185744285583\n",
      "epoch: 178 train RMSE: 0.6633185148239136\n",
      "epoch: 179 train RMSE: 0.6633185148239136\n",
      "epoch: 180 train RMSE: 0.6633185148239136\n",
      "epoch: 181 train RMSE: 0.6633184552192688\n",
      "epoch: 182 train RMSE: 0.6633184552192688\n",
      "epoch: 183 train RMSE: 0.6633184552192688\n",
      "epoch: 184 train RMSE: 0.663318395614624\n",
      "epoch: 185 train RMSE: 0.6633183360099792\n",
      "epoch: 186 train RMSE: 0.6633183360099792\n",
      "epoch: 187 train RMSE: 0.6633183360099792\n",
      "epoch: 188 train RMSE: 0.6633182764053345\n",
      "epoch: 189 train RMSE: 0.6633182764053345\n",
      "epoch: 190 train RMSE: 0.6633182764053345\n",
      "epoch: 191 train RMSE: 0.6633182168006897\n",
      "epoch: 192 train RMSE: 0.6633182168006897\n",
      "epoch: 193 train RMSE: 0.6633182168006897\n",
      "epoch: 194 train RMSE: 0.6633182168006897\n",
      "epoch: 195 train RMSE: 0.6633180975914001\n",
      "epoch: 196 train RMSE: 0.6633180975914001\n",
      "epoch: 197 train RMSE: 0.6633180975914001\n",
      "epoch: 198 train RMSE: 0.6633180975914001\n",
      "epoch: 199 train RMSE: 0.6633180379867554\n",
      "epoch: 200 train RMSE: 0.6633180379867554\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_epocs(train, model, batch_size=64, epochs=10, lr=0.005, reg=0):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=reg)\n",
    "    dataloader = DataLoader(train.values, batch_size=batch_size)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        for batch_id, train_batch in enumerate(dataloader):\n",
    "            # model.train()\n",
    "            train_batch = train_batch.float().to(device)\n",
    "            preds = model(train_batch).to(device)\n",
    "\n",
    "            loss = torch.sqrt(nn.functional.mse_loss(preds, train_batch))\n",
    "            # print(f'epoch: {epoch}, batch: {batch_id}, loss: {loss.item()}')\n",
    "\n",
    "        # backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # update\n",
    "            optimizer.step()\n",
    "        print(f'epoch: {epoch} train RMSE: {loss.item()}')\n",
    "\n",
    "    return preds\n",
    "\n",
    "p = train_epocs(train, model, epochs=200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[4.9101810e+00, 1.9693743e+00, 3.4679255e+00, ..., 3.3794111e-01,\n        3.8359052e-01, 4.7213659e-01],\n       [4.7767887e+00, 3.3519408e-03, 3.1996059e-01, ..., 1.9354329e-01,\n        2.1273448e-01, 2.1550149e-01],\n       [4.0800991e+00, 1.0779200e-01, 1.6463345e-01, ..., 6.1387408e-01,\n        7.1507138e-01, 7.4785805e-01],\n       ...,\n       [4.8953419e+00, 1.7699021e-01, 9.3510562e-01, ..., 1.9119012e-01,\n        2.8748101e-01, 1.6761416e-01],\n       [4.8995171e+00, 5.6515604e-01, 8.8921607e-02, ..., 2.5211126e-01,\n        2.9596657e-01, 4.7826663e-01],\n       [4.9196835e+00, 4.9169917e+00, 3.4284275e+00, ..., 2.5384778e-01,\n        6.7711121e-01, 5.3850901e-01]], dtype=float32)"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler((0, 5))\n",
    "scaler.fit_transform(torch.Tensor.cpu(p).detach().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "item_id  1     2     3     4     5     6     7     8     9     10    ...  \\\nuser_id                                                              ...   \n1         5.0   3.0   4.0   3.0   3.0   0.0   4.0   1.0   5.0   0.0  ...   \n2         4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  ...   \n3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n939       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   5.0   0.0  ...   \n940       0.0   0.0   0.0   2.0   0.0   0.0   4.0   5.0   3.0   0.0  ...   \n941       5.0   0.0   0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0  ...   \n942       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n943       0.0   5.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0   0.0  ...   \n\nitem_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \nuser_id                                                              \n1         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n2         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n939       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n940       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n941       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n942       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n943       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n\n[943 rows x 1650 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>item_id</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>1673</th>\n      <th>1674</th>\n      <th>1675</th>\n      <th>1676</th>\n      <th>1677</th>\n      <th>1678</th>\n      <th>1679</th>\n      <th>1680</th>\n      <th>1681</th>\n      <th>1682</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>939</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>940</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>941</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>942</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>943</th>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>943 rows Ã— 1650 columns</p>\n</div>"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [3., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "torch.Size([15, 1650])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "for batch in DataLoader(train.values, batch_size=15):\n",
    "    print(batch)\n",
    "    print(batch.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}