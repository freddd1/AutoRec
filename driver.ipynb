{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AutoRec cs3639 Recommendation Systems course IDC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### here will be general explanations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch\n",
    "from torch import nn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this project, we will use 2 datasets:\n",
    "* **movielens**, which can be downloaded using `utils.datasets_download.py` or straight from [here](http://files.grouplens.org/datasets/movielens/).\n",
    "* **netflixprize**, which can be downloaded from this [semi-parsed version from kaggle](https://www.kaggle.com/netflix-inc/netflix-prize-data) or from this [raw version](https://archive.org/download/nf_prize_dataset.tar)\n",
    "\n",
    "**NOTE**: for the notebook to run properly, you should save you dataset under `data` folder and `movielens` folder for the movielens dataset and `netflix` folder for the netflixprize dataset.\n",
    "i.e `data/movielens` folder and `data/netflix` folder respectively."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "       user_id  item_id  rating  timestamp\n0            1        1       5  874965758\n1            1        2       3  876893171\n2            1        3       4  878542960\n3            1        4       3  876893119\n4            1        5       3  889751712\n...        ...      ...     ...        ...\n79995      943     1067       2  875501756\n79996      943     1074       4  888640250\n79997      943     1188       3  888640250\n79998      943     1228       3  888640275\n79999      943     1330       3  888692465\n\n[80000 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>874965758</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>876893171</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>878542960</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n      <td>876893119</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>3</td>\n      <td>889751712</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>79995</th>\n      <td>943</td>\n      <td>1067</td>\n      <td>2</td>\n      <td>875501756</td>\n    </tr>\n    <tr>\n      <th>79996</th>\n      <td>943</td>\n      <td>1074</td>\n      <td>4</td>\n      <td>888640250</td>\n    </tr>\n    <tr>\n      <th>79997</th>\n      <td>943</td>\n      <td>1188</td>\n      <td>3</td>\n      <td>888640250</td>\n    </tr>\n    <tr>\n      <th>79998</th>\n      <td>943</td>\n      <td>1228</td>\n      <td>3</td>\n      <td>888640275</td>\n    </tr>\n    <tr>\n      <th>79999</th>\n      <td>943</td>\n      <td>1330</td>\n      <td>3</td>\n      <td>888692465</td>\n    </tr>\n  </tbody>\n</table>\n<p>80000 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data_prep import movielens_load\n",
    "train, test = movielens_load(1)\n",
    "print(train.shape)\n",
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - add function that will calculate the validation loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# def mf_train_epocs(train, model, epochs=10, lr=0.001, reg=0):\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=reg)\n",
    "#     for i in range(epochs):\n",
    "#         model.train()\n",
    "#         # users and items indexes start 1, therefore we use the -1\n",
    "#         users = torch.LongTensor(train.user_id.values-1).to(device)\n",
    "#         items = torch.LongTensor(train.item_id.values-1).to(device)\n",
    "#         ratings = torch.FloatTensor(train.rating.values).to(device) # rating is our label\n",
    "#\n",
    "#         preds = model(users, items)\n",
    "#         loss = torch.sqrt(nn.functional.mse_loss(preds, ratings))\n",
    "#\n",
    "#         # backpropagation\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#\n",
    "#         # update\n",
    "#         optimizer.step()\n",
    "#\n",
    "#         print(f'train RMSE: {loss.item()}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 1682\n"
     ]
    }
   ],
   "source": [
    "from src.matrixfactorization import MatrixFactorization\n",
    "num_users = train.user_id.max()\n",
    "num_items = train.item_id.max()\n",
    "print(num_users, num_items)\n",
    "model = MatrixFactorization(num_users, num_items).to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train RMSE: 5.348294734954834\n",
      "train RMSE: 5.343664169311523\n",
      "train RMSE: 5.339043617248535\n",
      "train RMSE: 5.334432125091553\n",
      "train RMSE: 5.329831123352051\n",
      "train RMSE: 5.325239181518555\n",
      "train RMSE: 5.320658206939697\n",
      "train RMSE: 5.316086769104004\n",
      "train RMSE: 5.311525821685791\n",
      "train RMSE: 5.306975364685059\n",
      "train RMSE: 5.302434921264648\n",
      "train RMSE: 5.297904968261719\n",
      "train RMSE: 5.293386936187744\n",
      "train RMSE: 5.288877964019775\n",
      "train RMSE: 5.284380912780762\n",
      "train RMSE: 5.2798943519592285\n",
      "train RMSE: 5.275418758392334\n",
      "train RMSE: 5.270954132080078\n",
      "train RMSE: 5.266500473022461\n",
      "train RMSE: 5.262057304382324\n",
      "train RMSE: 5.257626056671143\n",
      "train RMSE: 5.253205299377441\n",
      "train RMSE: 5.248796463012695\n",
      "train RMSE: 5.24439811706543\n",
      "train RMSE: 5.240011215209961\n",
      "train RMSE: 5.235635757446289\n",
      "train RMSE: 5.231271266937256\n",
      "train RMSE: 5.2269182205200195\n",
      "train RMSE: 5.22257661819458\n",
      "train RMSE: 5.218245983123779\n",
      "train RMSE: 5.213927268981934\n",
      "train RMSE: 5.209619522094727\n",
      "train RMSE: 5.205322742462158\n",
      "train RMSE: 5.201037883758545\n",
      "train RMSE: 5.19676399230957\n",
      "train RMSE: 5.192501544952393\n",
      "train RMSE: 5.188250541687012\n",
      "train RMSE: 5.1840105056762695\n",
      "train RMSE: 5.179781913757324\n",
      "train RMSE: 5.175564765930176\n",
      "train RMSE: 5.171358585357666\n",
      "train RMSE: 5.167163848876953\n",
      "train RMSE: 5.162981033325195\n",
      "train RMSE: 5.158808708190918\n",
      "train RMSE: 5.154648303985596\n",
      "train RMSE: 5.150498867034912\n",
      "train RMSE: 5.146360397338867\n",
      "train RMSE: 5.142233371734619\n",
      "train RMSE: 5.138117790222168\n",
      "train RMSE: 5.1340131759643555\n",
      "train RMSE: 5.12992000579834\n",
      "train RMSE: 5.125837802886963\n",
      "train RMSE: 5.121766567230225\n",
      "train RMSE: 5.117706775665283\n",
      "train RMSE: 5.1136579513549805\n",
      "train RMSE: 5.109620571136475\n",
      "train RMSE: 5.105594158172607\n",
      "train RMSE: 5.101578235626221\n",
      "train RMSE: 5.097574234008789\n",
      "train RMSE: 5.093580722808838\n",
      "train RMSE: 5.089597702026367\n",
      "train RMSE: 5.085626125335693\n",
      "train RMSE: 5.0816650390625\n",
      "train RMSE: 5.077714920043945\n",
      "train RMSE: 5.073775768280029\n",
      "train RMSE: 5.069847106933594\n",
      "train RMSE: 5.065929412841797\n",
      "train RMSE: 5.0620222091674805\n",
      "train RMSE: 5.058125972747803\n",
      "train RMSE: 5.0542402267456055\n",
      "train RMSE: 5.050364971160889\n",
      "train RMSE: 5.0465006828308105\n",
      "train RMSE: 5.042646884918213\n",
      "train RMSE: 5.038803577423096\n",
      "train RMSE: 5.034970760345459\n",
      "train RMSE: 5.031148433685303\n",
      "train RMSE: 5.027336597442627\n",
      "train RMSE: 5.023535251617432\n",
      "train RMSE: 5.019744396209717\n",
      "train RMSE: 5.015964031219482\n",
      "train RMSE: 5.012193202972412\n",
      "train RMSE: 5.0084333419799805\n",
      "train RMSE: 5.004683494567871\n",
      "train RMSE: 5.0009446144104\n",
      "train RMSE: 4.997215270996094\n",
      "train RMSE: 4.993495941162109\n",
      "train RMSE: 4.989787578582764\n",
      "train RMSE: 4.986088752746582\n",
      "train RMSE: 4.982400417327881\n",
      "train RMSE: 4.978722095489502\n",
      "train RMSE: 4.975053310394287\n",
      "train RMSE: 4.971395015716553\n",
      "train RMSE: 4.967746257781982\n",
      "train RMSE: 4.964108467102051\n",
      "train RMSE: 4.960479736328125\n",
      "train RMSE: 4.9568610191345215\n",
      "train RMSE: 4.95325231552124\n",
      "train RMSE: 4.949653625488281\n",
      "train RMSE: 4.946064472198486\n",
      "train RMSE: 4.9424848556518555\n",
      "train RMSE: 4.938915729522705\n",
      "train RMSE: 4.935356140136719\n",
      "train RMSE: 4.931805610656738\n",
      "train RMSE: 4.928265571594238\n",
      "train RMSE: 4.924735069274902\n",
      "train RMSE: 4.921213626861572\n",
      "train RMSE: 4.9177021980285645\n",
      "train RMSE: 4.914200305938721\n",
      "train RMSE: 4.910708427429199\n",
      "train RMSE: 4.907225608825684\n",
      "train RMSE: 4.903751850128174\n",
      "train RMSE: 4.900288105010986\n",
      "train RMSE: 4.896833896636963\n",
      "train RMSE: 4.893388748168945\n",
      "train RMSE: 4.889953136444092\n",
      "train RMSE: 4.886527061462402\n",
      "train RMSE: 4.883110046386719\n",
      "train RMSE: 4.879702568054199\n",
      "train RMSE: 4.8763041496276855\n",
      "train RMSE: 4.872915267944336\n",
      "train RMSE: 4.869535446166992\n",
      "train RMSE: 4.866164684295654\n",
      "train RMSE: 4.8628034591674805\n",
      "train RMSE: 4.8594512939453125\n",
      "train RMSE: 4.856107711791992\n",
      "train RMSE: 4.852773666381836\n",
      "train RMSE: 4.849449157714844\n",
      "train RMSE: 4.846133232116699\n",
      "train RMSE: 4.842825889587402\n",
      "train RMSE: 4.8395280838012695\n",
      "train RMSE: 4.836238861083984\n",
      "train RMSE: 4.832959175109863\n",
      "train RMSE: 4.82968807220459\n",
      "train RMSE: 4.826426029205322\n",
      "train RMSE: 4.823172569274902\n",
      "train RMSE: 4.81992769241333\n",
      "train RMSE: 4.816692352294922\n",
      "train RMSE: 4.813465595245361\n",
      "train RMSE: 4.810247421264648\n",
      "train RMSE: 4.807037830352783\n",
      "train RMSE: 4.803837776184082\n",
      "train RMSE: 4.80064582824707\n",
      "train RMSE: 4.797462463378906\n",
      "train RMSE: 4.794288158416748\n",
      "train RMSE: 4.791121959686279\n",
      "train RMSE: 4.787964820861816\n",
      "train RMSE: 4.784815788269043\n",
      "train RMSE: 4.781675815582275\n",
      "train RMSE: 4.778543949127197\n",
      "train RMSE: 4.775421142578125\n",
      "train RMSE: 4.772305965423584\n",
      "train RMSE: 4.769199848175049\n",
      "train RMSE: 4.766102313995361\n",
      "train RMSE: 4.763012886047363\n",
      "train RMSE: 4.759932041168213\n",
      "train RMSE: 4.756859302520752\n",
      "train RMSE: 4.753795146942139\n",
      "train RMSE: 4.750739097595215\n",
      "train RMSE: 4.747691631317139\n",
      "train RMSE: 4.744652271270752\n",
      "train RMSE: 4.741621017456055\n",
      "train RMSE: 4.738598346710205\n",
      "train RMSE: 4.735583305358887\n",
      "train RMSE: 4.732576847076416\n",
      "train RMSE: 4.729578971862793\n",
      "train RMSE: 4.726588726043701\n",
      "train RMSE: 4.723606586456299\n",
      "train RMSE: 4.720632553100586\n",
      "train RMSE: 4.717667102813721\n",
      "train RMSE: 4.7147088050842285\n",
      "train RMSE: 4.711759090423584\n",
      "train RMSE: 4.708817481994629\n",
      "train RMSE: 4.705883979797363\n",
      "train RMSE: 4.702958106994629\n",
      "train RMSE: 4.700040340423584\n",
      "train RMSE: 4.69713020324707\n",
      "train RMSE: 4.694228172302246\n",
      "train RMSE: 4.691334247589111\n",
      "train RMSE: 4.688447952270508\n",
      "train RMSE: 4.6855692863464355\n",
      "train RMSE: 4.682698726654053\n",
      "train RMSE: 4.679836273193359\n",
      "train RMSE: 4.676980972290039\n",
      "train RMSE: 4.67413330078125\n",
      "train RMSE: 4.671294212341309\n",
      "train RMSE: 4.66846227645874\n",
      "train RMSE: 4.665637969970703\n",
      "train RMSE: 4.662821292877197\n",
      "train RMSE: 4.660012722015381\n",
      "train RMSE: 4.6572113037109375\n",
      "train RMSE: 4.654417514801025\n",
      "train RMSE: 4.651631832122803\n",
      "train RMSE: 4.648853302001953\n",
      "train RMSE: 4.646082401275635\n",
      "train RMSE: 4.6433186531066895\n",
      "train RMSE: 4.640563011169434\n",
      "train RMSE: 4.637814521789551\n",
      "train RMSE: 4.635073661804199\n",
      "train RMSE: 4.632339954376221\n",
      "train RMSE: 4.629613876342773\n",
      "train RMSE: 4.626895427703857\n",
      "train RMSE: 4.6241841316223145\n",
      "train RMSE: 4.621480464935303\n",
      "train RMSE: 4.618783473968506\n",
      "train RMSE: 4.61609411239624\n",
      "train RMSE: 4.613412380218506\n",
      "train RMSE: 4.6107378005981445\n",
      "train RMSE: 4.608070373535156\n",
      "train RMSE: 4.605410099029541\n",
      "train RMSE: 4.602757453918457\n",
      "train RMSE: 4.600111961364746\n",
      "train RMSE: 4.59747314453125\n",
      "train RMSE: 4.594841957092285\n",
      "train RMSE: 4.592217445373535\n",
      "train RMSE: 4.589600563049316\n",
      "train RMSE: 4.5869903564453125\n",
      "train RMSE: 4.58438777923584\n",
      "train RMSE: 4.581791877746582\n",
      "train RMSE: 4.579203128814697\n",
      "train RMSE: 4.5766215324401855\n",
      "train RMSE: 4.574046611785889\n",
      "train RMSE: 4.571479320526123\n",
      "train RMSE: 4.568918228149414\n",
      "train RMSE: 4.566364765167236\n",
      "train RMSE: 4.563817977905273\n",
      "train RMSE: 4.561277866363525\n",
      "train RMSE: 4.558745384216309\n",
      "train RMSE: 4.556219100952148\n",
      "train RMSE: 4.553699970245361\n",
      "train RMSE: 4.551187515258789\n",
      "train RMSE: 4.54868221282959\n",
      "train RMSE: 4.546183109283447\n",
      "train RMSE: 4.543691158294678\n",
      "train RMSE: 4.541205883026123\n",
      "train RMSE: 4.538727760314941\n",
      "train RMSE: 4.536255836486816\n",
      "train RMSE: 4.5337910652160645\n",
      "train RMSE: 4.531332969665527\n",
      "train RMSE: 4.528881072998047\n",
      "train RMSE: 4.526436805725098\n",
      "train RMSE: 4.523998260498047\n",
      "train RMSE: 4.521566390991211\n",
      "train RMSE: 4.519141674041748\n",
      "train RMSE: 4.516723155975342\n",
      "train RMSE: 4.51431131362915\n",
      "train RMSE: 4.511906147003174\n",
      "train RMSE: 4.509507179260254\n",
      "train RMSE: 4.507115364074707\n",
      "train RMSE: 4.504729747772217\n",
      "train RMSE: 4.502350807189941\n",
      "train RMSE: 4.4999775886535645\n",
      "train RMSE: 4.4976115226745605\n",
      "train RMSE: 4.495251655578613\n",
      "train RMSE: 4.492898464202881\n",
      "train RMSE: 4.490551471710205\n",
      "train RMSE: 4.488211154937744\n",
      "train RMSE: 4.48587703704834\n",
      "train RMSE: 4.483549118041992\n",
      "train RMSE: 4.481227397918701\n",
      "train RMSE: 4.478911876678467\n",
      "train RMSE: 4.4766035079956055\n",
      "train RMSE: 4.474300384521484\n",
      "train RMSE: 4.472003936767578\n",
      "train RMSE: 4.469714164733887\n",
      "train RMSE: 4.467430114746094\n",
      "train RMSE: 4.465152740478516\n",
      "train RMSE: 4.462881565093994\n",
      "train RMSE: 4.460616111755371\n",
      "train RMSE: 4.458356857299805\n",
      "train RMSE: 4.456103801727295\n",
      "train RMSE: 4.453857421875\n",
      "train RMSE: 4.4516167640686035\n",
      "train RMSE: 4.449382305145264\n",
      "train RMSE: 4.4471540451049805\n",
      "train RMSE: 4.444931507110596\n",
      "train RMSE: 4.442715167999268\n",
      "train RMSE: 4.440504550933838\n",
      "train RMSE: 4.438300132751465\n",
      "train RMSE: 4.436102390289307\n",
      "train RMSE: 4.433909893035889\n",
      "train RMSE: 4.431723594665527\n",
      "train RMSE: 4.4295430183410645\n",
      "train RMSE: 4.427368640899658\n",
      "train RMSE: 4.42519998550415\n",
      "train RMSE: 4.423037528991699\n",
      "train RMSE: 4.420881271362305\n",
      "train RMSE: 4.41873025894165\n",
      "train RMSE: 4.416585445404053\n",
      "train RMSE: 4.4144463539123535\n",
      "train RMSE: 4.412312984466553\n",
      "train RMSE: 4.410185813903809\n",
      "train RMSE: 4.408063888549805\n",
      "train RMSE: 4.405948162078857\n",
      "train RMSE: 4.403838157653809\n",
      "train RMSE: 4.401733875274658\n",
      "train RMSE: 4.399634838104248\n",
      "train RMSE: 4.3975419998168945\n",
      "train RMSE: 4.3954548835754395\n",
      "train RMSE: 4.393373966217041\n",
      "train RMSE: 4.391297817230225\n",
      "train RMSE: 4.389227867126465\n",
      "train RMSE: 4.387163162231445\n",
      "train RMSE: 4.385104179382324\n",
      "train RMSE: 4.38305139541626\n",
      "train RMSE: 4.381003379821777\n",
      "train RMSE: 4.378961563110352\n",
      "train RMSE: 4.376924991607666\n",
      "train RMSE: 4.374894142150879\n",
      "train RMSE: 4.372868537902832\n",
      "train RMSE: 4.370849132537842\n",
      "train RMSE: 4.368834495544434\n",
      "train RMSE: 4.366825580596924\n",
      "train RMSE: 4.3648223876953125\n",
      "train RMSE: 4.362824440002441\n",
      "train RMSE: 4.3608317375183105\n",
      "train RMSE: 4.358844757080078\n",
      "train RMSE: 4.356863498687744\n",
      "train RMSE: 4.35488748550415\n",
      "train RMSE: 4.352916240692139\n",
      "train RMSE: 4.350951194763184\n",
      "train RMSE: 4.3489909172058105\n",
      "train RMSE: 4.347036361694336\n",
      "train RMSE: 4.345087051391602\n",
      "train RMSE: 4.343142986297607\n",
      "train RMSE: 4.3412041664123535\n",
      "train RMSE: 4.33927059173584\n",
      "train RMSE: 4.337342739105225\n",
      "train RMSE: 4.33542013168335\n",
      "train RMSE: 4.333501815795898\n",
      "train RMSE: 4.331589698791504\n",
      "train RMSE: 4.329682350158691\n",
      "train RMSE: 4.327780723571777\n",
      "train RMSE: 4.325883865356445\n",
      "train RMSE: 4.3239922523498535\n",
      "train RMSE: 4.322105884552002\n",
      "train RMSE: 4.320224761962891\n",
      "train RMSE: 4.318348407745361\n",
      "train RMSE: 4.316477298736572\n",
      "train RMSE: 4.314611434936523\n",
      "train RMSE: 4.312750816345215\n",
      "train RMSE: 4.310894966125488\n",
      "train RMSE: 4.309044361114502\n",
      "train RMSE: 4.307198524475098\n",
      "train RMSE: 4.305357933044434\n",
      "train RMSE: 4.30352258682251\n",
      "train RMSE: 4.301692485809326\n",
      "train RMSE: 4.299866676330566\n",
      "train RMSE: 4.298046112060547\n",
      "train RMSE: 4.296230792999268\n",
      "train RMSE: 4.294419765472412\n",
      "train RMSE: 4.292613983154297\n",
      "train RMSE: 4.290813446044922\n",
      "train RMSE: 4.289017677307129\n",
      "train RMSE: 4.287226676940918\n",
      "train RMSE: 4.285440921783447\n",
      "train RMSE: 4.283659934997559\n",
      "train RMSE: 4.281883239746094\n",
      "train RMSE: 4.280111789703369\n",
      "train RMSE: 4.278345584869385\n",
      "train RMSE: 4.276583671569824\n",
      "train RMSE: 4.274827003479004\n",
      "train RMSE: 4.273074626922607\n",
      "train RMSE: 4.271327495574951\n",
      "train RMSE: 4.269584655761719\n",
      "train RMSE: 4.267847061157227\n",
      "train RMSE: 4.266114234924316\n",
      "train RMSE: 4.26438570022583\n",
      "train RMSE: 4.262661933898926\n",
      "train RMSE: 4.260943412780762\n",
      "train RMSE: 4.2592291831970215\n",
      "train RMSE: 4.257519721984863\n",
      "train RMSE: 4.255814552307129\n",
      "train RMSE: 4.254114627838135\n",
      "train RMSE: 4.2524189949035645\n",
      "train RMSE: 4.250728130340576\n",
      "train RMSE: 4.24904203414917\n",
      "train RMSE: 4.2473602294921875\n",
      "train RMSE: 4.245682716369629\n",
      "train RMSE: 4.2440104484558105\n",
      "train RMSE: 4.242342948913574\n",
      "train RMSE: 4.2406792640686035\n",
      "train RMSE: 4.239020347595215\n",
      "train RMSE: 4.237366676330566\n",
      "train RMSE: 4.235716819763184\n",
      "train RMSE: 4.234071731567383\n",
      "train RMSE: 4.232430458068848\n",
      "train RMSE: 4.230794429779053\n",
      "train RMSE: 4.229162693023682\n",
      "train RMSE: 4.227535247802734\n",
      "train RMSE: 4.225912570953369\n",
      "train RMSE: 4.224294185638428\n",
      "train RMSE: 4.222679615020752\n",
      "train RMSE: 4.221070289611816\n",
      "train RMSE: 4.2194647789001465\n",
      "train RMSE: 4.217864036560059\n",
      "train RMSE: 4.2162675857543945\n",
      "train RMSE: 4.214675426483154\n",
      "train RMSE: 4.213087558746338\n",
      "train RMSE: 4.2115044593811035\n",
      "train RMSE: 4.209925174713135\n",
      "train RMSE: 4.20835018157959\n",
      "train RMSE: 4.206780433654785\n",
      "train RMSE: 4.205214023590088\n",
      "train RMSE: 4.2036519050598145\n",
      "train RMSE: 4.202094078063965\n",
      "train RMSE: 4.200541019439697\n",
      "train RMSE: 4.1989922523498535\n",
      "train RMSE: 4.197447299957275\n",
      "train RMSE: 4.195906162261963\n",
      "train RMSE: 4.194369792938232\n",
      "train RMSE: 4.192837715148926\n",
      "train RMSE: 4.191309452056885\n",
      "train RMSE: 4.189785480499268\n",
      "train RMSE: 4.188265800476074\n",
      "train RMSE: 4.1867499351501465\n",
      "train RMSE: 4.185238838195801\n",
      "train RMSE: 4.1837310791015625\n",
      "train RMSE: 4.182228088378906\n",
      "train RMSE: 4.180728912353516\n",
      "train RMSE: 4.179234027862549\n",
      "train RMSE: 4.177742958068848\n",
      "train RMSE: 4.17625617980957\n",
      "train RMSE: 4.174773216247559\n",
      "train RMSE: 4.173294544219971\n",
      "train RMSE: 4.171819686889648\n",
      "train RMSE: 4.17034912109375\n",
      "train RMSE: 4.168882369995117\n",
      "train RMSE: 4.167419910430908\n",
      "train RMSE: 4.165960788726807\n",
      "train RMSE: 4.164506435394287\n",
      "train RMSE: 4.163055419921875\n",
      "train RMSE: 4.161608695983887\n",
      "train RMSE: 4.160165786743164\n",
      "train RMSE: 4.158727169036865\n",
      "train RMSE: 4.157291889190674\n",
      "train RMSE: 4.155860900878906\n",
      "train RMSE: 4.154433727264404\n",
      "train RMSE: 4.153010368347168\n",
      "train RMSE: 4.151590824127197\n",
      "train RMSE: 4.15017557144165\n",
      "train RMSE: 4.148764133453369\n",
      "train RMSE: 4.1473565101623535\n",
      "train RMSE: 4.145952224731445\n",
      "train RMSE: 4.144552230834961\n",
      "train RMSE: 4.143156051635742\n",
      "train RMSE: 4.141763210296631\n",
      "train RMSE: 4.140374660491943\n",
      "train RMSE: 4.1389899253845215\n",
      "train RMSE: 4.137608528137207\n",
      "train RMSE: 4.136231422424316\n",
      "train RMSE: 4.134857654571533\n",
      "train RMSE: 4.133487701416016\n",
      "train RMSE: 4.132121562957764\n",
      "train RMSE: 4.130759239196777\n",
      "train RMSE: 4.129400730133057\n",
      "train RMSE: 4.128045082092285\n",
      "train RMSE: 4.126694202423096\n",
      "train RMSE: 4.1253461837768555\n",
      "train RMSE: 4.124002456665039\n",
      "train RMSE: 4.12266206741333\n",
      "train RMSE: 4.121325492858887\n",
      "train RMSE: 4.119992733001709\n",
      "train RMSE: 4.118663311004639\n",
      "train RMSE: 4.117337703704834\n",
      "train RMSE: 4.116015434265137\n",
      "train RMSE: 4.114696502685547\n",
      "train RMSE: 4.113381862640381\n",
      "train RMSE: 4.112070083618164\n",
      "train RMSE: 4.110762596130371\n",
      "train RMSE: 4.109457969665527\n",
      "train RMSE: 4.108157634735107\n",
      "train RMSE: 4.106860637664795\n",
      "train RMSE: 4.10556697845459\n",
      "train RMSE: 4.104276657104492\n",
      "train RMSE: 4.10299015045166\n",
      "train RMSE: 4.1017069816589355\n",
      "train RMSE: 4.100427150726318\n",
      "train RMSE: 4.099151134490967\n",
      "train RMSE: 4.097878456115723\n",
      "train RMSE: 4.096609115600586\n",
      "train RMSE: 4.095343589782715\n",
      "train RMSE: 4.094080924987793\n",
      "train RMSE: 4.092822074890137\n",
      "train RMSE: 4.091567039489746\n",
      "train RMSE: 4.090314865112305\n",
      "train RMSE: 4.089066028594971\n",
      "train RMSE: 4.087820529937744\n",
      "train RMSE: 4.086578845977783\n",
      "train RMSE: 4.08534049987793\n",
      "train RMSE: 4.084105014801025\n",
      "train RMSE: 4.082873344421387\n",
      "train RMSE: 4.0816450119018555\n",
      "train RMSE: 4.080419540405273\n",
      "train RMSE: 4.079197883605957\n",
      "train RMSE: 4.07797908782959\n",
      "train RMSE: 4.076764106750488\n",
      "train RMSE: 4.075552463531494\n",
      "train RMSE: 4.074343681335449\n",
      "train RMSE: 4.073138236999512\n",
      "train RMSE: 4.071936130523682\n",
      "train RMSE: 4.070737361907959\n",
      "train RMSE: 4.069541931152344\n",
      "train RMSE: 4.068349838256836\n",
      "train RMSE: 4.067160606384277\n",
      "train RMSE: 4.065974712371826\n",
      "train RMSE: 4.064792156219482\n",
      "train RMSE: 4.063612461090088\n",
      "train RMSE: 4.062436580657959\n",
      "train RMSE: 4.061263084411621\n",
      "train RMSE: 4.060093402862549\n",
      "train RMSE: 4.058927059173584\n",
      "train RMSE: 4.05776309967041\n",
      "train RMSE: 4.056602478027344\n",
      "train RMSE: 4.055445194244385\n",
      "train RMSE: 4.054291248321533\n",
      "train RMSE: 4.053140163421631\n",
      "train RMSE: 4.051992416381836\n",
      "train RMSE: 4.05084753036499\n",
      "train RMSE: 4.049705505371094\n",
      "train RMSE: 4.048567295074463\n",
      "train RMSE: 4.047431468963623\n",
      "train RMSE: 4.046299457550049\n",
      "train RMSE: 4.045169830322266\n",
      "train RMSE: 4.044043064117432\n",
      "train RMSE: 4.042920112609863\n",
      "train RMSE: 4.041799545288086\n",
      "train RMSE: 4.040682315826416\n",
      "train RMSE: 4.0395684242248535\n",
      "train RMSE: 4.038456916809082\n",
      "train RMSE: 4.03734827041626\n",
      "train RMSE: 4.036243438720703\n",
      "train RMSE: 4.0351409912109375\n",
      "train RMSE: 4.034041404724121\n",
      "train RMSE: 4.032945156097412\n",
      "train RMSE: 4.031851768493652\n",
      "train RMSE: 4.030761241912842\n",
      "train RMSE: 4.029674053192139\n",
      "train RMSE: 4.028589248657227\n",
      "train RMSE: 4.027507305145264\n",
      "train RMSE: 4.026428699493408\n",
      "train RMSE: 4.025352954864502\n",
      "train RMSE: 4.024279594421387\n",
      "train RMSE: 4.023209571838379\n",
      "train RMSE: 4.02214241027832\n",
      "train RMSE: 4.021078109741211\n",
      "train RMSE: 4.020016670227051\n",
      "train RMSE: 4.01895809173584\n",
      "train RMSE: 4.01790189743042\n",
      "train RMSE: 4.016849517822266\n",
      "train RMSE: 4.015799045562744\n",
      "train RMSE: 4.014751434326172\n",
      "train RMSE: 4.013707160949707\n",
      "train RMSE: 4.012665271759033\n",
      "train RMSE: 4.011626720428467\n",
      "train RMSE: 4.010590553283691\n",
      "train RMSE: 4.009557247161865\n",
      "train RMSE: 4.00852632522583\n",
      "train RMSE: 4.007498741149902\n",
      "train RMSE: 4.006473541259766\n",
      "train RMSE: 4.005451202392578\n",
      "train RMSE: 4.00443172454834\n",
      "train RMSE: 4.003414630889893\n",
      "train RMSE: 4.002400875091553\n",
      "train RMSE: 4.001389026641846\n",
      "train RMSE: 4.000380516052246\n",
      "train RMSE: 3.9993743896484375\n",
      "train RMSE: 3.998371124267578\n",
      "train RMSE: 3.9973702430725098\n",
      "train RMSE: 3.9963724613189697\n",
      "train RMSE: 3.9953770637512207\n",
      "train RMSE: 3.994384527206421\n",
      "train RMSE: 3.993394613265991\n",
      "train RMSE: 3.9924070835113525\n",
      "train RMSE: 3.991422414779663\n",
      "train RMSE: 3.9904401302337646\n",
      "train RMSE: 3.9894607067108154\n",
      "train RMSE: 3.9884836673736572\n",
      "train RMSE: 3.987509250640869\n",
      "train RMSE: 3.9865376949310303\n",
      "train RMSE: 3.9855685234069824\n",
      "train RMSE: 3.984602212905884\n",
      "train RMSE: 3.983638286590576\n",
      "train RMSE: 3.9826767444610596\n",
      "train RMSE: 3.981717824935913\n",
      "train RMSE: 3.9807615280151367\n",
      "train RMSE: 3.9798078536987305\n",
      "train RMSE: 3.9788565635681152\n",
      "train RMSE: 3.977907657623291\n",
      "train RMSE: 3.976961851119995\n",
      "train RMSE: 3.976017951965332\n",
      "train RMSE: 3.975076675415039\n",
      "train RMSE: 3.9741384983062744\n",
      "train RMSE: 3.9732019901275635\n",
      "train RMSE: 3.9722683429718018\n",
      "train RMSE: 3.971337080001831\n",
      "train RMSE: 3.9704082012176514\n",
      "train RMSE: 3.969481945037842\n",
      "train RMSE: 3.9685580730438232\n",
      "train RMSE: 3.9676365852355957\n",
      "train RMSE: 3.9667177200317383\n",
      "train RMSE: 3.9658010005950928\n",
      "train RMSE: 3.9648869037628174\n",
      "train RMSE: 3.963974952697754\n",
      "train RMSE: 3.9630658626556396\n",
      "train RMSE: 3.9621589183807373\n",
      "train RMSE: 3.961254358291626\n",
      "train RMSE: 3.9603521823883057\n",
      "train RMSE: 3.9594523906707764\n",
      "train RMSE: 3.958554983139038\n",
      "train RMSE: 3.957659959793091\n",
      "train RMSE: 3.9567673206329346\n",
      "train RMSE: 3.9558768272399902\n",
      "train RMSE: 3.954988956451416\n",
      "train RMSE: 3.9541032314300537\n",
      "train RMSE: 3.9532198905944824\n",
      "train RMSE: 3.952338933944702\n",
      "train RMSE: 3.951460123062134\n",
      "train RMSE: 3.9505836963653564\n",
      "train RMSE: 3.94970965385437\n",
      "train RMSE: 3.9488375186920166\n",
      "train RMSE: 3.9479682445526123\n",
      "train RMSE: 3.947100877761841\n",
      "train RMSE: 3.9462358951568604\n",
      "train RMSE: 3.945373058319092\n",
      "train RMSE: 3.9445128440856934\n",
      "train RMSE: 3.9436542987823486\n",
      "train RMSE: 3.942798376083374\n",
      "train RMSE: 3.9419445991516113\n",
      "train RMSE: 3.9410932064056396\n",
      "train RMSE: 3.940243721008301\n",
      "train RMSE: 3.939396619796753\n",
      "train RMSE: 3.938551664352417\n",
      "train RMSE: 3.937709093093872\n",
      "train RMSE: 3.93686842918396\n",
      "train RMSE: 3.936030387878418\n",
      "train RMSE: 3.935194253921509\n",
      "train RMSE: 3.9343602657318115\n",
      "train RMSE: 3.933528184890747\n",
      "train RMSE: 3.9326987266540527\n",
      "train RMSE: 3.9318714141845703\n",
      "train RMSE: 3.9310460090637207\n",
      "train RMSE: 3.930222511291504\n",
      "train RMSE: 3.929401397705078\n",
      "train RMSE: 3.9285826683044434\n",
      "train RMSE: 3.9277658462524414\n",
      "train RMSE: 3.9269511699676514\n",
      "train RMSE: 3.9261386394500732\n",
      "train RMSE: 3.925328016281128\n",
      "train RMSE: 3.9245197772979736\n",
      "train RMSE: 3.923713207244873\n",
      "train RMSE: 3.9229090213775635\n",
      "train RMSE: 3.922106981277466\n",
      "train RMSE: 3.921306610107422\n",
      "train RMSE: 3.920508861541748\n",
      "train RMSE: 3.919712543487549\n",
      "train RMSE: 3.9189188480377197\n",
      "train RMSE: 3.9181268215179443\n",
      "train RMSE: 3.9173367023468018\n",
      "train RMSE: 3.91654896736145\n",
      "train RMSE: 3.9157633781433105\n",
      "train RMSE: 3.9149794578552246\n",
      "train RMSE: 3.9141974449157715\n",
      "train RMSE: 3.9134175777435303\n",
      "train RMSE: 3.912639617919922\n",
      "train RMSE: 3.9118640422821045\n",
      "train RMSE: 3.911090135574341\n",
      "train RMSE: 3.910318374633789\n",
      "train RMSE: 3.90954852104187\n",
      "train RMSE: 3.908780574798584\n",
      "train RMSE: 3.9080142974853516\n",
      "train RMSE: 3.90725040435791\n",
      "train RMSE: 3.9064881801605225\n",
      "train RMSE: 3.9057281017303467\n",
      "train RMSE: 3.9049699306488037\n",
      "train RMSE: 3.9042136669158936\n",
      "train RMSE: 3.903459310531616\n",
      "train RMSE: 3.9027066230773926\n",
      "train RMSE: 3.901956081390381\n",
      "train RMSE: 3.901207208633423\n",
      "train RMSE: 3.900460720062256\n",
      "train RMSE: 3.8997156620025635\n",
      "train RMSE: 3.898972511291504\n",
      "train RMSE: 3.8982315063476562\n",
      "train RMSE: 3.8974924087524414\n",
      "train RMSE: 3.896754741668701\n",
      "train RMSE: 3.896019220352173\n",
      "train RMSE: 3.8952856063842773\n",
      "train RMSE: 3.8945538997650146\n",
      "train RMSE: 3.8938236236572266\n",
      "train RMSE: 3.8930957317352295\n",
      "train RMSE: 3.892369031906128\n",
      "train RMSE: 3.8916447162628174\n",
      "train RMSE: 3.8909218311309814\n",
      "train RMSE: 3.8902010917663574\n",
      "train RMSE: 3.889481782913208\n",
      "train RMSE: 3.8887646198272705\n",
      "train RMSE: 3.8880488872528076\n",
      "train RMSE: 3.8873353004455566\n",
      "train RMSE: 3.8866233825683594\n",
      "train RMSE: 3.8859128952026367\n",
      "train RMSE: 3.885204553604126\n",
      "train RMSE: 3.884498119354248\n",
      "train RMSE: 3.8837928771972656\n",
      "train RMSE: 3.883090019226074\n",
      "train RMSE: 3.8823883533477783\n",
      "train RMSE: 3.8816888332366943\n",
      "train RMSE: 3.880990743637085\n",
      "train RMSE: 3.8802945613861084\n",
      "train RMSE: 3.8796000480651855\n",
      "train RMSE: 3.8789072036743164\n",
      "train RMSE: 3.87821626663208\n",
      "train RMSE: 3.8775269985198975\n",
      "train RMSE: 3.8768389225006104\n",
      "train RMSE: 3.876152992248535\n",
      "train RMSE: 3.8754689693450928\n",
      "train RMSE: 3.874786138534546\n",
      "train RMSE: 3.8741049766540527\n",
      "train RMSE: 3.8734257221221924\n",
      "train RMSE: 3.872748374938965\n",
      "train RMSE: 3.872072219848633\n",
      "train RMSE: 3.8713979721069336\n",
      "train RMSE: 3.870725393295288\n",
      "train RMSE: 3.870054006576538\n",
      "train RMSE: 3.869384527206421\n",
      "train RMSE: 3.8687169551849365\n",
      "train RMSE: 3.8680508136749268\n",
      "train RMSE: 3.8673863410949707\n",
      "train RMSE: 3.8667232990264893\n",
      "train RMSE: 3.8660621643066406\n",
      "train RMSE: 3.8654022216796875\n",
      "train RMSE: 3.864744186401367\n",
      "train RMSE: 3.8640873432159424\n",
      "train RMSE: 3.8634326457977295\n",
      "train RMSE: 3.862779140472412\n",
      "train RMSE: 3.8621273040771484\n",
      "train RMSE: 3.8614771366119385\n",
      "train RMSE: 3.860828399658203\n",
      "train RMSE: 3.8601810932159424\n",
      "train RMSE: 3.8595356941223145\n",
      "train RMSE: 3.858891487121582\n",
      "train RMSE: 3.8582489490509033\n",
      "train RMSE: 3.8576080799102783\n",
      "train RMSE: 3.856968641281128\n",
      "train RMSE: 3.856330633163452\n",
      "train RMSE: 3.85569429397583\n",
      "train RMSE: 3.8550593852996826\n",
      "train RMSE: 3.8544259071350098\n",
      "train RMSE: 3.8537938594818115\n",
      "train RMSE: 3.853163719177246\n",
      "train RMSE: 3.852534770965576\n",
      "train RMSE: 3.85190749168396\n",
      "train RMSE: 3.8512814044952393\n",
      "train RMSE: 3.8506569862365723\n",
      "train RMSE: 3.850033760070801\n",
      "train RMSE: 3.849412202835083\n",
      "train RMSE: 3.848792314529419\n",
      "train RMSE: 3.8481736183166504\n",
      "train RMSE: 3.8475563526153564\n",
      "train RMSE: 3.846940755844116\n",
      "train RMSE: 3.8463261127471924\n",
      "train RMSE: 3.8457133769989014\n",
      "train RMSE: 3.845102071762085\n",
      "train RMSE: 3.844491958618164\n",
      "train RMSE: 3.8438830375671387\n",
      "train RMSE: 3.843276023864746\n",
      "train RMSE: 3.842670202255249\n",
      "train RMSE: 3.8420655727386475\n",
      "train RMSE: 3.8414628505706787\n",
      "train RMSE: 3.8408613204956055\n",
      "train RMSE: 3.8402609825134277\n",
      "train RMSE: 3.8396618366241455\n",
      "train RMSE: 3.839064836502075\n",
      "train RMSE: 3.838468313217163\n",
      "train RMSE: 3.837873697280884\n",
      "train RMSE: 3.837280035018921\n",
      "train RMSE: 3.8366880416870117\n",
      "train RMSE: 3.836097240447998\n",
      "train RMSE: 3.835508108139038\n",
      "train RMSE: 3.8349201679229736\n",
      "train RMSE: 3.8343334197998047\n",
      "train RMSE: 3.8337478637695312\n",
      "train RMSE: 3.8331639766693115\n",
      "train RMSE: 3.832581043243408\n",
      "train RMSE: 3.8319995403289795\n",
      "train RMSE: 3.8314197063446045\n",
      "train RMSE: 3.830840826034546\n",
      "train RMSE: 3.830263137817383\n",
      "train RMSE: 3.8296871185302734\n",
      "train RMSE: 3.8291120529174805\n",
      "train RMSE: 3.828538417816162\n",
      "train RMSE: 3.8279662132263184\n",
      "train RMSE: 3.827394962310791\n",
      "train RMSE: 3.8268251419067383\n",
      "train RMSE: 3.826256513595581\n",
      "train RMSE: 3.8256890773773193\n",
      "train RMSE: 3.8251230716705322\n",
      "train RMSE: 3.8245584964752197\n",
      "train RMSE: 3.8239946365356445\n",
      "train RMSE: 3.823432207107544\n",
      "train RMSE: 3.822871208190918\n",
      "train RMSE: 3.8223111629486084\n",
      "train RMSE: 3.8217525482177734\n",
      "train RMSE: 3.821195125579834\n",
      "train RMSE: 3.820638656616211\n",
      "train RMSE: 3.8200838565826416\n",
      "train RMSE: 3.8195300102233887\n",
      "train RMSE: 3.8189775943756104\n",
      "train RMSE: 3.8184261322021484\n",
      "train RMSE: 3.817875623703003\n",
      "train RMSE: 3.817326545715332\n",
      "train RMSE: 3.8167786598205566\n",
      "train RMSE: 3.8162319660186768\n",
      "train RMSE: 3.8156864643096924\n",
      "train RMSE: 3.8151421546936035\n",
      "train RMSE: 3.814598560333252\n",
      "train RMSE: 3.814056634902954\n",
      "train RMSE: 3.8135156631469727\n",
      "train RMSE: 3.8129756450653076\n",
      "train RMSE: 3.8124372959136963\n",
      "train RMSE: 3.811899423599243\n",
      "train RMSE: 3.8113632202148438\n",
      "train RMSE: 3.8108279705047607\n",
      "train RMSE: 3.8102939128875732\n",
      "train RMSE: 3.809760808944702\n",
      "train RMSE: 3.8092286586761475\n",
      "train RMSE: 3.8086979389190674\n",
      "train RMSE: 3.8081679344177246\n",
      "train RMSE: 3.8076393604278564\n",
      "train RMSE: 3.807111978530884\n",
      "train RMSE: 3.8065855503082275\n",
      "train RMSE: 3.8060600757598877\n",
      "train RMSE: 3.8055357933044434\n",
      "train RMSE: 3.8050124645233154\n",
      "train RMSE: 3.804490327835083\n",
      "train RMSE: 3.803969383239746\n",
      "train RMSE: 3.8034493923187256\n",
      "train RMSE: 3.8029301166534424\n",
      "train RMSE: 3.802412271499634\n",
      "train RMSE: 3.8018953800201416\n",
      "train RMSE: 3.8013792037963867\n",
      "train RMSE: 3.8008644580841064\n",
      "train RMSE: 3.8003506660461426\n",
      "train RMSE: 3.799837827682495\n",
      "train RMSE: 3.7993264198303223\n",
      "train RMSE: 3.7988154888153076\n",
      "train RMSE: 3.7983055114746094\n",
      "train RMSE: 3.7977969646453857\n",
      "train RMSE: 3.7972893714904785\n",
      "train RMSE: 3.7967822551727295\n",
      "train RMSE: 3.796276569366455\n",
      "train RMSE: 3.795771837234497\n",
      "train RMSE: 3.7952680587768555\n",
      "train RMSE: 3.7947652339935303\n",
      "train RMSE: 3.7942636013031006\n",
      "train RMSE: 3.793762445449829\n",
      "train RMSE: 3.7932627201080322\n",
      "train RMSE: 3.7927637100219727\n",
      "train RMSE: 3.7922658920288086\n",
      "train RMSE: 3.791768789291382\n",
      "train RMSE: 3.7912728786468506\n",
      "train RMSE: 3.7907774448394775\n",
      "train RMSE: 3.790283203125\n",
      "train RMSE: 3.789790153503418\n",
      "train RMSE: 3.7892978191375732\n",
      "train RMSE: 3.788806200027466\n",
      "train RMSE: 3.788315773010254\n",
      "train RMSE: 3.7878260612487793\n",
      "train RMSE: 3.787337303161621\n",
      "train RMSE: 3.7868494987487793\n",
      "train RMSE: 3.786362886428833\n",
      "train RMSE: 3.785876989364624\n",
      "train RMSE: 3.785391330718994\n",
      "train RMSE: 3.784907341003418\n",
      "train RMSE: 3.784424066543579\n",
      "train RMSE: 3.7839415073394775\n",
      "train RMSE: 3.7834601402282715\n",
      "train RMSE: 3.7829792499542236\n",
      "train RMSE: 3.7824995517730713\n",
      "train RMSE: 3.782020330429077\n",
      "train RMSE: 3.7815423011779785\n",
      "train RMSE: 3.781064987182617\n",
      "train RMSE: 3.7805886268615723\n",
      "train RMSE: 3.7801129817962646\n",
      "train RMSE: 3.7796382904052734\n",
      "train RMSE: 3.7791643142700195\n",
      "train RMSE: 3.778691053390503\n",
      "train RMSE: 3.7782187461853027\n",
      "train RMSE: 3.777747392654419\n",
      "train RMSE: 3.7772765159606934\n",
      "train RMSE: 3.776806592941284\n",
      "train RMSE: 3.7763376235961914\n",
      "train RMSE: 3.775869607925415\n",
      "train RMSE: 3.775402307510376\n",
      "train RMSE: 3.774935483932495\n",
      "train RMSE: 3.7744696140289307\n",
      "train RMSE: 3.7740046977996826\n",
      "train RMSE: 3.7735402584075928\n",
      "train RMSE: 3.7730767726898193\n",
      "train RMSE: 3.772613763809204\n",
      "train RMSE: 3.7721519470214844\n",
      "train RMSE: 3.771690607070923\n",
      "train RMSE: 3.7712302207946777\n",
      "train RMSE: 3.770770311355591\n",
      "train RMSE: 3.7703115940093994\n",
      "train RMSE: 3.769853115081787\n",
      "train RMSE: 3.769395589828491\n",
      "train RMSE: 3.7689387798309326\n",
      "train RMSE: 3.7684829235076904\n",
      "train RMSE: 3.7680273056030273\n",
      "train RMSE: 3.7675728797912598\n",
      "train RMSE: 3.7671191692352295\n",
      "train RMSE: 3.7666659355163574\n",
      "train RMSE: 3.7662134170532227\n",
      "train RMSE: 3.7657618522644043\n",
      "train RMSE: 3.765310764312744\n",
      "train RMSE: 3.764860153198242\n",
      "train RMSE: 3.7644104957580566\n",
      "train RMSE: 3.7639615535736084\n",
      "train RMSE: 3.7635135650634766\n",
      "train RMSE: 3.7630655765533447\n",
      "train RMSE: 3.7626187801361084\n",
      "train RMSE: 3.762172222137451\n",
      "train RMSE: 3.7617268562316895\n",
      "train RMSE: 3.761281967163086\n",
      "train RMSE: 3.7608375549316406\n",
      "train RMSE: 3.7603938579559326\n",
      "train RMSE: 3.759950876235962\n",
      "train RMSE: 3.7595086097717285\n",
      "train RMSE: 3.7590668201446533\n",
      "train RMSE: 3.7586257457733154\n",
      "train RMSE: 3.7581851482391357\n",
      "train RMSE: 3.7577452659606934\n",
      "train RMSE: 3.7573060989379883\n",
      "train RMSE: 3.7568674087524414\n",
      "train RMSE: 3.756429433822632\n",
      "train RMSE: 3.7559919357299805\n",
      "train RMSE: 3.7555551528930664\n",
      "train RMSE: 3.7551190853118896\n",
      "train RMSE: 3.75468373298645\n",
      "train RMSE: 3.7542483806610107\n",
      "train RMSE: 3.7538139820098877\n",
      "train RMSE: 3.753380060195923\n",
      "train RMSE: 3.7529470920562744\n",
      "train RMSE: 3.752514123916626\n",
      "train RMSE: 3.752082109451294\n",
      "train RMSE: 3.75165057182312\n",
      "train RMSE: 3.7512195110321045\n",
      "train RMSE: 3.750789165496826\n",
      "train RMSE: 3.750359058380127\n",
      "train RMSE: 3.749929666519165\n",
      "train RMSE: 3.7495007514953613\n",
      "train RMSE: 3.749072790145874\n",
      "train RMSE: 3.7486448287963867\n",
      "train RMSE: 3.748217821121216\n",
      "train RMSE: 3.747791051864624\n",
      "train RMSE: 3.7473649978637695\n",
      "train RMSE: 3.746939182281494\n",
      "train RMSE: 3.746514081954956\n",
      "train RMSE: 3.746089458465576\n",
      "train RMSE: 3.7456653118133545\n",
      "train RMSE: 3.745241641998291\n",
      "train RMSE: 3.744818687438965\n",
      "train RMSE: 3.7443957328796387\n",
      "train RMSE: 3.743973970413208\n",
      "train RMSE: 3.7435519695281982\n",
      "train RMSE: 3.743130683898926\n",
      "train RMSE: 3.7427098751068115\n",
      "train RMSE: 3.7422900199890137\n",
      "train RMSE: 3.7418699264526367\n",
      "train RMSE: 3.741450786590576\n",
      "train RMSE: 3.7410316467285156\n",
      "train RMSE: 3.7406132221221924\n",
      "train RMSE: 3.7401955127716064\n",
      "train RMSE: 3.7397775650024414\n",
      "train RMSE: 3.739360809326172\n",
      "train RMSE: 3.7389438152313232\n",
      "train RMSE: 3.738527536392212\n",
      "train RMSE: 3.738111972808838\n",
      "train RMSE: 3.737696409225464\n",
      "train RMSE: 3.737281322479248\n",
      "train RMSE: 3.7368669509887695\n",
      "train RMSE: 3.736452579498291\n",
      "train RMSE: 3.7360386848449707\n",
      "train RMSE: 3.7356252670288086\n",
      "train RMSE: 3.7352123260498047\n",
      "train RMSE: 3.734799861907959\n",
      "train RMSE: 3.7343876361846924\n",
      "train RMSE: 3.733975648880005\n",
      "train RMSE: 3.7335641384124756\n",
      "train RMSE: 3.7331533432006836\n",
      "train RMSE: 3.7327423095703125\n",
      "train RMSE: 3.7323319911956787\n",
      "train RMSE: 3.731922149658203\n",
      "train RMSE: 3.7315125465393066\n",
      "train RMSE: 3.7311031818389893\n",
      "train RMSE: 3.73069429397583\n",
      "train RMSE: 3.73028564453125\n",
      "train RMSE: 3.729877233505249\n",
      "train RMSE: 3.7294695377349854\n",
      "train RMSE: 3.7290618419647217\n"
     ]
    }
   ],
   "source": [
    "from src.matrixfactorization import mf_train\n",
    "\n",
    "# %%time\n",
    "mf_train(train, model,device, epochs=1000, lr=0.001, reg=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# halpful links:\n",
    "# https://d2l.ai/chapter_recommender-systems/autorec.html\n",
    "# https://github.com/gtshs2/Autorec\n",
    "# https://github.com/ImKeTT/Recommend_algorithms_Librec2Python/blob/master/AutoRec_torch/src/model.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "item_id  1     2     3     4     5     6     7     8     9     10    ...  \\\nuser_id                                                              ...   \n1         5.0   3.0   4.0   3.0   3.0   0.0   4.0   1.0   5.0   0.0  ...   \n2         4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  ...   \n3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n939       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   5.0   0.0  ...   \n940       0.0   0.0   0.0   2.0   0.0   0.0   4.0   5.0   3.0   0.0  ...   \n941       5.0   0.0   0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0  ...   \n942       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n943       0.0   5.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0   0.0  ...   \n\nitem_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \nuser_id                                                              \n1         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n2         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n939       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n940       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n941       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n942       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n943       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n\n[943 rows x 1650 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>item_id</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>1673</th>\n      <th>1674</th>\n      <th>1675</th>\n      <th>1676</th>\n      <th>1677</th>\n      <th>1678</th>\n      <th>1679</th>\n      <th>1680</th>\n      <th>1681</th>\n      <th>1682</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>939</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>940</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>941</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>942</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>943</th>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>943 rows Ã— 1650 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data_prep import movielens_prep\n",
    "train, test = movielens_prep(1)\n",
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# class AutoRec(nn.Module):\n",
    "#     \"\"\"\n",
    "#     AutoRec model. See explanation on :param: num_features for use as USER TO USER or ITEM TO ITEM\n",
    "#     \"\"\"\n",
    "#     def __init__(self, num_features, num_hidden=500):\n",
    "#         \"\"\"\n",
    "#         :param num_hidden: Size of the hidden layer\n",
    "#         :param num_features: If num_features == num_items that means that we are doing USER TO USER model.\n",
    "#                              If num_features == num_users that means that we are doing ITEM TO ITEM model.\n",
    "#                              The logic is the a user vector has number of items features for it.\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "#\n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Linear(num_features, num_hidden),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "#\n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Linear(num_hidden, num_features),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#\n",
    "#         encoded = self.encoder(x)\n",
    "#         decoded = self.decoder(encoded)\n",
    "#         return decoded"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from src.autorec import AutoRec\n",
    "num_items = train.shape[1]\n",
    "model = AutoRec(num_hidden=500, num_features=num_items).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "item_id  1     2     3     4     5     6     7     8     9     10    ...  \\\nuser_id                                                              ...   \n1         5.0   3.0   4.0   3.0   3.0   0.0   4.0   1.0   5.0   0.0  ...   \n2         4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  ...   \n3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n939       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   5.0   0.0  ...   \n940       0.0   0.0   0.0   2.0   0.0   0.0   4.0   5.0   3.0   0.0  ...   \n941       5.0   0.0   0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0  ...   \n942       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n943       0.0   5.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0   0.0  ...   \n\nitem_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \nuser_id                                                              \n1         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n2         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n939       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n940       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n941       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n942       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n943       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n\n[943 rows x 1650 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>item_id</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>1673</th>\n      <th>1674</th>\n      <th>1675</th>\n      <th>1676</th>\n      <th>1677</th>\n      <th>1678</th>\n      <th>1679</th>\n      <th>1680</th>\n      <th>1681</th>\n      <th>1682</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>939</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>940</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>941</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>942</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>943</th>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>943 rows Ã— 1650 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "#\n",
    "# def train_epocs(train, model, batch_size=64, epochs=10, lr=0.005, reg=0):\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=reg)\n",
    "#     dataloader = DataLoader(train.values, batch_size=batch_size)\n",
    "#     for epoch in range(1, epochs+1):\n",
    "#         for batch_id, train_batch in enumerate(dataloader):\n",
    "#             # model.train()\n",
    "#             train_batch = train_batch.float().to(device)\n",
    "#             preds = model(train_batch).to(device)\n",
    "#\n",
    "#             loss = torch.sqrt(nn.functional.mse_loss(preds, train_batch))\n",
    "#             # print(f'epoch: {epoch}, batch: {batch_id}, loss: {loss.item()}')\n",
    "#\n",
    "#         # backpropagation\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#\n",
    "#             # update\n",
    "#             optimizer.step()\n",
    "#         print(f'epoch: {epoch} train RMSE: {loss.item()}')\n",
    "#\n",
    "#     return preds\n",
    "#\n",
    "# p = train_epocs(train, model, epochs=200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train RMSE: 0.7958652377128601\n",
      "epoch: 2 train RMSE: 0.7793866395950317\n",
      "epoch: 3 train RMSE: 0.7678214311599731\n",
      "epoch: 4 train RMSE: 0.7601146697998047\n",
      "epoch: 5 train RMSE: 0.7540083527565002\n",
      "epoch: 6 train RMSE: 0.7459284663200378\n",
      "epoch: 7 train RMSE: 0.7496024966239929\n",
      "epoch: 8 train RMSE: 0.7381505370140076\n",
      "epoch: 9 train RMSE: 0.7318482995033264\n",
      "epoch: 10 train RMSE: 0.7263002395629883\n",
      "epoch: 11 train RMSE: 0.721406877040863\n",
      "epoch: 12 train RMSE: 0.7167291045188904\n",
      "epoch: 13 train RMSE: 0.7126479148864746\n",
      "epoch: 14 train RMSE: 0.7086724638938904\n",
      "epoch: 15 train RMSE: 0.7051829099655151\n",
      "epoch: 16 train RMSE: 0.7021512985229492\n",
      "epoch: 17 train RMSE: 0.6993169188499451\n",
      "epoch: 18 train RMSE: 0.6970480680465698\n",
      "epoch: 19 train RMSE: 0.6965256333351135\n",
      "epoch: 20 train RMSE: 0.698455810546875\n",
      "epoch: 21 train RMSE: 0.6953354477882385\n",
      "epoch: 22 train RMSE: 0.6927146911621094\n",
      "epoch: 23 train RMSE: 0.6896097660064697\n",
      "epoch: 24 train RMSE: 0.6863771080970764\n",
      "epoch: 25 train RMSE: 0.6842828989028931\n",
      "epoch: 26 train RMSE: 0.6829280853271484\n",
      "epoch: 27 train RMSE: 0.6817460656166077\n",
      "epoch: 28 train RMSE: 0.6806846261024475\n",
      "epoch: 29 train RMSE: 0.6798050403594971\n",
      "epoch: 30 train RMSE: 0.6790372133255005\n",
      "epoch: 31 train RMSE: 0.6784397959709167\n",
      "epoch: 32 train RMSE: 0.6778036952018738\n",
      "epoch: 33 train RMSE: 0.6770934462547302\n",
      "epoch: 34 train RMSE: 0.6768040060997009\n",
      "epoch: 35 train RMSE: 0.6760421395301819\n",
      "epoch: 36 train RMSE: 0.6759196519851685\n",
      "epoch: 37 train RMSE: 0.6750267148017883\n",
      "epoch: 38 train RMSE: 0.6746906638145447\n",
      "epoch: 39 train RMSE: 0.674172043800354\n",
      "epoch: 40 train RMSE: 0.6737144589424133\n",
      "epoch: 41 train RMSE: 0.6732996106147766\n",
      "epoch: 42 train RMSE: 0.6728482246398926\n",
      "epoch: 43 train RMSE: 0.6724873185157776\n",
      "epoch: 44 train RMSE: 0.67220538854599\n",
      "epoch: 45 train RMSE: 0.6718493103981018\n",
      "epoch: 46 train RMSE: 0.671527624130249\n",
      "epoch: 47 train RMSE: 0.6712618470191956\n",
      "epoch: 48 train RMSE: 0.6710862517356873\n",
      "epoch: 49 train RMSE: 0.6708193421363831\n",
      "epoch: 50 train RMSE: 0.6706101298332214\n",
      "epoch: 51 train RMSE: 0.6703717112541199\n",
      "epoch: 52 train RMSE: 0.6702419519424438\n",
      "epoch: 53 train RMSE: 0.6699957251548767\n",
      "epoch: 54 train RMSE: 0.6698414087295532\n",
      "epoch: 55 train RMSE: 0.6695879101753235\n",
      "epoch: 56 train RMSE: 0.6695206165313721\n",
      "epoch: 57 train RMSE: 0.6692536473274231\n",
      "epoch: 58 train RMSE: 0.6691763997077942\n",
      "epoch: 59 train RMSE: 0.6689785718917847\n",
      "epoch: 60 train RMSE: 0.6689127087593079\n",
      "epoch: 61 train RMSE: 0.6687294840812683\n",
      "epoch: 62 train RMSE: 0.6685999631881714\n",
      "epoch: 63 train RMSE: 0.6685252785682678\n",
      "epoch: 64 train RMSE: 0.6683671474456787\n",
      "epoch: 65 train RMSE: 0.6682935953140259\n",
      "epoch: 66 train RMSE: 0.6681583523750305\n",
      "epoch: 67 train RMSE: 0.6681341528892517\n",
      "epoch: 68 train RMSE: 0.6680014729499817\n",
      "epoch: 69 train RMSE: 0.6679175496101379\n",
      "epoch: 70 train RMSE: 0.6678663492202759\n",
      "epoch: 71 train RMSE: 0.6677484512329102\n",
      "epoch: 72 train RMSE: 0.6676995754241943\n",
      "epoch: 73 train RMSE: 0.6676151156425476\n",
      "epoch: 74 train RMSE: 0.6675719618797302\n",
      "epoch: 75 train RMSE: 0.6674979329109192\n",
      "epoch: 76 train RMSE: 0.6674154996871948\n",
      "epoch: 77 train RMSE: 0.6673992872238159\n",
      "epoch: 78 train RMSE: 0.6673105359077454\n",
      "epoch: 79 train RMSE: 0.6672521829605103\n",
      "epoch: 80 train RMSE: 0.6672205328941345\n",
      "epoch: 81 train RMSE: 0.6671535968780518\n",
      "epoch: 82 train RMSE: 0.6671232581138611\n",
      "epoch: 83 train RMSE: 0.6670770049095154\n",
      "epoch: 84 train RMSE: 0.6670259833335876\n",
      "epoch: 85 train RMSE: 0.6669927835464478\n",
      "epoch: 86 train RMSE: 0.6669213175773621\n",
      "epoch: 87 train RMSE: 0.6668883562088013\n",
      "epoch: 88 train RMSE: 0.6668589115142822\n",
      "epoch: 89 train RMSE: 0.666799008846283\n",
      "epoch: 90 train RMSE: 0.6667861342430115\n",
      "epoch: 91 train RMSE: 0.6667526364326477\n",
      "epoch: 92 train RMSE: 0.6667007803916931\n",
      "epoch: 93 train RMSE: 0.6666673421859741\n",
      "epoch: 94 train RMSE: 0.6666103005409241\n",
      "epoch: 95 train RMSE: 0.6665422916412354\n",
      "epoch: 96 train RMSE: 0.6665515899658203\n",
      "epoch: 97 train RMSE: 0.6664847731590271\n",
      "epoch: 98 train RMSE: 0.6664490103721619\n",
      "epoch: 99 train RMSE: 0.6664318442344666\n",
      "epoch: 100 train RMSE: 0.6663486361503601\n"
     ]
    }
   ],
   "source": [
    "from src.autorec import autorec_train\n",
    "p = autorec_train(train, model,device, epochs=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler((0, 5))\n",
    "# scaler.fit_transform(torch.Tensor.cpu(p).detach().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}