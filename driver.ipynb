{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AutoRec cs3639 Recommendation Systems course IDC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### here will be general explanations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this project, we will use 2 datasets:\n",
    "* **movielens**, which can be downloaded using `utils.datasets_download.py` or straight from [here](http://files.grouplens.org/datasets/movielens/).\n",
    "* **netflixprize**, which can be downloaded from this [semi-parsed version from kaggle](https://www.kaggle.com/netflix-inc/netflix-prize-data) or from this [raw version](https://archive.org/download/nf_prize_dataset.tar)\n",
    "\n",
    "**NOTE**: for the notebook to run properly, you should save you dataset under `data` folder and `movielens` folder for the movielens dataset and `netflix` folder for the netflixprize dataset.\n",
    "i.e `data/movielens` folder and `data/netflix` folder respectively."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "outputs": [],
   "source": [
    "from src.data_prep import movielens_prep\n",
    "train, test = movielens_prep(fold=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "       user_id  item_id  rating  timestamp\n0            1        1       5  874965758\n1            1        2       3  876893171\n2            1        3       4  878542960\n3            1        4       3  876893119\n4            1        5       3  889751712\n...        ...      ...     ...        ...\n79995      943     1067       2  875501756\n79996      943     1074       4  888640250\n79997      943     1188       3  888640250\n79998      943     1228       3  888640275\n79999      943     1330       3  888692465\n\n[80000 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>874965758</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>876893171</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>878542960</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n      <td>876893119</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>3</td>\n      <td>889751712</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>79995</th>\n      <td>943</td>\n      <td>1067</td>\n      <td>2</td>\n      <td>875501756</td>\n    </tr>\n    <tr>\n      <th>79996</th>\n      <td>943</td>\n      <td>1074</td>\n      <td>4</td>\n      <td>888640250</td>\n    </tr>\n    <tr>\n      <th>79997</th>\n      <td>943</td>\n      <td>1188</td>\n      <td>3</td>\n      <td>888640250</td>\n    </tr>\n    <tr>\n      <th>79998</th>\n      <td>943</td>\n      <td>1228</td>\n      <td>3</td>\n      <td>888640275</td>\n    </tr>\n    <tr>\n      <th>79999</th>\n      <td>943</td>\n      <td>1330</td>\n      <td>3</td>\n      <td>888692465</td>\n    </tr>\n  </tbody>\n</table>\n<p>80000 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data_prep import movielens_load\n",
    "train, test = movielens_load(1)\n",
    "print(train.shape)\n",
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "outputs": [
    {
     "data": {
      "text/plain": "min       1\nmax    1682\nName: item_id, dtype: int64"
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.item_id.agg(['min', 'max'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "outputs": [
    {
     "data": {
      "text/plain": "min      1\nmax    943\nName: user_id, dtype: int64"
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.user_id.agg(['min', 'max'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "outputs": [],
   "source": [
    "# userid2idx = {old_id: i for i, old_id in enumerate(train.user_id)}\n",
    "# userid2idx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "outputs": [],
   "source": [
    "# train['user_id'] = train.user_id.apply(lambda x: userid2idx[x])\n",
    "# np.sort(np.unique(train.user_id))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "outputs": [],
   "source": [
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_items, k=15):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "\n",
    "        # create the latent matrixs\n",
    "        self.users_emb = nn.Embedding(num_users, k)\n",
    "        self.items_emb = nn.Embedding(num_items, k)\n",
    "\n",
    "        self.batch_size = 100\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        # the embedding vector of user_id\n",
    "        user = self.users_emb(user)\n",
    "        item = self.items_emb(item)\n",
    "        return (user*item).sum(axis=1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "outputs": [],
   "source": [
    "def train_epocs(train, model, epochs=10, lr=0.01, reg=0):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=reg)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        # users and items indexes start 1, therefore we use the -1\n",
    "        users = torch.LongTensor(train.user_id.values-1)#.to(device)\n",
    "        items = torch.LongTensor(train.item_id.values-1)#.to(device)\n",
    "        ratings = torch.FloatTensor(train.rating.values)#.to(device) # rating is our label\n",
    "\n",
    "        preds = model(users, items)\n",
    "        loss = nn.functional.mse_loss(preds, ratings)\n",
    "\n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # update\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'train loss: {loss.item()}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 1682\n",
      "self.users_emb.weight.shape=torch.Size([943, 15])\n",
      "self.items_emb.weight.shape=torch.Size([1682, 15])\n"
     ]
    }
   ],
   "source": [
    "num_users = len(np.unique(train.user_id))\n",
    "num_items = train.item_id.max()\n",
    "print(num_users, num_items)\n",
    "model = MatrixFactorization(num_users, num_items)#.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 28.033849716186523\n",
      "train loss: 27.497081756591797\n",
      "train loss: 26.9763126373291\n",
      "train loss: 26.471330642700195\n",
      "train loss: 25.98189926147461\n",
      "train loss: 25.50773811340332\n",
      "train loss: 25.04854965209961\n",
      "train loss: 24.6040096282959\n",
      "train loss: 24.173763275146484\n",
      "train loss: 23.757436752319336\n",
      "train loss: 23.354631423950195\n",
      "train loss: 22.96492576599121\n",
      "train loss: 22.587881088256836\n",
      "train loss: 22.223058700561523\n",
      "train loss: 21.869993209838867\n",
      "train loss: 21.52821922302246\n",
      "train loss: 21.19725227355957\n",
      "train loss: 20.876611709594727\n",
      "train loss: 20.56580352783203\n",
      "train loss: 20.26432991027832\n",
      "train loss: 19.971691131591797\n",
      "train loss: 19.687374114990234\n",
      "train loss: 19.41087532043457\n",
      "train loss: 19.141677856445312\n",
      "train loss: 18.87926483154297\n",
      "train loss: 18.623117446899414\n",
      "train loss: 18.37271499633789\n",
      "train loss: 18.127531051635742\n",
      "train loss: 17.887039184570312\n",
      "train loss: 17.650712966918945\n",
      "train loss: 17.41801643371582\n",
      "train loss: 17.18842315673828\n",
      "train loss: 16.96139907836914\n",
      "train loss: 16.736419677734375\n",
      "train loss: 16.51295280456543\n",
      "train loss: 16.29047393798828\n",
      "train loss: 16.06846809387207\n",
      "train loss: 15.84642505645752\n",
      "train loss: 15.623844146728516\n",
      "train loss: 15.400243759155273\n",
      "train loss: 15.175151824951172\n",
      "train loss: 14.94812297821045\n",
      "train loss: 14.718735694885254\n",
      "train loss: 14.486597061157227\n",
      "train loss: 14.25134563446045\n",
      "train loss: 14.012659072875977\n",
      "train loss: 13.770258903503418\n",
      "train loss: 13.523917198181152\n",
      "train loss: 13.273452758789062\n",
      "train loss: 13.01875114440918\n",
      "train loss: 12.759750366210938\n",
      "train loss: 12.49646282196045\n",
      "train loss: 12.22896671295166\n",
      "train loss: 11.957414627075195\n",
      "train loss: 11.682034492492676\n",
      "train loss: 11.403132438659668\n",
      "train loss: 11.121086120605469\n",
      "train loss: 10.836348533630371\n",
      "train loss: 10.549447059631348\n",
      "train loss: 10.260969161987305\n",
      "train loss: 9.971567153930664\n",
      "train loss: 9.6819429397583\n",
      "train loss: 9.39283561706543\n",
      "train loss: 9.105019569396973\n",
      "train loss: 8.819281578063965\n",
      "train loss: 8.53641128540039\n",
      "train loss: 8.25719165802002\n",
      "train loss: 7.982375621795654\n",
      "train loss: 7.712678909301758\n",
      "train loss: 7.448764801025391\n",
      "train loss: 7.191232681274414\n",
      "train loss: 6.940610885620117\n",
      "train loss: 6.697347640991211\n",
      "train loss: 6.46180534362793\n",
      "train loss: 6.2342658042907715\n",
      "train loss: 6.014919757843018\n",
      "train loss: 5.8038811683654785\n",
      "train loss: 5.601190567016602\n",
      "train loss: 5.406818389892578\n",
      "train loss: 5.220677375793457\n",
      "train loss: 5.042631149291992\n",
      "train loss: 4.872503757476807\n",
      "train loss: 4.710089683532715\n",
      "train loss: 4.555159568786621\n",
      "train loss: 4.407469749450684\n",
      "train loss: 4.266766548156738\n",
      "train loss: 4.132793426513672\n",
      "train loss: 4.005290508270264\n",
      "train loss: 3.884000778198242\n",
      "train loss: 3.768667459487915\n",
      "train loss: 3.6590378284454346\n",
      "train loss: 3.554861307144165\n",
      "train loss: 3.45589017868042\n",
      "train loss: 3.3618781566619873\n",
      "train loss: 3.2725820541381836\n",
      "train loss: 3.187760353088379\n",
      "train loss: 3.10717511177063\n",
      "train loss: 3.0305893421173096\n",
      "train loss: 2.9577739238739014\n",
      "train loss: 2.888502359390259\n"
     ]
    }
   ],
   "source": [
    "train_epocs(train, model, epochs=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}