{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AutoRec cs3639 Recommendation Systems course IDC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### here will be general explanations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch\n",
    "from torch import nn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this project, we will use 2 datasets:\n",
    "* **movielens**, which can be downloaded using `utils.datasets_download.py` or straight from [here](http://files.grouplens.org/datasets/movielens/).\n",
    "* **netflixprize**, which can be downloaded from this [semi-parsed version from kaggle](https://www.kaggle.com/netflix-inc/netflix-prize-data) or from this [raw version](https://archive.org/download/nf_prize_dataset.tar)\n",
    "\n",
    "**NOTE**: for the notebook to run properly, you should save you dataset under `data` folder and `movielens` folder for the movielens dataset and `netflix` folder for the netflixprize dataset.\n",
    "i.e `data/movielens` folder and `data/netflix` folder respectively."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "       user_id  item_id  rating  timestamp\n0            1        1       5  874965758\n1            1        2       3  876893171\n2            1        3       4  878542960\n3            1        4       3  876893119\n4            1        5       3  889751712\n...        ...      ...     ...        ...\n79995      943     1067       2  875501756\n79996      943     1074       4  888640250\n79997      943     1188       3  888640250\n79998      943     1228       3  888640275\n79999      943     1330       3  888692465\n\n[80000 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>874965758</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>876893171</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>878542960</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n      <td>876893119</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>3</td>\n      <td>889751712</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>79995</th>\n      <td>943</td>\n      <td>1067</td>\n      <td>2</td>\n      <td>875501756</td>\n    </tr>\n    <tr>\n      <th>79996</th>\n      <td>943</td>\n      <td>1074</td>\n      <td>4</td>\n      <td>888640250</td>\n    </tr>\n    <tr>\n      <th>79997</th>\n      <td>943</td>\n      <td>1188</td>\n      <td>3</td>\n      <td>888640250</td>\n    </tr>\n    <tr>\n      <th>79998</th>\n      <td>943</td>\n      <td>1228</td>\n      <td>3</td>\n      <td>888640275</td>\n    </tr>\n    <tr>\n      <th>79999</th>\n      <td>943</td>\n      <td>1330</td>\n      <td>3</td>\n      <td>888692465</td>\n    </tr>\n  </tbody>\n</table>\n<p>80000 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data_prep import movielens_load\n",
    "train, test = movielens_load(1)\n",
    "print(train.shape)\n",
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - Add dataloder class\n",
    "# - Add batch size\n",
    "# - Add bias for the MatrixFactorization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_items, k=15):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "\n",
    "        # create the latent matrixs\n",
    "        self.users_emb = nn.Embedding(num_users, k)\n",
    "        self.items_emb = nn.Embedding(num_items, k)\n",
    "\n",
    "        self.batch_size = 100\n",
    "\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        user = self.users_emb(user)\n",
    "        item = self.items_emb(item)\n",
    "        return (user*item).sum(axis=1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - add function that will calculate the validation loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def train_epocs(train, model, epochs=10, lr=0.001, reg=0):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=reg)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        # users and items indexes start 1, therefore we use the -1\n",
    "        users = torch.LongTensor(train.user_id.values-1).to(device)\n",
    "        items = torch.LongTensor(train.item_id.values-1).to(device)\n",
    "        ratings = torch.FloatTensor(train.rating.values).to(device) # rating is our label\n",
    "\n",
    "        preds = model(users, items)\n",
    "        loss = torch.sqrt(nn.functional.mse_loss(preds, ratings))\n",
    "\n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # update\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'train RMSE: {loss.item()}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 1682\n"
     ]
    }
   ],
   "source": [
    "num_users = train.user_id.max()\n",
    "num_items = train.item_id.max()\n",
    "print(num_users, num_items)\n",
    "model = MatrixFactorization(num_users, num_items).to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train RMSE: 5.363035202026367\n",
      "train RMSE: 5.3583760261535645\n",
      "train RMSE: 5.353726387023926\n",
      "train RMSE: 5.349086284637451\n",
      "train RMSE: 5.344456672668457\n",
      "train RMSE: 5.339837551116943\n",
      "train RMSE: 5.335227966308594\n",
      "train RMSE: 5.330629348754883\n",
      "train RMSE: 5.326040267944336\n",
      "train RMSE: 5.321462631225586\n",
      "train RMSE: 5.316894054412842\n",
      "train RMSE: 5.312336444854736\n",
      "train RMSE: 5.3077898025512695\n",
      "train RMSE: 5.303253650665283\n",
      "train RMSE: 5.298727989196777\n",
      "train RMSE: 5.29421329498291\n",
      "train RMSE: 5.28971004486084\n",
      "train RMSE: 5.285216808319092\n",
      "train RMSE: 5.280735492706299\n",
      "train RMSE: 5.276265621185303\n",
      "train RMSE: 5.271806240081787\n",
      "train RMSE: 5.267358303070068\n",
      "train RMSE: 5.2629218101501465\n",
      "train RMSE: 5.258496284484863\n",
      "train RMSE: 5.254081726074219\n",
      "train RMSE: 5.249679088592529\n",
      "train RMSE: 5.24528694152832\n",
      "train RMSE: 5.240906715393066\n",
      "train RMSE: 5.236537933349609\n",
      "train RMSE: 5.232179641723633\n",
      "train RMSE: 5.227833271026611\n",
      "train RMSE: 5.2234978675842285\n",
      "train RMSE: 5.219174385070801\n",
      "train RMSE: 5.2148613929748535\n",
      "train RMSE: 5.2105607986450195\n",
      "train RMSE: 5.206270694732666\n",
      "train RMSE: 5.201992511749268\n",
      "train RMSE: 5.197725296020508\n",
      "train RMSE: 5.193469524383545\n",
      "train RMSE: 5.189224720001221\n",
      "train RMSE: 5.18499231338501\n",
      "train RMSE: 5.180770397186279\n",
      "train RMSE: 5.176559925079346\n",
      "train RMSE: 5.172361373901367\n",
      "train RMSE: 5.168173789978027\n",
      "train RMSE: 5.163997650146484\n",
      "train RMSE: 5.15983247756958\n",
      "train RMSE: 5.155678749084473\n",
      "train RMSE: 5.151536464691162\n",
      "train RMSE: 5.147405624389648\n",
      "train RMSE: 5.143286228179932\n",
      "train RMSE: 5.1391777992248535\n",
      "train RMSE: 5.135080337524414\n",
      "train RMSE: 5.130993843078613\n",
      "train RMSE: 5.126919269561768\n",
      "train RMSE: 5.122855186462402\n",
      "train RMSE: 5.118802547454834\n",
      "train RMSE: 5.114760875701904\n",
      "train RMSE: 5.110729694366455\n",
      "train RMSE: 5.106710433959961\n",
      "train RMSE: 5.102701187133789\n",
      "train RMSE: 5.098703384399414\n",
      "train RMSE: 5.094716548919678\n",
      "train RMSE: 5.09074068069458\n",
      "train RMSE: 5.086775302886963\n",
      "train RMSE: 5.082820892333984\n",
      "train RMSE: 5.0788774490356445\n",
      "train RMSE: 5.074944496154785\n",
      "train RMSE: 5.0710225105285645\n",
      "train RMSE: 5.067111015319824\n",
      "train RMSE: 5.0632100105285645\n",
      "train RMSE: 5.059320449829102\n",
      "train RMSE: 5.055440425872803\n",
      "train RMSE: 5.051571369171143\n",
      "train RMSE: 5.047712802886963\n",
      "train RMSE: 5.043864727020264\n",
      "train RMSE: 5.040027141571045\n",
      "train RMSE: 5.036200046539307\n",
      "train RMSE: 5.032382965087891\n",
      "train RMSE: 5.028576850891113\n",
      "train RMSE: 5.0247802734375\n",
      "train RMSE: 5.020994663238525\n",
      "train RMSE: 5.017219066619873\n",
      "train RMSE: 5.013453483581543\n",
      "train RMSE: 5.009698390960693\n",
      "train RMSE: 5.005953311920166\n",
      "train RMSE: 5.002218723297119\n",
      "train RMSE: 4.998493671417236\n",
      "train RMSE: 4.994779109954834\n",
      "train RMSE: 4.991074085235596\n",
      "train RMSE: 4.987379550933838\n",
      "train RMSE: 4.983695030212402\n",
      "train RMSE: 4.980020523071289\n",
      "train RMSE: 4.97635555267334\n",
      "train RMSE: 4.972701072692871\n",
      "train RMSE: 4.969056129455566\n",
      "train RMSE: 4.965421199798584\n",
      "train RMSE: 4.961796283721924\n",
      "train RMSE: 4.958180904388428\n",
      "train RMSE: 4.954575538635254\n",
      "train RMSE: 4.950979709625244\n",
      "train RMSE: 4.947393417358398\n",
      "train RMSE: 4.943817138671875\n",
      "train RMSE: 4.940250873565674\n",
      "train RMSE: 4.9366936683654785\n",
      "train RMSE: 4.933145999908447\n",
      "train RMSE: 4.929608345031738\n",
      "train RMSE: 4.926080226898193\n",
      "train RMSE: 4.9225616455078125\n",
      "train RMSE: 4.919052600860596\n",
      "train RMSE: 4.915552616119385\n",
      "train RMSE: 4.912062168121338\n",
      "train RMSE: 4.908581256866455\n",
      "train RMSE: 4.9051103591918945\n",
      "train RMSE: 4.901648044586182\n",
      "train RMSE: 4.898195266723633\n",
      "train RMSE: 4.894752025604248\n",
      "train RMSE: 4.891317844390869\n",
      "train RMSE: 4.887892723083496\n",
      "train RMSE: 4.884477138519287\n",
      "train RMSE: 4.881070613861084\n",
      "train RMSE: 4.877673625946045\n",
      "train RMSE: 4.874285697937012\n",
      "train RMSE: 4.870906829833984\n",
      "train RMSE: 4.867537021636963\n",
      "train RMSE: 4.864176273345947\n",
      "train RMSE: 4.860825061798096\n",
      "train RMSE: 4.857481956481934\n",
      "train RMSE: 4.854148864746094\n",
      "train RMSE: 4.850823879241943\n",
      "train RMSE: 4.847508430480957\n",
      "train RMSE: 4.844201564788818\n",
      "train RMSE: 4.840904235839844\n",
      "train RMSE: 4.837615013122559\n",
      "train RMSE: 4.8343353271484375\n",
      "train RMSE: 4.831064224243164\n",
      "train RMSE: 4.827801704406738\n",
      "train RMSE: 4.824548244476318\n",
      "train RMSE: 4.821303367614746\n",
      "train RMSE: 4.81806755065918\n",
      "train RMSE: 4.814840316772461\n",
      "train RMSE: 4.81162166595459\n",
      "train RMSE: 4.808412075042725\n",
      "train RMSE: 4.805210590362549\n",
      "train RMSE: 4.802018165588379\n",
      "train RMSE: 4.798833847045898\n",
      "train RMSE: 4.795658588409424\n",
      "train RMSE: 4.792491436004639\n",
      "train RMSE: 4.789333343505859\n",
      "train RMSE: 4.7861833572387695\n",
      "train RMSE: 4.7830424308776855\n",
      "train RMSE: 4.779909610748291\n",
      "train RMSE: 4.776784896850586\n",
      "train RMSE: 4.7736687660217285\n",
      "train RMSE: 4.770561218261719\n",
      "train RMSE: 4.767462253570557\n",
      "train RMSE: 4.764371395111084\n",
      "train RMSE: 4.761288642883301\n",
      "train RMSE: 4.758214473724365\n",
      "train RMSE: 4.755148887634277\n",
      "train RMSE: 4.752090930938721\n",
      "train RMSE: 4.749041557312012\n",
      "train RMSE: 4.746000289916992\n",
      "train RMSE: 4.742967128753662\n",
      "train RMSE: 4.73994255065918\n",
      "train RMSE: 4.7369256019592285\n",
      "train RMSE: 4.733917236328125\n",
      "train RMSE: 4.730916500091553\n",
      "train RMSE: 4.727924346923828\n",
      "train RMSE: 4.724939823150635\n",
      "train RMSE: 4.721963882446289\n",
      "train RMSE: 4.718995571136475\n",
      "train RMSE: 4.71603536605835\n",
      "train RMSE: 4.713082790374756\n",
      "train RMSE: 4.710138320922852\n",
      "train RMSE: 4.707202434539795\n",
      "train RMSE: 4.704273700714111\n",
      "train RMSE: 4.701353073120117\n",
      "train RMSE: 4.6984405517578125\n",
      "train RMSE: 4.695535182952881\n",
      "train RMSE: 4.692638397216797\n",
      "train RMSE: 4.689749240875244\n",
      "train RMSE: 4.686867713928223\n",
      "train RMSE: 4.683993816375732\n",
      "train RMSE: 4.68112850189209\n",
      "train RMSE: 4.67827033996582\n",
      "train RMSE: 4.675419807434082\n",
      "train RMSE: 4.672576427459717\n",
      "train RMSE: 4.669741630554199\n",
      "train RMSE: 4.666913986206055\n",
      "train RMSE: 4.664093971252441\n",
      "train RMSE: 4.661282062530518\n",
      "train RMSE: 4.658476829528809\n",
      "train RMSE: 4.655680179595947\n",
      "train RMSE: 4.652890205383301\n",
      "train RMSE: 4.650108337402344\n",
      "train RMSE: 4.64733362197876\n",
      "train RMSE: 4.644566535949707\n",
      "train RMSE: 4.6418070793151855\n",
      "train RMSE: 4.639054775238037\n",
      "train RMSE: 4.636309623718262\n",
      "train RMSE: 4.633572578430176\n",
      "train RMSE: 4.630842208862305\n",
      "train RMSE: 4.628119468688965\n",
      "train RMSE: 4.625404357910156\n",
      "train RMSE: 4.622696399688721\n",
      "train RMSE: 4.619995594024658\n",
      "train RMSE: 4.617302417755127\n",
      "train RMSE: 4.6146159172058105\n",
      "train RMSE: 4.611937046051025\n",
      "train RMSE: 4.609265327453613\n",
      "train RMSE: 4.606601238250732\n",
      "train RMSE: 4.603943824768066\n",
      "train RMSE: 4.601293563842773\n",
      "train RMSE: 4.5986504554748535\n",
      "train RMSE: 4.596014499664307\n",
      "train RMSE: 4.593385696411133\n",
      "train RMSE: 4.590764045715332\n",
      "train RMSE: 4.588149547576904\n",
      "train RMSE: 4.585541725158691\n",
      "train RMSE: 4.58294153213501\n",
      "train RMSE: 4.580348014831543\n",
      "train RMSE: 4.577761650085449\n",
      "train RMSE: 4.57518196105957\n",
      "train RMSE: 4.5726094245910645\n",
      "train RMSE: 4.570043563842773\n",
      "train RMSE: 4.5674848556518555\n",
      "train RMSE: 4.5649333000183105\n",
      "train RMSE: 4.5623884201049805\n",
      "train RMSE: 4.559850215911865\n",
      "train RMSE: 4.557318687438965\n",
      "train RMSE: 4.554794788360596\n",
      "train RMSE: 4.552277088165283\n",
      "train RMSE: 4.549766540527344\n",
      "train RMSE: 4.547262191772461\n",
      "train RMSE: 4.544764995574951\n",
      "train RMSE: 4.542274475097656\n",
      "train RMSE: 4.539790630340576\n",
      "train RMSE: 4.537313461303711\n",
      "train RMSE: 4.5348429679870605\n",
      "train RMSE: 4.532379627227783\n",
      "train RMSE: 4.5299224853515625\n",
      "train RMSE: 4.527472019195557\n",
      "train RMSE: 4.525027751922607\n",
      "train RMSE: 4.522590637207031\n",
      "train RMSE: 4.52016019821167\n",
      "train RMSE: 4.517735958099365\n",
      "train RMSE: 4.515318393707275\n",
      "train RMSE: 4.512907028198242\n",
      "train RMSE: 4.510502338409424\n",
      "train RMSE: 4.5081048011779785\n",
      "train RMSE: 4.505712985992432\n",
      "train RMSE: 4.5033278465271\n",
      "train RMSE: 4.500948905944824\n",
      "train RMSE: 4.498577117919922\n",
      "train RMSE: 4.496211051940918\n",
      "train RMSE: 4.493851661682129\n",
      "train RMSE: 4.4914984703063965\n",
      "train RMSE: 4.489151477813721\n",
      "train RMSE: 4.48681116104126\n",
      "train RMSE: 4.4844770431518555\n",
      "train RMSE: 4.482149124145508\n",
      "train RMSE: 4.479827404022217\n",
      "train RMSE: 4.477512359619141\n",
      "train RMSE: 4.475203514099121\n",
      "train RMSE: 4.472900390625\n",
      "train RMSE: 4.470603942871094\n",
      "train RMSE: 4.468313694000244\n",
      "train RMSE: 4.466029644012451\n",
      "train RMSE: 4.463751316070557\n",
      "train RMSE: 4.461479663848877\n",
      "train RMSE: 4.459213733673096\n",
      "train RMSE: 4.456954002380371\n",
      "train RMSE: 4.454700946807861\n",
      "train RMSE: 4.452453136444092\n",
      "train RMSE: 4.450212001800537\n",
      "train RMSE: 4.447976589202881\n",
      "train RMSE: 4.445746898651123\n",
      "train RMSE: 4.44352388381958\n",
      "train RMSE: 4.441307067871094\n",
      "train RMSE: 4.439095497131348\n",
      "train RMSE: 4.436890125274658\n",
      "train RMSE: 4.434690952301025\n",
      "train RMSE: 4.432497501373291\n",
      "train RMSE: 4.430309772491455\n",
      "train RMSE: 4.428128719329834\n",
      "train RMSE: 4.425952911376953\n",
      "train RMSE: 4.423783302307129\n",
      "train RMSE: 4.421618938446045\n",
      "train RMSE: 4.419460773468018\n",
      "train RMSE: 4.417308807373047\n",
      "train RMSE: 4.415162086486816\n",
      "train RMSE: 4.413021564483643\n",
      "train RMSE: 4.410886287689209\n",
      "train RMSE: 4.40875768661499\n",
      "train RMSE: 4.406634330749512\n",
      "train RMSE: 4.404516220092773\n",
      "train RMSE: 4.402404308319092\n",
      "train RMSE: 4.400298118591309\n",
      "train RMSE: 4.398197650909424\n",
      "train RMSE: 4.3961029052734375\n",
      "train RMSE: 4.394013404846191\n",
      "train RMSE: 4.391930103302002\n",
      "train RMSE: 4.389852523803711\n",
      "train RMSE: 4.387779712677002\n",
      "train RMSE: 4.38571310043335\n",
      "train RMSE: 4.3836517333984375\n",
      "train RMSE: 4.381596565246582\n",
      "train RMSE: 4.379546165466309\n",
      "train RMSE: 4.377501487731934\n",
      "train RMSE: 4.375463008880615\n",
      "train RMSE: 4.373429298400879\n",
      "train RMSE: 4.371401309967041\n",
      "train RMSE: 4.369378566741943\n",
      "train RMSE: 4.367361545562744\n",
      "train RMSE: 4.365350246429443\n",
      "train RMSE: 4.363344192504883\n",
      "train RMSE: 4.3613433837890625\n",
      "train RMSE: 4.359347820281982\n",
      "train RMSE: 4.357357978820801\n",
      "train RMSE: 4.355373382568359\n",
      "train RMSE: 4.353394031524658\n",
      "train RMSE: 4.351419925689697\n",
      "train RMSE: 4.349451541900635\n",
      "train RMSE: 4.3474884033203125\n",
      "train RMSE: 4.3455305099487305\n",
      "train RMSE: 4.343577861785889\n",
      "train RMSE: 4.341630458831787\n",
      "train RMSE: 4.339688301086426\n",
      "train RMSE: 4.337751388549805\n",
      "train RMSE: 4.335819721221924\n",
      "train RMSE: 4.333893299102783\n",
      "train RMSE: 4.331972122192383\n",
      "train RMSE: 4.3300557136535645\n",
      "train RMSE: 4.3281450271606445\n",
      "train RMSE: 4.326239109039307\n",
      "train RMSE: 4.324338912963867\n",
      "train RMSE: 4.322443008422852\n",
      "train RMSE: 4.320552825927734\n",
      "train RMSE: 4.318667888641357\n",
      "train RMSE: 4.316787242889404\n",
      "train RMSE: 4.31491231918335\n",
      "train RMSE: 4.313042163848877\n",
      "train RMSE: 4.3111772537231445\n",
      "train RMSE: 4.309317111968994\n",
      "train RMSE: 4.307462215423584\n",
      "train RMSE: 4.305612564086914\n",
      "train RMSE: 4.303767204284668\n",
      "train RMSE: 4.30192756652832\n",
      "train RMSE: 4.3000922203063965\n",
      "train RMSE: 4.298262596130371\n",
      "train RMSE: 4.296437740325928\n",
      "train RMSE: 4.294617176055908\n",
      "train RMSE: 4.292801856994629\n",
      "train RMSE: 4.290991306304932\n",
      "train RMSE: 4.289186000823975\n",
      "train RMSE: 4.287384986877441\n",
      "train RMSE: 4.285589694976807\n",
      "train RMSE: 4.283798694610596\n",
      "train RMSE: 4.282012462615967\n",
      "train RMSE: 4.28023099899292\n",
      "train RMSE: 4.278454780578613\n",
      "train RMSE: 4.2766828536987305\n",
      "train RMSE: 4.27491569519043\n",
      "train RMSE: 4.273153781890869\n",
      "train RMSE: 4.271396160125732\n",
      "train RMSE: 4.269643783569336\n",
      "train RMSE: 4.267895221710205\n",
      "train RMSE: 4.266152381896973\n",
      "train RMSE: 4.264413833618164\n",
      "train RMSE: 4.2626800537109375\n",
      "train RMSE: 4.260950565338135\n",
      "train RMSE: 4.259225845336914\n",
      "train RMSE: 4.257505893707275\n",
      "train RMSE: 4.255790710449219\n",
      "train RMSE: 4.254080295562744\n",
      "train RMSE: 4.252374172210693\n",
      "train RMSE: 4.250672817230225\n",
      "train RMSE: 4.24897575378418\n",
      "train RMSE: 4.247283935546875\n",
      "train RMSE: 4.245595932006836\n",
      "train RMSE: 4.243912696838379\n",
      "train RMSE: 4.242234230041504\n",
      "train RMSE: 4.2405595779418945\n",
      "train RMSE: 4.238890171051025\n",
      "train RMSE: 4.23722505569458\n",
      "train RMSE: 4.235564231872559\n",
      "train RMSE: 4.233908176422119\n",
      "train RMSE: 4.2322564125061035\n",
      "train RMSE: 4.230608940124512\n",
      "train RMSE: 4.228965759277344\n",
      "train RMSE: 4.227327823638916\n",
      "train RMSE: 4.225693702697754\n",
      "train RMSE: 4.224063873291016\n",
      "train RMSE: 4.222438335418701\n",
      "train RMSE: 4.220817565917969\n",
      "train RMSE: 4.21920108795166\n",
      "train RMSE: 4.217588901519775\n",
      "train RMSE: 4.2159810066223145\n",
      "train RMSE: 4.214377403259277\n",
      "train RMSE: 4.212778568267822\n",
      "train RMSE: 4.211183071136475\n",
      "train RMSE: 4.209592819213867\n",
      "train RMSE: 4.208005905151367\n",
      "train RMSE: 4.206423759460449\n",
      "train RMSE: 4.204846382141113\n",
      "train RMSE: 4.203272342681885\n",
      "train RMSE: 4.201703071594238\n",
      "train RMSE: 4.200138092041016\n",
      "train RMSE: 4.198576927185059\n",
      "train RMSE: 4.197020053863525\n",
      "train RMSE: 4.195467472076416\n",
      "train RMSE: 4.193918704986572\n",
      "train RMSE: 4.1923747062683105\n",
      "train RMSE: 4.1908345222473145\n",
      "train RMSE: 4.189298152923584\n",
      "train RMSE: 4.1877665519714355\n",
      "train RMSE: 4.186238765716553\n",
      "train RMSE: 4.1847147941589355\n",
      "train RMSE: 4.183195114135742\n",
      "train RMSE: 4.181679725646973\n",
      "train RMSE: 4.180168151855469\n",
      "train RMSE: 4.178660869598389\n",
      "train RMSE: 4.177157402038574\n",
      "train RMSE: 4.175657749176025\n",
      "train RMSE: 4.1741623878479\n",
      "train RMSE: 4.172671318054199\n",
      "train RMSE: 4.171184062957764\n",
      "train RMSE: 4.169700622558594\n",
      "train RMSE: 4.1682209968566895\n",
      "train RMSE: 4.166745662689209\n",
      "train RMSE: 4.165274143218994\n",
      "train RMSE: 4.163806438446045\n",
      "train RMSE: 4.1623430252075195\n",
      "train RMSE: 4.16088342666626\n",
      "train RMSE: 4.159427165985107\n",
      "train RMSE: 4.157975196838379\n",
      "train RMSE: 4.156527042388916\n",
      "train RMSE: 4.155083179473877\n",
      "train RMSE: 4.153642654418945\n",
      "train RMSE: 4.152205944061279\n",
      "train RMSE: 4.150773525238037\n",
      "train RMSE: 4.1493449211120605\n",
      "train RMSE: 4.14792013168335\n",
      "train RMSE: 4.146498680114746\n",
      "train RMSE: 4.145081520080566\n",
      "train RMSE: 4.143667697906494\n",
      "train RMSE: 4.1422576904296875\n",
      "train RMSE: 4.1408514976501465\n",
      "train RMSE: 4.139449596405029\n",
      "train RMSE: 4.1380510330200195\n",
      "train RMSE: 4.136656284332275\n",
      "train RMSE: 4.135264873504639\n",
      "train RMSE: 4.133877754211426\n",
      "train RMSE: 4.13249397277832\n",
      "train RMSE: 4.1311140060424805\n",
      "train RMSE: 4.129737377166748\n",
      "train RMSE: 4.1283650398254395\n",
      "train RMSE: 4.12699556350708\n",
      "train RMSE: 4.1256303787231445\n",
      "train RMSE: 4.124268531799316\n",
      "train RMSE: 4.122910499572754\n",
      "train RMSE: 4.121556282043457\n",
      "train RMSE: 4.120204925537109\n",
      "train RMSE: 4.1188578605651855\n",
      "train RMSE: 4.117514133453369\n",
      "train RMSE: 4.11617374420166\n",
      "train RMSE: 4.114837169647217\n",
      "train RMSE: 4.113503932952881\n",
      "train RMSE: 4.1121745109558105\n",
      "train RMSE: 4.110848903656006\n",
      "train RMSE: 4.10952615737915\n",
      "train RMSE: 4.108207702636719\n",
      "train RMSE: 4.106892108917236\n",
      "train RMSE: 4.105579853057861\n",
      "train RMSE: 4.104271411895752\n",
      "train RMSE: 4.10296630859375\n",
      "train RMSE: 4.101665019989014\n",
      "train RMSE: 4.100367069244385\n",
      "train RMSE: 4.099071979522705\n",
      "train RMSE: 4.097781181335449\n",
      "train RMSE: 4.096493244171143\n",
      "train RMSE: 4.095208644866943\n",
      "train RMSE: 4.09392786026001\n",
      "train RMSE: 4.092650413513184\n",
      "train RMSE: 4.091376304626465\n",
      "train RMSE: 4.0901055335998535\n",
      "train RMSE: 4.088837623596191\n",
      "train RMSE: 4.087574005126953\n",
      "train RMSE: 4.086312770843506\n",
      "train RMSE: 4.085055828094482\n",
      "train RMSE: 4.08380126953125\n",
      "train RMSE: 4.082550525665283\n",
      "train RMSE: 4.081303119659424\n",
      "train RMSE: 4.080059051513672\n",
      "train RMSE: 4.078817844390869\n",
      "train RMSE: 4.077580451965332\n",
      "train RMSE: 4.076345920562744\n",
      "train RMSE: 4.075114727020264\n",
      "train RMSE: 4.073886871337891\n",
      "train RMSE: 4.072662353515625\n",
      "train RMSE: 4.071441173553467\n",
      "train RMSE: 4.0702223777771\n",
      "train RMSE: 4.069007873535156\n",
      "train RMSE: 4.067795753479004\n",
      "train RMSE: 4.066587448120117\n",
      "train RMSE: 4.06538200378418\n",
      "train RMSE: 4.064179420471191\n",
      "train RMSE: 4.0629801750183105\n",
      "train RMSE: 4.061784267425537\n",
      "train RMSE: 4.060591697692871\n",
      "train RMSE: 4.059401988983154\n",
      "train RMSE: 4.058215618133545\n",
      "train RMSE: 4.057032108306885\n",
      "train RMSE: 4.055851936340332\n",
      "train RMSE: 4.0546746253967285\n",
      "train RMSE: 4.053500175476074\n",
      "train RMSE: 4.0523295402526855\n",
      "train RMSE: 4.051161289215088\n",
      "train RMSE: 4.049996376037598\n",
      "train RMSE: 4.048834800720215\n",
      "train RMSE: 4.047675609588623\n",
      "train RMSE: 4.046520233154297\n",
      "train RMSE: 4.045367240905762\n",
      "train RMSE: 4.044217586517334\n",
      "train RMSE: 4.0430707931518555\n",
      "train RMSE: 4.041926860809326\n",
      "train RMSE: 4.040786266326904\n",
      "train RMSE: 4.039648056030273\n",
      "train RMSE: 4.038513660430908\n",
      "train RMSE: 4.037381649017334\n",
      "train RMSE: 4.036252975463867\n",
      "train RMSE: 4.03512716293335\n",
      "train RMSE: 4.034003734588623\n",
      "train RMSE: 4.032883644104004\n",
      "train RMSE: 4.031766414642334\n",
      "train RMSE: 4.030652046203613\n",
      "train RMSE: 4.029541015625\n",
      "train RMSE: 4.028432369232178\n",
      "train RMSE: 4.027326583862305\n",
      "train RMSE: 4.026224136352539\n",
      "train RMSE: 4.0251240730285645\n",
      "train RMSE: 4.024026870727539\n",
      "train RMSE: 4.022933006286621\n",
      "train RMSE: 4.021841526031494\n",
      "train RMSE: 4.020753383636475\n",
      "train RMSE: 4.019667625427246\n",
      "train RMSE: 4.018584728240967\n",
      "train RMSE: 4.017504692077637\n",
      "train RMSE: 4.016427040100098\n",
      "train RMSE: 4.015352725982666\n",
      "train RMSE: 4.014281272888184\n",
      "train RMSE: 4.013212203979492\n",
      "train RMSE: 4.01214599609375\n",
      "train RMSE: 4.011082649230957\n",
      "train RMSE: 4.010021686553955\n",
      "train RMSE: 4.0089640617370605\n",
      "train RMSE: 4.007908821105957\n",
      "train RMSE: 4.006856441497803\n",
      "train RMSE: 4.005806922912598\n",
      "train RMSE: 4.004759788513184\n",
      "train RMSE: 4.0037150382995605\n",
      "train RMSE: 4.002673625946045\n",
      "train RMSE: 4.00163459777832\n",
      "train RMSE: 4.000597953796387\n",
      "train RMSE: 3.9995644092559814\n",
      "train RMSE: 3.9985334873199463\n",
      "train RMSE: 3.9975051879882812\n",
      "train RMSE: 3.9964795112609863\n",
      "train RMSE: 3.9954564571380615\n",
      "train RMSE: 3.994436025619507\n",
      "train RMSE: 3.993417978286743\n",
      "train RMSE: 3.9924027919769287\n",
      "train RMSE: 3.9913902282714844\n",
      "train RMSE: 3.990379810333252\n",
      "train RMSE: 3.989372491836548\n",
      "train RMSE: 3.988367795944214\n",
      "train RMSE: 3.987365245819092\n",
      "train RMSE: 3.986365795135498\n",
      "train RMSE: 3.985368490219116\n",
      "train RMSE: 3.9843735694885254\n",
      "train RMSE: 3.983381509780884\n",
      "train RMSE: 3.9823920726776123\n",
      "train RMSE: 3.9814047813415527\n",
      "train RMSE: 3.9804203510284424\n",
      "train RMSE: 3.979438066482544\n",
      "train RMSE: 3.9784584045410156\n",
      "train RMSE: 3.9774816036224365\n",
      "train RMSE: 3.9765067100524902\n",
      "train RMSE: 3.975534677505493\n",
      "train RMSE: 3.974565029144287\n",
      "train RMSE: 3.973597526550293\n",
      "train RMSE: 3.972632884979248\n",
      "train RMSE: 3.971670627593994\n",
      "train RMSE: 3.9707107543945312\n",
      "train RMSE: 3.9697532653808594\n",
      "train RMSE: 3.9687981605529785\n",
      "train RMSE: 3.9678452014923096\n",
      "train RMSE: 3.9668948650360107\n",
      "train RMSE: 3.965947151184082\n",
      "train RMSE: 3.9650018215179443\n",
      "train RMSE: 3.9640586376190186\n",
      "train RMSE: 3.963118076324463\n",
      "train RMSE: 3.962179660797119\n",
      "train RMSE: 3.9612436294555664\n",
      "train RMSE: 3.9603099822998047\n",
      "train RMSE: 3.959378480911255\n",
      "train RMSE: 3.958449602127075\n",
      "train RMSE: 3.9575228691101074\n",
      "train RMSE: 3.9565985202789307\n",
      "train RMSE: 3.955676794052124\n",
      "train RMSE: 3.954756736755371\n",
      "train RMSE: 3.9538395404815674\n",
      "train RMSE: 3.9529244899749756\n",
      "train RMSE: 3.952011823654175\n",
      "train RMSE: 3.9511008262634277\n",
      "train RMSE: 3.950192451477051\n",
      "train RMSE: 3.949286699295044\n",
      "train RMSE: 3.94838285446167\n",
      "train RMSE: 3.947481393814087\n",
      "train RMSE: 3.9465818405151367\n",
      "train RMSE: 3.9456846714019775\n",
      "train RMSE: 3.9447898864746094\n",
      "train RMSE: 3.9438974857330322\n",
      "train RMSE: 3.943006753921509\n",
      "train RMSE: 3.9421186447143555\n",
      "train RMSE: 3.941232681274414\n",
      "train RMSE: 3.9403488636016846\n",
      "train RMSE: 3.939467191696167\n",
      "train RMSE: 3.9385879039764404\n",
      "train RMSE: 3.9377105236053467\n",
      "train RMSE: 3.936835289001465\n",
      "train RMSE: 3.935962200164795\n",
      "train RMSE: 3.935091495513916\n",
      "train RMSE: 3.93422269821167\n",
      "train RMSE: 3.9333558082580566\n",
      "train RMSE: 3.9324915409088135\n",
      "train RMSE: 3.9316294193267822\n",
      "train RMSE: 3.930769205093384\n",
      "train RMSE: 3.929910898208618\n",
      "train RMSE: 3.9290549755096436\n",
      "train RMSE: 3.9282009601593018\n",
      "train RMSE: 3.927349090576172\n",
      "train RMSE: 3.926499366760254\n",
      "train RMSE: 3.9256515502929688\n",
      "train RMSE: 3.9248061180114746\n",
      "train RMSE: 3.923962116241455\n",
      "train RMSE: 3.9231207370758057\n",
      "train RMSE: 3.922281265258789\n",
      "train RMSE: 3.9214437007904053\n",
      "train RMSE: 3.9206080436706543\n",
      "train RMSE: 3.9197750091552734\n",
      "train RMSE: 3.918943405151367\n",
      "train RMSE: 3.918113946914673\n",
      "train RMSE: 3.9172866344451904\n",
      "train RMSE: 3.916461229324341\n",
      "train RMSE: 3.915637731552124\n",
      "train RMSE: 3.914816379547119\n",
      "train RMSE: 3.913996934890747\n",
      "train RMSE: 3.9131791591644287\n",
      "train RMSE: 3.9123637676239014\n",
      "train RMSE: 3.9115500450134277\n",
      "train RMSE: 3.910738468170166\n",
      "train RMSE: 3.909928798675537\n",
      "train RMSE: 3.909120559692383\n",
      "train RMSE: 3.9083149433135986\n",
      "train RMSE: 3.9075112342834473\n",
      "train RMSE: 3.9067091941833496\n",
      "train RMSE: 3.9059088230133057\n",
      "train RMSE: 3.9051108360290527\n",
      "train RMSE: 3.9043145179748535\n",
      "train RMSE: 3.903520107269287\n",
      "train RMSE: 3.9027273654937744\n",
      "train RMSE: 3.9019365310668945\n",
      "train RMSE: 3.9011480808258057\n",
      "train RMSE: 3.9003608226776123\n",
      "train RMSE: 3.899575710296631\n",
      "train RMSE: 3.8987925052642822\n",
      "train RMSE: 3.8980109691619873\n",
      "train RMSE: 3.8972315788269043\n",
      "train RMSE: 3.896453619003296\n",
      "train RMSE: 3.8956778049468994\n",
      "train RMSE: 3.8949036598205566\n",
      "train RMSE: 3.8941314220428467\n",
      "train RMSE: 3.8933608531951904\n",
      "train RMSE: 3.892592191696167\n",
      "train RMSE: 3.8918251991271973\n",
      "train RMSE: 3.8910601139068604\n",
      "train RMSE: 3.890296459197998\n",
      "train RMSE: 3.8895351886749268\n",
      "train RMSE: 3.88877534866333\n",
      "train RMSE: 3.888017177581787\n",
      "train RMSE: 3.887260913848877\n",
      "train RMSE: 3.8865063190460205\n",
      "train RMSE: 3.885753631591797\n",
      "train RMSE: 3.885002374649048\n",
      "train RMSE: 3.8842527866363525\n",
      "train RMSE: 3.88350510597229\n",
      "train RMSE: 3.8827593326568604\n",
      "train RMSE: 3.8820149898529053\n",
      "train RMSE: 3.881272554397583\n",
      "train RMSE: 3.8805317878723145\n",
      "train RMSE: 3.8797924518585205\n",
      "train RMSE: 3.8790550231933594\n",
      "train RMSE: 3.878319025039673\n",
      "train RMSE: 3.877584934234619\n",
      "train RMSE: 3.876852512359619\n",
      "train RMSE: 3.8761215209960938\n",
      "train RMSE: 3.8753926753997803\n",
      "train RMSE: 3.8746650218963623\n",
      "train RMSE: 3.873938798904419\n",
      "train RMSE: 3.8732147216796875\n",
      "train RMSE: 3.8724923133850098\n",
      "train RMSE: 3.8717710971832275\n",
      "train RMSE: 3.871051788330078\n",
      "train RMSE: 3.8703341484069824\n",
      "train RMSE: 3.8696179389953613\n",
      "train RMSE: 3.868903160095215\n",
      "train RMSE: 3.868190288543701\n",
      "train RMSE: 3.867479085922241\n",
      "train RMSE: 3.8667690753936768\n",
      "train RMSE: 3.866060495376587\n",
      "train RMSE: 3.865354061126709\n",
      "train RMSE: 3.8646490573883057\n",
      "train RMSE: 3.863945245742798\n",
      "train RMSE: 3.863243341445923\n",
      "train RMSE: 3.8625428676605225\n",
      "train RMSE: 3.8618438243865967\n",
      "train RMSE: 3.8611466884613037\n",
      "train RMSE: 3.860450506210327\n",
      "train RMSE: 3.8597562313079834\n",
      "train RMSE: 3.859063148498535\n",
      "train RMSE: 3.8583719730377197\n",
      "train RMSE: 3.8576819896698\n",
      "train RMSE: 3.8569936752319336\n",
      "train RMSE: 3.856306791305542\n",
      "train RMSE: 3.855621337890625\n",
      "train RMSE: 3.8549375534057617\n",
      "train RMSE: 3.854254961013794\n",
      "train RMSE: 3.85357403755188\n",
      "train RMSE: 3.8528945446014404\n",
      "train RMSE: 3.8522164821624756\n",
      "train RMSE: 3.8515398502349854\n",
      "train RMSE: 3.8508646488189697\n",
      "train RMSE: 3.8501908779144287\n",
      "train RMSE: 3.8495185375213623\n",
      "train RMSE: 3.8488476276397705\n",
      "train RMSE: 3.8481781482696533\n",
      "train RMSE: 3.8475100994110107\n",
      "train RMSE: 3.8468434810638428\n",
      "train RMSE: 3.8461782932281494\n",
      "train RMSE: 3.8455142974853516\n",
      "train RMSE: 3.8448517322540283\n",
      "train RMSE: 3.844190835952759\n",
      "train RMSE: 3.8435311317443848\n",
      "train RMSE: 3.8428728580474854\n",
      "train RMSE: 3.8422157764434814\n",
      "train RMSE: 3.841560125350952\n",
      "train RMSE: 3.8409059047698975\n",
      "train RMSE: 3.8402531147003174\n",
      "train RMSE: 3.8396012783050537\n",
      "train RMSE: 3.8389511108398438\n",
      "train RMSE: 3.8383021354675293\n",
      "train RMSE: 3.8376545906066895\n",
      "train RMSE: 3.837008476257324\n",
      "train RMSE: 3.8363635540008545\n",
      "train RMSE: 3.8357198238372803\n",
      "train RMSE: 3.8350775241851807\n",
      "train RMSE: 3.8344366550445557\n",
      "train RMSE: 3.833796739578247\n",
      "train RMSE: 3.833158254623413\n",
      "train RMSE: 3.8325212001800537\n",
      "train RMSE: 3.83188533782959\n",
      "train RMSE: 3.8312506675720215\n",
      "train RMSE: 3.8306174278259277\n",
      "train RMSE: 3.8299851417541504\n",
      "train RMSE: 3.8293545246124268\n",
      "train RMSE: 3.8287248611450195\n",
      "train RMSE: 3.828096389770508\n",
      "train RMSE: 3.8274693489074707\n",
      "train RMSE: 3.826843500137329\n",
      "train RMSE: 3.826218843460083\n",
      "train RMSE: 3.8255953788757324\n",
      "train RMSE: 3.8249731063842773\n",
      "train RMSE: 3.824352264404297\n",
      "train RMSE: 3.823732614517212\n",
      "train RMSE: 3.8231139183044434\n",
      "train RMSE: 3.822496175765991\n",
      "train RMSE: 3.821880340576172\n",
      "train RMSE: 3.82126522064209\n",
      "train RMSE: 3.820651054382324\n",
      "train RMSE: 3.8200385570526123\n",
      "train RMSE: 3.819427013397217\n",
      "train RMSE: 3.818816661834717\n",
      "train RMSE: 3.8182075023651123\n",
      "train RMSE: 3.817599296569824\n",
      "train RMSE: 3.8169925212860107\n",
      "train RMSE: 3.8163866996765137\n",
      "train RMSE: 3.815782070159912\n",
      "train RMSE: 3.815178394317627\n",
      "train RMSE: 3.8145759105682373\n",
      "train RMSE: 3.813974618911743\n",
      "train RMSE: 3.8133747577667236\n",
      "train RMSE: 3.8127756118774414\n",
      "train RMSE: 3.8121776580810547\n",
      "train RMSE: 3.8115806579589844\n",
      "train RMSE: 3.8109848499298096\n",
      "train RMSE: 3.8103902339935303\n",
      "train RMSE: 3.8097965717315674\n",
      "train RMSE: 3.809203863143921\n",
      "train RMSE: 3.80861234664917\n",
      "train RMSE: 3.8080220222473145\n",
      "train RMSE: 3.8074326515197754\n",
      "train RMSE: 3.8068442344665527\n",
      "train RMSE: 3.8062572479248047\n",
      "train RMSE: 3.805670738220215\n",
      "train RMSE: 3.8050856590270996\n",
      "train RMSE: 3.804501533508301\n",
      "train RMSE: 3.8039183616638184\n",
      "train RMSE: 3.8033361434936523\n",
      "train RMSE: 3.802755117416382\n",
      "train RMSE: 3.8021750450134277\n",
      "train RMSE: 3.80159592628479\n",
      "train RMSE: 3.8010177612304688\n",
      "train RMSE: 3.800440788269043\n",
      "train RMSE: 3.7998647689819336\n",
      "train RMSE: 3.7992894649505615\n",
      "train RMSE: 3.798715353012085\n",
      "train RMSE: 3.798142194747925\n",
      "train RMSE: 3.797569990158081\n",
      "train RMSE: 3.7969985008239746\n",
      "train RMSE: 3.7964282035827637\n",
      "train RMSE: 3.795858860015869\n",
      "train RMSE: 3.79529070854187\n",
      "train RMSE: 3.79472279548645\n",
      "train RMSE: 3.794156551361084\n",
      "train RMSE: 3.793590784072876\n",
      "train RMSE: 3.7930259704589844\n",
      "train RMSE: 3.7924623489379883\n",
      "train RMSE: 3.7918996810913086\n",
      "train RMSE: 3.791337490081787\n",
      "train RMSE: 3.7907767295837402\n",
      "train RMSE: 3.7902164459228516\n",
      "train RMSE: 3.7896571159362793\n",
      "train RMSE: 3.7890989780426025\n",
      "train RMSE: 3.788541555404663\n",
      "train RMSE: 3.787984609603882\n",
      "train RMSE: 3.787428855895996\n",
      "train RMSE: 3.7868740558624268\n",
      "train RMSE: 3.7863199710845947\n",
      "train RMSE: 3.785766839981079\n",
      "train RMSE: 3.78521466255188\n",
      "train RMSE: 3.784662961959839\n",
      "train RMSE: 3.7841122150421143\n",
      "train RMSE: 3.783562660217285\n",
      "train RMSE: 3.7830138206481934\n",
      "train RMSE: 3.782465696334839\n",
      "train RMSE: 3.7819180488586426\n",
      "train RMSE: 3.781371831893921\n",
      "train RMSE: 3.7808260917663574\n",
      "train RMSE: 3.7802810668945312\n",
      "train RMSE: 3.7797369956970215\n",
      "train RMSE: 3.779193878173828\n",
      "train RMSE: 3.778651237487793\n",
      "train RMSE: 3.778109550476074\n",
      "train RMSE: 3.7775685787200928\n",
      "train RMSE: 3.7770283222198486\n",
      "train RMSE: 3.7764892578125\n",
      "train RMSE: 3.7759506702423096\n",
      "train RMSE: 3.7754123210906982\n",
      "train RMSE: 3.7748754024505615\n",
      "train RMSE: 3.774338960647583\n",
      "train RMSE: 3.773803234100342\n",
      "train RMSE: 3.773268461227417\n",
      "train RMSE: 3.7727341651916504\n",
      "train RMSE: 3.7722008228302\n",
      "train RMSE: 3.771667957305908\n",
      "train RMSE: 3.7711360454559326\n",
      "train RMSE: 3.7706048488616943\n",
      "train RMSE: 3.7700741291046143\n",
      "train RMSE: 3.7695443630218506\n",
      "train RMSE: 3.769015073776245\n",
      "train RMSE: 3.768486499786377\n",
      "train RMSE: 3.767958641052246\n",
      "train RMSE: 3.7674314975738525\n",
      "train RMSE: 3.7669050693511963\n",
      "train RMSE: 3.7663791179656982\n",
      "train RMSE: 3.7658538818359375\n",
      "train RMSE: 3.765329360961914\n",
      "train RMSE: 3.764805793762207\n",
      "train RMSE: 3.764282464981079\n",
      "train RMSE: 3.7637600898742676\n",
      "train RMSE: 3.763237953186035\n",
      "train RMSE: 3.762716770172119\n",
      "train RMSE: 3.7621960639953613\n",
      "train RMSE: 3.7616758346557617\n",
      "train RMSE: 3.7611565589904785\n",
      "train RMSE: 3.7606379985809326\n",
      "train RMSE: 3.760119676589966\n",
      "train RMSE: 3.7596023082733154\n",
      "train RMSE: 3.759085178375244\n",
      "train RMSE: 3.7585690021514893\n",
      "train RMSE: 3.7580530643463135\n",
      "train RMSE: 3.757537841796875\n",
      "train RMSE: 3.7570230960845947\n",
      "train RMSE: 3.7565090656280518\n",
      "train RMSE: 3.755995512008667\n",
      "train RMSE: 3.7554826736450195\n",
      "train RMSE: 3.754970073699951\n",
      "train RMSE: 3.754458427429199\n",
      "train RMSE: 3.7539470195770264\n",
      "train RMSE: 3.753436326980591\n",
      "train RMSE: 3.7529258728027344\n",
      "train RMSE: 3.7524161338806152\n",
      "train RMSE: 3.7519068717956543\n",
      "train RMSE: 3.7513985633850098\n",
      "train RMSE: 3.7508902549743652\n",
      "train RMSE: 3.750382900238037\n",
      "train RMSE: 3.749875783920288\n",
      "train RMSE: 3.7493691444396973\n",
      "train RMSE: 3.7488629817962646\n",
      "train RMSE: 3.7483572959899902\n",
      "train RMSE: 3.747852087020874\n",
      "train RMSE: 3.747347354888916\n",
      "train RMSE: 3.746843099594116\n",
      "train RMSE: 3.7463393211364746\n",
      "train RMSE: 3.7458362579345703\n",
      "train RMSE: 3.745333433151245\n",
      "train RMSE: 3.744830846786499\n",
      "train RMSE: 3.7443289756774902\n",
      "train RMSE: 3.7438278198242188\n",
      "train RMSE: 3.7433266639709473\n",
      "train RMSE: 3.742825984954834\n",
      "train RMSE: 3.742326021194458\n",
      "train RMSE: 3.741826057434082\n",
      "train RMSE: 3.7413270473480225\n",
      "train RMSE: 3.740827798843384\n",
      "train RMSE: 3.7403292655944824\n",
      "train RMSE: 3.7398314476013184\n",
      "train RMSE: 3.7393336296081543\n",
      "train RMSE: 3.7388362884521484\n",
      "train RMSE: 3.7383391857147217\n",
      "train RMSE: 3.7378427982330322\n",
      "train RMSE: 3.737346649169922\n",
      "train RMSE: 3.7368507385253906\n",
      "train RMSE: 3.7363555431365967\n",
      "train RMSE: 3.7358603477478027\n",
      "train RMSE: 3.735365629196167\n",
      "train RMSE: 3.7348711490631104\n",
      "train RMSE: 3.734377145767212\n",
      "train RMSE: 3.7338836193084717\n",
      "train RMSE: 3.7333903312683105\n",
      "train RMSE: 3.7328972816467285\n",
      "train RMSE: 3.7324044704437256\n",
      "train RMSE: 3.731912136077881\n",
      "train RMSE: 3.7314200401306152\n",
      "train RMSE: 3.7309281826019287\n",
      "train RMSE: 3.7304365634918213\n",
      "train RMSE: 3.729945421218872\n",
      "train RMSE: 3.729454755783081\n",
      "train RMSE: 3.728964328765869\n",
      "train RMSE: 3.7284741401672363\n",
      "train RMSE: 3.7279837131500244\n",
      "train RMSE: 3.72749400138855\n",
      "train RMSE: 3.7270047664642334\n",
      "train RMSE: 3.726515531539917\n",
      "train RMSE: 3.7260265350341797\n",
      "train RMSE: 3.7255377769470215\n",
      "train RMSE: 3.7250492572784424\n",
      "train RMSE: 3.7245612144470215\n",
      "train RMSE: 3.7240734100341797\n",
      "train RMSE: 3.723585367202759\n",
      "train RMSE: 3.723097801208496\n",
      "train RMSE: 3.7226104736328125\n",
      "train RMSE: 3.722123146057129\n",
      "train RMSE: 3.7216362953186035\n",
      "train RMSE: 3.7211499214172363\n",
      "train RMSE: 3.72066330909729\n",
      "train RMSE: 3.720176935195923\n",
      "train RMSE: 3.719691038131714\n",
      "train RMSE: 3.719205141067505\n",
      "train RMSE: 3.718719244003296\n",
      "train RMSE: 3.718233823776245\n",
      "train RMSE: 3.7177484035491943\n",
      "train RMSE: 3.7172629833221436\n",
      "train RMSE: 3.71677827835083\n",
      "train RMSE: 3.7162930965423584\n",
      "train RMSE: 3.715808153152466\n",
      "train RMSE: 3.7153236865997314\n",
      "train RMSE: 3.714839220046997\n",
      "train RMSE: 3.7143547534942627\n",
      "train RMSE: 3.7138705253601074\n",
      "train RMSE: 3.7133865356445312\n",
      "train RMSE: 3.712902545928955\n",
      "train RMSE: 3.712418556213379\n",
      "train RMSE: 3.7119345664978027\n",
      "train RMSE: 3.7114508152008057\n",
      "train RMSE: 3.710967540740967\n",
      "train RMSE: 3.7104837894439697\n",
      "train RMSE: 3.7100002765655518\n",
      "CPU times: total: 46.5 s\n",
      "Wall time: 8.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_epocs(train, model, epochs=1000, lr=0.001, reg=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# halpful links:\n",
    "# https://d2l.ai/chapter_recommender-systems/autorec.html\n",
    "# https://github.com/gtshs2/Autorec\n",
    "# https://github.com/ImKeTT/Recommend_algorithms_Librec2Python/blob/master/AutoRec_torch/src/model.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "item_id  1     2     3     4     5     6     7     8     9     10    ...  \\\nuser_id                                                              ...   \n1         5.0   3.0   4.0   3.0   3.0   0.0   4.0   1.0   5.0   0.0  ...   \n2         4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  ...   \n3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n939       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   5.0   0.0  ...   \n940       0.0   0.0   0.0   2.0   0.0   0.0   4.0   5.0   3.0   0.0  ...   \n941       5.0   0.0   0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0  ...   \n942       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n943       0.0   5.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0   0.0  ...   \n\nitem_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \nuser_id                                                              \n1         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n2         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n939       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n940       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n941       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n942       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n943       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n\n[943 rows x 1650 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>item_id</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>1673</th>\n      <th>1674</th>\n      <th>1675</th>\n      <th>1676</th>\n      <th>1677</th>\n      <th>1678</th>\n      <th>1679</th>\n      <th>1680</th>\n      <th>1681</th>\n      <th>1682</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>939</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>940</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>941</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>942</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>943</th>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>943 rows Ã— 1650 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data_prep import movielens_prep\n",
    "train, test = movielens_prep(1)\n",
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "class AutoRec(nn.Module):\n",
    "    \"\"\"\n",
    "    AutoRec model. See explanation on :param: num_features for use as USER TO USER or ITEM TO ITEM\n",
    "    \"\"\"\n",
    "    def __init__(self, num_hidden=500, num_features):\n",
    "        \"\"\"\n",
    "        :param num_hidden: Size of the hidden layer\n",
    "        :param num_features: If num_features == num_items that means that we are doing USER TO USER model.\n",
    "                             If num_features == num_users that means that we are doing ITEM TO ITEM model.\n",
    "                             The logic is the a user vector has number of items features for it.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_features, num_hidden),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(num_hidden, num_features),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "num_items = train.shape[1]\n",
    "model = AutoRec(num_hidden=500, num_items=num_items).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "item_id  1     2     3     4     5     6     7     8     9     10    ...  \\\nuser_id                                                              ...   \n1         5.0   3.0   4.0   3.0   3.0   0.0   4.0   1.0   5.0   0.0  ...   \n2         4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  ...   \n3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n939       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   5.0   0.0  ...   \n940       0.0   0.0   0.0   2.0   0.0   0.0   4.0   5.0   3.0   0.0  ...   \n941       5.0   0.0   0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0  ...   \n942       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n943       0.0   5.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0   0.0  ...   \n\nitem_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \nuser_id                                                              \n1         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n2         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n939       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n940       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n941       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n942       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n943       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n\n[943 rows x 1650 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>item_id</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>1673</th>\n      <th>1674</th>\n      <th>1675</th>\n      <th>1676</th>\n      <th>1677</th>\n      <th>1678</th>\n      <th>1679</th>\n      <th>1680</th>\n      <th>1681</th>\n      <th>1682</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>939</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>940</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>941</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>942</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>943</th>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>943 rows Ã— 1650 columns</p>\n</div>"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.8818525671958923\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.8551897406578064\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.8325791954994202\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.8136186003684998\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7990342974662781\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7889807820320129\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7826008200645447\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7786074876785278\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7759285569190979\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.773897647857666\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7721620202064514\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7705500721931458\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7689843773841858\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7674416899681091\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7659291625022888\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7644634246826172\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7630578279495239\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7617179155349731\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.760441780090332\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7592237591743469\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7580554485321045\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7569267153739929\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7558286786079407\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7547565698623657\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.753710150718689\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7526924014091492\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7517065405845642\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7507543563842773\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7498352527618408\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7489463090896606\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7480830550193787\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7472404837608337\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7464137673377991\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7455996870994568\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7447960376739502\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7440024614334106\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7432196140289307\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7424489855766296\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7416920065879822\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7409501671791077\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7402242422103882\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.739514172077179\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7388194799423218\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7381395697593689\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.737473726272583\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7368216514587402\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7361830472946167\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7355582118034363\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7349474430084229\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.734351634979248\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7337709069252014\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7332056760787964\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7326554656028748\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7321197390556335\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.731597363948822\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7310869693756104\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7305871248245239\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7300965189933777\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7296140789985657\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7291391491889954\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7286714911460876\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.728210985660553\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.72775799036026\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7273126244544983\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7268750667572021\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.726445198059082\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7260228991508484\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7256076335906982\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7251989841461182\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7247961163520813\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7243984937667847\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.724005401134491\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.723616361618042\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.72323077917099\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7228484153747559\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7224690914154053\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7220925688743591\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7217187285423279\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7213475704193115\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7209790349006653\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7206131815910339\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7202499508857727\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7198892831802368\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7195311784744263\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7191755175590515\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7188223600387573\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7184715270996094\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7181232571601868\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7177776098251343\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7174350023269653\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.717095673084259\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7167599201202393\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7164278030395508\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.716099202632904\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7157735824584961\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7154502868652344\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7151288390159607\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7148089408874512\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7144905924797058\n",
      "type(x)=<class 'torch.Tensor'>\n",
      "x.shape=torch.Size([943, 1650])\n",
      "x=tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
      "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 5., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "preds.shape=torch.Size([943, 1650])\n",
      "train RMSE: 0.7141739130020142\n"
     ]
    }
   ],
   "source": [
    "def train_epocs(train, model, epochs=10, lr=0.001, reg=0):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=reg)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        rating = torch.FloatTensor(train.values).to(device)\n",
    "\n",
    "        preds = model(rating)\n",
    "        print(f'{preds.shape=}')\n",
    "        loss = torch.sqrt(nn.functional.mse_loss(preds, rating))\n",
    "\n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # update\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'train RMSE: {loss.item()}')\n",
    "    return preds\n",
    "\n",
    "p = train_epocs(train, model, epochs=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "         0         1         2         3         4         5         6     \\\n0    0.994848  0.392903  0.662953  0.895451  0.325029  0.145041  0.986105   \n1    0.988557  0.003067  0.068967  0.021322  0.034220  0.101958  0.940231   \n2    0.955694  0.023776  0.039658  0.048901  0.087155  0.077824  0.887364   \n3    0.975177  0.028419  0.028970  0.054612  0.088096  0.056843  0.916210   \n4    0.994654  0.622858  0.165374  0.718378  0.274245  0.058419  0.977258   \n..        ...       ...       ...       ...       ...       ...       ...   \n938  0.991130  0.051025  0.323125  0.071026  0.153836  0.089749  0.955611   \n939  0.995140  0.143129  0.101056  0.801486  0.182982  0.102510  0.984325   \n940  0.994149  0.037497  0.185038  0.086007  0.100694  0.064025  0.975074   \n941  0.994345  0.114465  0.025372  0.405925  0.097407  0.078003  0.966089   \n942  0.995297  0.977376  0.655500  0.978536  0.892372  0.070148  0.991101   \n\n         7         8         9     ...      1640      1641      1642  \\\n0    0.947417  0.950001  0.662624  ...  0.010853  0.011235  0.010198   \n1    0.049378  0.840171  0.371149  ...  0.006684  0.010159  0.009151   \n2    0.072917  0.259490  0.084609  ...  0.021863  0.018907  0.019174   \n3    0.085047  0.298206  0.046841  ...  0.014441  0.015681  0.015159   \n4    0.887227  0.581146  0.094884  ...  0.013419  0.013453  0.017735   \n..        ...       ...       ...  ...       ...       ...       ...   \n938  0.153340  0.911655  0.204451  ...  0.013207  0.016348  0.016048   \n939  0.909528  0.805859  0.389720  ...  0.005721  0.004535  0.005133   \n940  0.159960  0.828495  0.171009  ...  0.007111  0.009518  0.009600   \n941  0.860835  0.535772  0.136428  ...  0.010542  0.006965  0.009909   \n942  0.950009  0.825690  0.117983  ...  0.014136  0.018418  0.013745   \n\n         1643      1644      1645      1646      1647      1648      1649  \n0    0.014943  0.014040  0.012830  0.014401  0.012709  0.011365  0.016026  \n1    0.006457  0.008276  0.010902  0.010148  0.008574  0.007880  0.009527  \n2    0.020144  0.020436  0.023454  0.020993  0.020610  0.018124  0.023009  \n3    0.013156  0.014604  0.017919  0.015180  0.015510  0.014135  0.017592  \n4    0.012101  0.020025  0.017116  0.015807  0.017173  0.011341  0.013136  \n..        ...       ...       ...       ...       ...       ...       ...  \n938  0.011817  0.014905  0.018492  0.015332  0.014069  0.017185  0.015314  \n939  0.005847  0.003894  0.006064  0.006330  0.006631  0.005134  0.008273  \n940  0.007096  0.009748  0.009760  0.008535  0.008507  0.009405  0.008314  \n941  0.008443  0.006108  0.009024  0.009501  0.010251  0.009578  0.016181  \n942  0.012153  0.012881  0.013540  0.012963  0.010301  0.017350  0.017707  \n\n[943 rows x 1650 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>1640</th>\n      <th>1641</th>\n      <th>1642</th>\n      <th>1643</th>\n      <th>1644</th>\n      <th>1645</th>\n      <th>1646</th>\n      <th>1647</th>\n      <th>1648</th>\n      <th>1649</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.994848</td>\n      <td>0.392903</td>\n      <td>0.662953</td>\n      <td>0.895451</td>\n      <td>0.325029</td>\n      <td>0.145041</td>\n      <td>0.986105</td>\n      <td>0.947417</td>\n      <td>0.950001</td>\n      <td>0.662624</td>\n      <td>...</td>\n      <td>0.010853</td>\n      <td>0.011235</td>\n      <td>0.010198</td>\n      <td>0.014943</td>\n      <td>0.014040</td>\n      <td>0.012830</td>\n      <td>0.014401</td>\n      <td>0.012709</td>\n      <td>0.011365</td>\n      <td>0.016026</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.988557</td>\n      <td>0.003067</td>\n      <td>0.068967</td>\n      <td>0.021322</td>\n      <td>0.034220</td>\n      <td>0.101958</td>\n      <td>0.940231</td>\n      <td>0.049378</td>\n      <td>0.840171</td>\n      <td>0.371149</td>\n      <td>...</td>\n      <td>0.006684</td>\n      <td>0.010159</td>\n      <td>0.009151</td>\n      <td>0.006457</td>\n      <td>0.008276</td>\n      <td>0.010902</td>\n      <td>0.010148</td>\n      <td>0.008574</td>\n      <td>0.007880</td>\n      <td>0.009527</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.955694</td>\n      <td>0.023776</td>\n      <td>0.039658</td>\n      <td>0.048901</td>\n      <td>0.087155</td>\n      <td>0.077824</td>\n      <td>0.887364</td>\n      <td>0.072917</td>\n      <td>0.259490</td>\n      <td>0.084609</td>\n      <td>...</td>\n      <td>0.021863</td>\n      <td>0.018907</td>\n      <td>0.019174</td>\n      <td>0.020144</td>\n      <td>0.020436</td>\n      <td>0.023454</td>\n      <td>0.020993</td>\n      <td>0.020610</td>\n      <td>0.018124</td>\n      <td>0.023009</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.975177</td>\n      <td>0.028419</td>\n      <td>0.028970</td>\n      <td>0.054612</td>\n      <td>0.088096</td>\n      <td>0.056843</td>\n      <td>0.916210</td>\n      <td>0.085047</td>\n      <td>0.298206</td>\n      <td>0.046841</td>\n      <td>...</td>\n      <td>0.014441</td>\n      <td>0.015681</td>\n      <td>0.015159</td>\n      <td>0.013156</td>\n      <td>0.014604</td>\n      <td>0.017919</td>\n      <td>0.015180</td>\n      <td>0.015510</td>\n      <td>0.014135</td>\n      <td>0.017592</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.994654</td>\n      <td>0.622858</td>\n      <td>0.165374</td>\n      <td>0.718378</td>\n      <td>0.274245</td>\n      <td>0.058419</td>\n      <td>0.977258</td>\n      <td>0.887227</td>\n      <td>0.581146</td>\n      <td>0.094884</td>\n      <td>...</td>\n      <td>0.013419</td>\n      <td>0.013453</td>\n      <td>0.017735</td>\n      <td>0.012101</td>\n      <td>0.020025</td>\n      <td>0.017116</td>\n      <td>0.015807</td>\n      <td>0.017173</td>\n      <td>0.011341</td>\n      <td>0.013136</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>938</th>\n      <td>0.991130</td>\n      <td>0.051025</td>\n      <td>0.323125</td>\n      <td>0.071026</td>\n      <td>0.153836</td>\n      <td>0.089749</td>\n      <td>0.955611</td>\n      <td>0.153340</td>\n      <td>0.911655</td>\n      <td>0.204451</td>\n      <td>...</td>\n      <td>0.013207</td>\n      <td>0.016348</td>\n      <td>0.016048</td>\n      <td>0.011817</td>\n      <td>0.014905</td>\n      <td>0.018492</td>\n      <td>0.015332</td>\n      <td>0.014069</td>\n      <td>0.017185</td>\n      <td>0.015314</td>\n    </tr>\n    <tr>\n      <th>939</th>\n      <td>0.995140</td>\n      <td>0.143129</td>\n      <td>0.101056</td>\n      <td>0.801486</td>\n      <td>0.182982</td>\n      <td>0.102510</td>\n      <td>0.984325</td>\n      <td>0.909528</td>\n      <td>0.805859</td>\n      <td>0.389720</td>\n      <td>...</td>\n      <td>0.005721</td>\n      <td>0.004535</td>\n      <td>0.005133</td>\n      <td>0.005847</td>\n      <td>0.003894</td>\n      <td>0.006064</td>\n      <td>0.006330</td>\n      <td>0.006631</td>\n      <td>0.005134</td>\n      <td>0.008273</td>\n    </tr>\n    <tr>\n      <th>940</th>\n      <td>0.994149</td>\n      <td>0.037497</td>\n      <td>0.185038</td>\n      <td>0.086007</td>\n      <td>0.100694</td>\n      <td>0.064025</td>\n      <td>0.975074</td>\n      <td>0.159960</td>\n      <td>0.828495</td>\n      <td>0.171009</td>\n      <td>...</td>\n      <td>0.007111</td>\n      <td>0.009518</td>\n      <td>0.009600</td>\n      <td>0.007096</td>\n      <td>0.009748</td>\n      <td>0.009760</td>\n      <td>0.008535</td>\n      <td>0.008507</td>\n      <td>0.009405</td>\n      <td>0.008314</td>\n    </tr>\n    <tr>\n      <th>941</th>\n      <td>0.994345</td>\n      <td>0.114465</td>\n      <td>0.025372</td>\n      <td>0.405925</td>\n      <td>0.097407</td>\n      <td>0.078003</td>\n      <td>0.966089</td>\n      <td>0.860835</td>\n      <td>0.535772</td>\n      <td>0.136428</td>\n      <td>...</td>\n      <td>0.010542</td>\n      <td>0.006965</td>\n      <td>0.009909</td>\n      <td>0.008443</td>\n      <td>0.006108</td>\n      <td>0.009024</td>\n      <td>0.009501</td>\n      <td>0.010251</td>\n      <td>0.009578</td>\n      <td>0.016181</td>\n    </tr>\n    <tr>\n      <th>942</th>\n      <td>0.995297</td>\n      <td>0.977376</td>\n      <td>0.655500</td>\n      <td>0.978536</td>\n      <td>0.892372</td>\n      <td>0.070148</td>\n      <td>0.991101</td>\n      <td>0.950009</td>\n      <td>0.825690</td>\n      <td>0.117983</td>\n      <td>...</td>\n      <td>0.014136</td>\n      <td>0.018418</td>\n      <td>0.013745</td>\n      <td>0.012153</td>\n      <td>0.012881</td>\n      <td>0.013540</td>\n      <td>0.012963</td>\n      <td>0.010301</td>\n      <td>0.017350</td>\n      <td>0.017707</td>\n    </tr>\n  </tbody>\n</table>\n<p>943 rows Ã— 1650 columns</p>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(torch.Tensor.cpu(p).detach().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[4.9101810e+00, 1.9693743e+00, 3.4679255e+00, ..., 3.3794111e-01,\n        3.8359052e-01, 4.7213659e-01],\n       [4.7767887e+00, 3.3519408e-03, 3.1996059e-01, ..., 1.9354329e-01,\n        2.1273448e-01, 2.1550149e-01],\n       [4.0800991e+00, 1.0779200e-01, 1.6463345e-01, ..., 6.1387408e-01,\n        7.1507138e-01, 7.4785805e-01],\n       ...,\n       [4.8953419e+00, 1.7699021e-01, 9.3510562e-01, ..., 1.9119012e-01,\n        2.8748101e-01, 1.6761416e-01],\n       [4.8995171e+00, 5.6515604e-01, 8.8921607e-02, ..., 2.5211126e-01,\n        2.9596657e-01, 4.7826663e-01],\n       [4.9196835e+00, 4.9169917e+00, 3.4284275e+00, ..., 2.5384778e-01,\n        6.7711121e-01, 5.3850901e-01]], dtype=float32)"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler((0, 5))\n",
    "scaler.fit_transform(torch.Tensor.cpu(p).detach().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "item_id  1     2     3     4     5     6     7     8     9     10    ...  \\\nuser_id                                                              ...   \n1         5.0   3.0   4.0   3.0   3.0   0.0   4.0   1.0   5.0   0.0  ...   \n2         4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  ...   \n3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n939       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   5.0   0.0  ...   \n940       0.0   0.0   0.0   2.0   0.0   0.0   4.0   5.0   3.0   0.0  ...   \n941       5.0   0.0   0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0  ...   \n942       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n943       0.0   5.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0   0.0  ...   \n\nitem_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \nuser_id                                                              \n1         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n2         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n939       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n940       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n941       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n942       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n943       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n\n[943 rows x 1650 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>item_id</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>1673</th>\n      <th>1674</th>\n      <th>1675</th>\n      <th>1676</th>\n      <th>1677</th>\n      <th>1678</th>\n      <th>1679</th>\n      <th>1680</th>\n      <th>1681</th>\n      <th>1682</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>939</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>940</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>941</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>942</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>943</th>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>943 rows Ã— 1650 columns</p>\n</div>"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}